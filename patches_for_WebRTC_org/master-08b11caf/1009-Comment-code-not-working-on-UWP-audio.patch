From e53a8ac97e500e780c4c5ce8c650e8f043539b87 Mon Sep 17 00:00:00 2001
From: Filippo Banno <fiban@microsoft.com>
Date: Mon, 17 Feb 2020 18:31:33 +0000
Subject: [PATCH 1/3] Comment code not working on UWP - audio

---
 .../audio_device/win/audio_device_core_win.cc | 3257 +++++++++--------
 .../audio_device/win/core_audio_base_win.cc   |  269 +-
 .../audio_device/win/core_audio_base_win.h    |    2 +-
 .../audio_device/win/core_audio_input_win.cc  |   91 +-
 .../audio_device/win/core_audio_output_win.cc |   95 +-
 .../win/core_audio_utility_win.cc             | 1754 ++++-----
 .../audio_device/win/core_audio_utility_win.h |   84 +-
 .../win/core_audio_utility_win_unittest.cc    |    3 +-
 8 files changed, 2796 insertions(+), 2759 deletions(-)

diff --git a/modules/audio_device/win/audio_device_core_win.cc b/modules/audio_device/win/audio_device_core_win.cc
index 28768beb39..57b2809e1a 100644
--- a/modules/audio_device/win/audio_device_core_win.cc
+++ b/modules/audio_device/win/audio_device_core_win.cc
@@ -21,9 +21,9 @@
 #include <wrl/wrappers/corewrappers.h>
 
 #pragma comment(lib, "windowsapp")
-#include <winrt/Windows.Devices.Enumeration.h>
-#include <winrt/Windows.Foundation.h>
-#include <winrt/Windows.Media.Devices.h>
+// #include <winrt/Windows.Devices.Enumeration.h>
+// #include <winrt/Windows.Foundation.h>
+// #include <winrt/Windows.Media.Devices.h>
 
 #include "modules/audio_device/audio_device_config.h"
 #include "rtc_base/logging.h"
@@ -43,8 +43,8 @@
 const size_t MAXERRORLENGTH = 256;
 #endif
 
-    const size_t MIN_CORE_SPEAKER_VOLUME = 0;
-const size_t MAX_CORE_SPEAKER_VOLUME = 100;
+//     const size_t MIN_CORE_SPEAKER_VOLUME = 0;
+// const size_t MAX_CORE_SPEAKER_VOLUME = 100;
 
 // ----------------------------------------------------------------------------
 //  _TraceCOMError
@@ -121,1557 +121,1557 @@ struct CCompletionDelegate
   }
 };
 
-template <winrt::Windows::Devices::Enumeration::DeviceClass DEVICE_CLASS>
-struct DeviceHelper {
- protected:
-  winrt::Windows::Devices::Enumeration::DeviceInformation _deviceInformation =
-      nullptr;
-
-  bool _usingDeviceIndex = false;
-  uint16_t _deviceIndex = -1;
-  webrtc::AudioDeviceModule::WindowsDeviceType _deviceType =
-      static_cast<webrtc::AudioDeviceModule::WindowsDeviceType>(0);
-
- public:
-  //
-  // Device enumeration
-  //
-
-  int16_t Devices() {
-    auto deviceInformationFindAllAsync =
-        winrt::Windows::Devices::Enumeration::DeviceInformation::FindAllAsync(
-            DEVICE_CLASS);
-    blocking_suspend(deviceInformationFindAllAsync);
-    if (deviceInformationFindAllAsync.Status() ==
-        winrt::Windows::Foundation::AsyncStatus::Error) {
-      return -1;
-    }
-
-    winrt::Windows::Devices::Enumeration::DeviceInformationCollection
-        deviceInformationCollection =
-            deviceInformationFindAllAsync.GetResults();
-    return deviceInformationCollection.Size();
-  }
-
-  int32_t DeviceName(uint16_t index,
-                     char name[webrtc::kAdmMaxDeviceNameSize],
-                     char guid[webrtc::kAdmMaxGuidSize]) {
-    auto deviceInformationFindAllAsync =
-        winrt::Windows::Devices::Enumeration::DeviceInformation::FindAllAsync(
-            DEVICE_CLASS);
-    blocking_suspend(deviceInformationFindAllAsync);
-    if (deviceInformationFindAllAsync.Status() ==
-        winrt::Windows::Foundation::AsyncStatus::Error) {
-      return -1;
-    }
-
-    winrt::Windows::Devices::Enumeration::DeviceInformationCollection
-        deviceInformationCollection =
-            deviceInformationFindAllAsync.GetResults();
-
-    // Special fix for the case when the user selects '-1' as index (<=> Default
-    // Communication Device)
-    if (index == (uint16_t)(-1)) {
-      index = 0;
-      RTC_LOG(LS_VERBOSE)
-          << "Default Communication endpoint device will be used";
-    }
-
-    if (index >= deviceInformationCollection.Size()) {
-      return -1;
-    }
-
-    winrt::Windows::Devices::Enumeration::DeviceInformation deviceInformation =
-        deviceInformationCollection.GetAt(index);
-
-    if (name != nullptr) {
-      std::wstring deviceInformationName = deviceInformation.Name().c_str();
-      std::string nameUFT8 = rtc::ToUtf8(deviceInformationName);
-      size_t length =
-          std::min(nameUFT8.size(),
-                   static_cast<size_t>(webrtc::kAdmMaxDeviceNameSize - 1));
-      std::copy_n(nameUFT8.begin(), length, guid);
-      name[length] = '\0';
-    }
-
-    if (guid != nullptr) {
-      std::wstring deviceInformationId = deviceInformation.Id().c_str();
-      std::string idUFT8 = rtc::ToUtf8(deviceInformationId);
-      size_t length = std::min(
-          idUFT8.size(), static_cast<size_t>(webrtc::kAdmMaxGuidSize - 1));
-      std::copy_n(idUFT8.begin(), length, guid);
-      guid[length] = '\0';
-    }
-
-    return 0;
-  }
-
-  //
-  // Device selection
-  //
-
-  int32_t SetDevice(uint16_t index) {
-    auto deviceInformationFindAllAsync =
-        winrt::Windows::Devices::Enumeration::DeviceInformation::FindAllAsync(
-            DEVICE_CLASS);
-    blocking_suspend(deviceInformationFindAllAsync);
-    if (deviceInformationFindAllAsync.Status() ==
-        winrt::Windows::Foundation::AsyncStatus::Error) {
-      return -1;
-    }
-
-    winrt::Windows::Devices::Enumeration::DeviceInformationCollection
-        captureDevices = deviceInformationFindAllAsync.GetResults();
-
-    // Special fix for the case when the user selects '-1' as index (<=> Default
-    // Communication Device)
-    if (index == (uint16_t)(-1)) {
-      index = 0;
-      RTC_LOG(LS_VERBOSE)
-          << "Default Communication endpoint device will be used";
-    }
-
-    if (index >= captureDevices.Size()) {
-      return -1;
-    }
-
-    _deviceInformation = captureDevices.GetAt(index);
-
-    _deviceIndex = index;
-    _usingDeviceIndex = true;
-
-    return 0;
-  }
-
-  int32_t SetDevice(
-      webrtc::AudioDeviceModule::WindowsDeviceType windowsDeviceType) {
-    winrt::Windows::Media::Devices::AudioDeviceRole audioDeviceRole;
-    switch (windowsDeviceType) {
-      case webrtc::AudioDeviceModule::kDefaultCommunicationDevice:
-        audioDeviceRole =
-            winrt::Windows::Media::Devices::AudioDeviceRole::Communications;
-        break;
-
-      case webrtc::AudioDeviceModule::kDefaultDevice:
-        audioDeviceRole =
-            winrt::Windows::Media::Devices::AudioDeviceRole::Default;
-        break;
-
-      default:
-        return -1;
-    }
-
-    winrt::hstring audioDeviceId;
-    switch (DEVICE_CLASS) {
-      case winrt::Windows::Devices::Enumeration::DeviceClass::AudioCapture:
-        audioDeviceId = winrt::Windows::Media::Devices::MediaDevice::
-            GetDefaultAudioCaptureId(audioDeviceRole);
-        break;
-
-      case winrt::Windows::Devices::Enumeration::DeviceClass::AudioRender:
-        audioDeviceId = winrt::Windows::Media::Devices::MediaDevice::
-            GetDefaultAudioRenderId(audioDeviceRole);
-        break;
-
-      default:
-        return -1;
-    }
-    if (audioDeviceId.empty()) {
-      return -1;
-    }
-
-    auto deviceInformationCreateFromIdAsync = winrt::Windows::Devices::
-        Enumeration::DeviceInformation::CreateFromIdAsync(audioDeviceId);
-    blocking_suspend(deviceInformationCreateFromIdAsync);
-    if (deviceInformationCreateFromIdAsync.Status() ==
-        winrt::Windows::Foundation::AsyncStatus::Error) {
-      return -1;
-    }
-
-    _deviceInformation = deviceInformationCreateFromIdAsync.GetResults();
-
-    _deviceType = windowsDeviceType;
-    _usingDeviceIndex = false;
-
-    return 0;
-  }
-
-  virtual winrt::Windows::Devices::Enumeration::DeviceInformation GetDevice()
-      final {
-    return _deviceInformation;
-  }
-};
-
-template <winrt::Windows::Devices::Enumeration::DeviceClass DEVICE_CLASS>
-struct AudioDeviceHelper : public DeviceHelper<DEVICE_CLASS> {
- protected:
-  webrtc::AudioDeviceBuffer* _pAudioBuffer = nullptr;
-
-  bool _mixerInitialized = false;
-  bool _transportInitialized = false;
-  bool _transporting = false;
-
-  UINT _audioFrameSize = 0;
-  uint32_t _sampleRate = 0;
-  uint32_t _blockSize = 0;
-  uint32_t _channels = 2;
-  UINT64 _samples = 0;
-
-  HANDLE _hSamplesReadyEvent = CreateEvent(nullptr, FALSE, FALSE, nullptr);
-  HANDLE _hStartedEvent = CreateEvent(nullptr, FALSE, FALSE, nullptr);
-  HANDLE _hShutdownEvent = CreateEvent(nullptr, FALSE, FALSE, nullptr);
-  HANDLE _hThread = nullptr;
-
-  Microsoft::WRL::ComPtr<IAudioClient2> _audioClient;
-  Microsoft::WRL::ComPtr<ISimpleAudioVolume> _simpleAudioVolume;
-
-  static DWORD WINAPI WSAPIThread(LPVOID context) {
-    return reinterpret_cast<AudioDeviceHelper*>(context)->Transport();
-  }
-
- public:
-  virtual ~AudioDeviceHelper() {
-    CloseHandle(_hSamplesReadyEvent);
-    CloseHandle(_hThread);
-    CloseHandle(_hStartedEvent);
-    CloseHandle(_hShutdownEvent);
-  }
-
-  virtual void AttachAudioBuffer(webrtc::AudioDeviceBuffer* audioBuffer) {
-    _pAudioBuffer = audioBuffer;
-  }
-
-  virtual DWORD Transport() = 0;
-
-  //
-  // Audio mixer initialization
-  //
-
-  virtual int32_t InitMixer() {
-    if (MixerIsInitialized()) {
-      return 0;
-    }
-
-    if (Transporting() || GetDevice() == nullptr) {
-      return -1;
-    }
-
-    if (_usingDeviceIndex) {
-      int16_t nDevices = Devices();
-      if (_deviceIndex > (nDevices - 1)) {
-        RTC_LOG(LS_ERROR) << "current device selection is invalid => unable to"
-                          << " initialize";
-        return -1;
-      }
-    }
-
-    int32_t ret;
-    if (_usingDeviceIndex) {
-      ret = SetDevice(_deviceIndex);
-    } else {
-      ret = SetDevice(_deviceType);
-    }
-    if (ret != 0) {
-      RTC_LOG(LS_ERROR) << "failed to initialize the enpoint device";
-      return -1;
-    }
-
-    Microsoft::WRL::ComPtr<CCompletionDelegate> completionDelegate =
-        Microsoft::WRL::Make<CCompletionDelegate>();
-    {
-      Microsoft::WRL::ComPtr<IActivateAudioInterfaceAsyncOperation> asyncOp;
-      HRESULT hr = ActivateAudioInterfaceAsync(
-          GetDevice().Id().c_str(), __uuidof(IAudioClient2), nullptr,
-          completionDelegate.Get(), &asyncOp);
-      if (FAILED(hr)) {
-        return -1;
-      }
-    }
-
-    {
-      HRESULT hr = completionDelegate->Wait(INFINITE);
-      if (FAILED(hr)) {
-        return -1;
-      }
-    }
-
-    Microsoft::WRL::ComPtr<IUnknown> punkAudioInterface;
-    {
-      HRESULT hr = completionDelegate->GetActivateResult(&punkAudioInterface);
-      if (FAILED(hr)) {
-        return -1;
-      }
-    }
-
-    {
-      HRESULT hr =
-          punkAudioInterface->QueryInterface(IID_PPV_ARGS(&_audioClient));
-      if (FAILED(hr)) {
-        return -1;
-      }
-    }
-
-    {
-      AudioClientProperties properties = {};
-      properties.cbSize = sizeof AudioClientProperties;
-      properties.eCategory = AudioCategory_Communications;
-
-      HRESULT hr = _audioClient->SetClientProperties(&properties);
-      if (FAILED(hr)) {
-        return -1;
-      }
-    }
-
-    _mixerInitialized = true;
-    return 0;
-  }
-
-  virtual bool MixerIsInitialized() const final { return _mixerInitialized; }
-
-  //
-  // Audio transport initialization
-  //
-
-  virtual int32_t TransportIsAvailable(bool& available) { return true; }
-
-  virtual int32_t InitTransport() = 0;
-
-  virtual bool TransportIsInitialized() const final {
-    return _transportInitialized;
-  }
-
-  //
-  // Audio transport control
-  //
-
-  virtual int32_t StartTransport() {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    if (_hThread != nullptr) {
-      return 0;
-    }
-
-    if (Transporting()) {
-      return 0;
-    }
-
-    assert(_hThread == nullptr);
-    _hThread = CreateThread(nullptr, 0, WSAPIThread, this, 0, nullptr);
-    if (_hThread == nullptr) {
-      RTC_LOG(LS_ERROR) << "failed to create the thread";
-      return -1;
-    }
-
-    // Set thread priority to highest possible
-    SetThreadPriority(_hThread, THREAD_PRIORITY_TIME_CRITICAL);
-
-    DWORD ret = WaitForSingleObject(_hStartedEvent, 1000);
-    if (ret != WAIT_OBJECT_0) {
-      RTC_LOG(LS_VERBOSE) << "did not start up properly";
-
-      // Stop transport thread and clean up
-      _transporting = true;
-      StopTransport();
-
-      return -1;
-    }
-    RTC_LOG(LS_VERBOSE) << "audio stream has now started...";
-
-    _transporting = true;
-
-    return 0;
-  }
-
-  virtual int32_t StopTransport() {
-    if (!Transporting()) {
-      return 0;
-    }
-
-    if (_hThread == nullptr) {
-      RTC_LOG(LS_VERBOSE)
-          << "no rendering stream is active => close down WASAPI only";
-      _transportInitialized = false;
-      _transporting = false;
-      return 0;
-    }
-
-    // stop the driving thread...
-    RTC_LOG(LS_VERBOSE) << "closing down the webrtc_core_audio_thread...";
-    SetEvent(_hShutdownEvent);
-
-    DWORD ret = WaitForSingleObject(_hThread, 2000);
-    if (ret != WAIT_OBJECT_0) {
-      // the thread did not stop as it should
-      RTC_LOG(LS_ERROR) << "failed to close down webrtc_core_audio_thread";
-      CloseHandle(_hThread);
-      _hThread = nullptr;
-      _transportInitialized = false;
-      _transporting = false;
-      return -1;
-    }
-
-    RTC_LOG(LS_VERBOSE) << "webrtc_core_audio_thread is now closed";
-
-    // to reset this event manually at each time we finish with it,
-    // in case that the render thread has exited before StopPlayout(),
-    // this event might be caught by the new render thread within same VoE
-    // instance.
-    ResetEvent(_hShutdownEvent);
-
-    _transportInitialized = false;
-    _transporting = false;
-
-    CloseHandle(_hThread);
-    _hThread = nullptr;
-
-    return 0;
-  }
-
-  virtual bool Transporting() const final { return _transporting; }
-
-  //
-  // Speaker volume controls
-  //
-
-  virtual int32_t VolumeIsAvailable(bool& available) const {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    float volume;
-    HRESULT hr = _simpleAudioVolume->GetMasterVolume(&volume);
-    available = SUCCEEDED(hr);
-
-    return 0;
-  }
-
-  virtual int32_t SetVolume(uint32_t volume) {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    if (volume < MIN_CORE_SPEAKER_VOLUME || volume > MAX_CORE_SPEAKER_VOLUME) {
-      return -1;
-    }
-
-    const float fLevel = volume / static_cast<float>(MAX_CORE_SPEAKER_VOLUME);
-    HRESULT hr = _simpleAudioVolume->SetMasterVolume(fLevel, nullptr);
-    if (FAILED(hr)) {
-      return -1;
-    }
-
-    return 0;
-  }
-
-  virtual int32_t Volume(uint32_t& volume) const {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    float fLevel;
-    HRESULT hr = _simpleAudioVolume->GetMasterVolume(&fLevel);
-    if (FAILED(hr)) {
-      return -1;
-    }
-
-    volume = fLevel * MAX_CORE_SPEAKER_VOLUME;
-
-    return 0;
-  }
-
-  virtual int32_t MaxVolume(uint32_t& maxVolume) const {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    maxVolume = MAX_CORE_SPEAKER_VOLUME;
-
-    return 0;
-  }
-
-  virtual int32_t MinVolume(uint32_t& minVolume) const {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    minVolume = MIN_CORE_SPEAKER_VOLUME;
-
-    return 0;
-  }
-
-  //
-  // Mute control
-  //
-
-  virtual int32_t MuteIsAvailable(bool& available) const {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    BOOL mute;
-    HRESULT hr = _simpleAudioVolume->GetMute(&mute);
-    available = SUCCEEDED(hr);
-
-    return 0;
-  }
-
-  virtual int32_t SetMute(bool enable) {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    BOOL mute = enable;
-    HRESULT hr = _simpleAudioVolume->SetMute(mute, nullptr);
-    if (FAILED(hr)) {
-      return -1;
-    }
-
-    return 0;
-  }
-
-  virtual int32_t Mute(bool& enabled) const {
-    if (!TransportIsInitialized()) {
-      return -1;
-    }
-
-    BOOL mute;
-    HRESULT hr = _simpleAudioVolume->GetMute(&mute);
-    if (FAILED(hr)) {
-      return -1;
-    }
-
-    enabled = mute == TRUE;
-
-    return 0;
-  }
-
-  //
-  // Stereo support
-  //
-
-  virtual int32_t StereoIsAvailable(bool& available) const {
-    if (!MixerIsInitialized()) {
-      return -1;
-    }
-
-    available = true;
-
-    return 0;
-  }
-
-  virtual int32_t SetStereo(bool enable) = 0;
-
-  virtual int32_t Stereo(bool& enabled) const {
-    enabled = _channels == 2;
-
-    return 0;
-  }
-};
-
-struct CaptureDeviceInternal
-    : public AudioDeviceHelper<
-          winrt::Windows::Devices::Enumeration::DeviceClass::AudioCapture> {
- protected:
-  const rtc::CriticalSection* _critSect;
-  const uint32_t* _sndCardDelay;
-
-  Microsoft::WRL::ComPtr<IAudioCaptureClient> _audioCaptureClient;
-
-  LARGE_INTEGER _perfCounterFreq;
-  double _perfCounterFactor;
-
-  uint16_t _channelsPrioList[3];
-
- public:
-  CaptureDeviceInternal(rtc::CriticalSection* critSect, uint32_t* sndCardDelay)
-      : _critSect(critSect), _sndCardDelay(sndCardDelay) {
-    _perfCounterFreq.QuadPart = 1;
-    _perfCounterFactor = 0.0;
-
-    // list of number of channels to use on recording side
-    _channelsPrioList[0] = 2;  // stereo is prio 1
-    _channelsPrioList[1] = 1;  // mono is prio 2
-    _channelsPrioList[2] = 4;  // quad is prio 3
-  }
-
-  void AttachAudioBuffer(webrtc::AudioDeviceBuffer* audioBuffer) override {
-    AudioDeviceHelper::AttachAudioBuffer(audioBuffer);
-    audioBuffer->SetRecordingSampleRate(0);
-    audioBuffer->SetRecordingChannels(0);
-  }
-
-  DWORD Transport() override {
-    bool keepRecording = true;
-    HANDLE waitArray[2] = {_hShutdownEvent, _hSamplesReadyEvent};
-    HRESULT hr = S_OK;
-
-    LARGE_INTEGER t1;
-
-    BYTE* syncBuffer = nullptr;
-    UINT32 syncBufIndex = 0;
-
-    _samples = 0;
-
-    // Initialize COM as MTA in this thread.
-    Microsoft::WRL::Wrappers::RoInitializeWrapper roInitializeWrapper(
-        RO_INIT_MULTITHREADED);
-    if (FAILED(roInitializeWrapper)) {
-      RTC_LOG(LS_ERROR) << "failed to initialize COM in capture thread";
-      return 1;
-    }
-
-    rtc::SetCurrentThreadName("webrtc_core_audio_capture_thread");
-
-    // Get size of capturing buffer (length is expressed as the number of audio
-    // frames the buffer can hold). This value is fixed during the capturing
-    // session.
-    //
-    UINT32 bufferLength = 0;
-    if (_audioClient == nullptr) {
-      RTC_LOG(LS_ERROR)
-          << "input state has been modified before capture loop starts.";
-      return 1;
-    }
-    hr = _audioClient->GetBufferSize(&bufferLength);
-    EXIT_ON_ERROR(hr);
-    RTC_LOG(LS_VERBOSE) << "[CAPT] size of buffer       : " << bufferLength;
-
-    // Allocate memory for sync buffer.
-    // It is used for compensation between native 44.1 and internal 44.0 and
-    // for cases when the capture buffer is larger than 10ms.
-    //
-    const UINT32 syncBufferSize = 2 * (bufferLength * _audioFrameSize);
-    syncBuffer = new BYTE[syncBufferSize];
-    if (syncBuffer == nullptr) {
-      return (DWORD)E_POINTER;
-    }
-    RTC_LOG(LS_VERBOSE) << "[CAPT] size of sync buffer  : " << syncBufferSize
-                        << " [bytes]";
-
-    // Get maximum latency for the current stream (will not change for the
-    // lifetime of the IAudioClient object).
-    //
-    REFERENCE_TIME latency;
-    _audioClient->GetStreamLatency(&latency);
-    RTC_LOG(LS_VERBOSE) << "[CAPT] max stream latency   : " << (DWORD)latency
-                        << " (" << (double)(latency / 10000.0) << " ms)";
-
-    // Get the length of the periodic interval separating successive processing
-    // passes by the audio engine on the data in the endpoint buffer.
-    //
-    REFERENCE_TIME devPeriod = 0;
-    REFERENCE_TIME devPeriodMin = 0;
-    _audioClient->GetDevicePeriod(&devPeriod, &devPeriodMin);
-    RTC_LOG(LS_VERBOSE) << "[CAPT] device period        : " << (DWORD)devPeriod
-                        << " (" << (double)(devPeriod / 10000.0) << " ms)";
-
-    double extraDelayMS = (double)((latency + devPeriod) / 10000.0);
-    RTC_LOG(LS_VERBOSE) << "[CAPT] extraDelayMS         : " << extraDelayMS;
-
-    double endpointBufferSizeMS =
-        10.0 * ((double)bufferLength / (double)_blockSize);
-    RTC_LOG(LS_VERBOSE) << "[CAPT] endpointBufferSizeMS : "
-                        << endpointBufferSizeMS;
-
-    // Start up the capturing stream.
-    //
-    hr = _audioClient->Start();
-    EXIT_ON_ERROR(hr);
-
-    // Set event which will ensure that the calling thread modifies the
-    // recording state to true.
-    //
-    SetEvent(_hStartedEvent);
-
-    // >> ---------------------------- THREAD LOOP ----------------------------
-
-    while (keepRecording) {
-      // Wait for a capture notification event or a shutdown event
-      DWORD waitResult = WaitForMultipleObjects(2, waitArray, FALSE, 500);
-      switch (waitResult) {
-        case WAIT_OBJECT_0 + 0:  // _hShutdownCaptureEvent
-          keepRecording = false;
-          break;
-        case WAIT_OBJECT_0 + 1:  // _hCaptureSamplesReadyEvent
-          break;
-        case WAIT_TIMEOUT:  // timeout notification
-          RTC_LOG(LS_WARNING) << "capture event timed out after 0.5 seconds";
-          goto Exit;
-        default:  // unexpected error
-          RTC_LOG(LS_WARNING) << "unknown wait termination on capture side";
-          goto Exit;
-      }
-
-      while (keepRecording) {
-        rtc::CritScope lock(_critSect);
-
-        BYTE* pData = 0;
-        UINT32 framesAvailable = 0;
-        DWORD flags = 0;
-        UINT64 recTime = 0;
-        UINT64 recPos = 0;
-
-        // Sanity check to ensure that essential states are not modified
-        // during the unlocked period.
-        if (_audioCaptureClient == nullptr || _audioClient == nullptr) {
-          RTC_LOG(LS_ERROR)
-              << "input state has been modified during unlocked period";
-          goto Exit;
-        }
-
-        //  Find out how much capture data is available
-        //
-        hr = _audioCaptureClient->GetBuffer(
-            &pData,            // packet which is ready to be read by used
-            &framesAvailable,  // #frames in the captured packet (can be zero)
-            &flags,            // support flags (check)
-            &recPos,    // device position of first audio frame in data packet
-            &recTime);  // value of performance counter at the time of recording
-                        // the first audio frame
-
-        if (SUCCEEDED(hr)) {
-          if (AUDCLNT_S_BUFFER_EMPTY == hr) {
-            // Buffer was empty => start waiting for a new capture notification
-            // event
-            break;
-          }
-
-          if (flags & AUDCLNT_BUFFERFLAGS_SILENT) {
-            // Treat all of the data in the packet as silence and ignore the
-            // actual data values.
-            RTC_LOG(LS_WARNING) << "AUDCLNT_BUFFERFLAGS_SILENT";
-            pData = nullptr;
-          }
-
-          assert(framesAvailable != 0);
-
-          if (pData) {
-            CopyMemory(&syncBuffer[syncBufIndex * _audioFrameSize], pData,
-                       framesAvailable * _audioFrameSize);
-          } else {
-            ZeroMemory(&syncBuffer[syncBufIndex * _audioFrameSize],
-                       framesAvailable * _audioFrameSize);
-          }
-          assert(syncBufferSize >= (syncBufIndex * _audioFrameSize) +
-                                       framesAvailable * _audioFrameSize);
-
-          // Release the capture buffer
-          //
-          hr = _audioCaptureClient->ReleaseBuffer(framesAvailable);
-          EXIT_ON_ERROR(hr);
-
-          _samples += framesAvailable;
-          syncBufIndex += framesAvailable;
-
-          QueryPerformanceCounter(&t1);
-
-          // Get the current recording and playout delay.
-          uint32_t sndCardRecDelay = (uint32_t)(
-              ((((UINT64)t1.QuadPart * _perfCounterFactor) - recTime) / 10000) +
-              (10 * syncBufIndex) / _blockSize - 10);
-          uint32_t sndCardPlayDelay = *_sndCardDelay;
-
-          while (syncBufIndex >= _blockSize) {
-            if (_pAudioBuffer) {
-              _pAudioBuffer->SetRecordedBuffer((const int8_t*)syncBuffer,
-                                               _blockSize);
-              _pAudioBuffer->SetVQEData(sndCardPlayDelay, sndCardRecDelay);
-
-              _pAudioBuffer->SetTypingStatus(false);
-
-              _pAudioBuffer->DeliverRecordedData();
-
-              // Sanity check to ensure that essential states are not modified
-              // during the unlocked period
-              if (_audioCaptureClient == nullptr || _audioClient == nullptr) {
-                RTC_LOG(LS_ERROR) << "input state has been modified during"
-                                  << " unlocked period";
-                goto Exit;
-              }
-            }
-
-            // store remaining data which was not able to deliver as 10ms
-            // segment
-            MoveMemory(&syncBuffer[0],
-                       &syncBuffer[_blockSize * _audioFrameSize],
-                       (syncBufIndex - _blockSize) * _audioFrameSize);
-            syncBufIndex -= _blockSize;
-            sndCardRecDelay -= 10;
-          }
-        } else {
-          // If GetBuffer returns AUDCLNT_E_BUFFER_ERROR, the thread consuming
-          // the audio samples must wait for the next processing pass. The
-          // client might benefit from keeping a count of the failed GetBuffer
-          // calls. If GetBuffer returns this error repeatedly, the client can
-          // start a new processing loop after shutting down the current client
-          // by calling IAudioClient::Stop, IAudioClient::Reset, and releasing
-          // the audio client.
-          RTC_LOG(LS_ERROR)
-              << "IAudioCaptureClient::GetBuffer returned"
-              << " AUDCLNT_E_BUFFER_ERROR, hr = 0x" << rtc::ToHex(hr);
-          goto Exit;
-        }
-      }
-    }
-
-    // ---------------------------- THREAD LOOP ---------------------------- <<
-
-    if (_audioClient) {
-      hr = _audioClient->Stop();
-    }
-
-  Exit:
-    if (FAILED(hr)) {
-      _audioClient->Stop();
-      _TraceCOMError(hr);
-    }
-
-    if (keepRecording) {
-      rtc::CritScope lock(_critSect);
-
-      if (_audioClient != nullptr) {
-        hr = _audioClient->Stop();
-        if (FAILED(hr)) {
-          _TraceCOMError(hr);
-        }
-        hr = _audioClient->Reset();
-        if (FAILED(hr)) {
-          _TraceCOMError(hr);
-        }
-      }
-
-      RTC_LOG(LS_ERROR)
-          << "Recording error: capturing thread has ended pre-maturely";
-    } else {
-      RTC_LOG(LS_VERBOSE) << "_Capturing thread is now terminated properly";
-    }
-
-    if (syncBuffer) {
-      delete[] syncBuffer;
-    }
-
-    return (DWORD)hr;
-  }
-
-  int32_t InitTransport() override {
-    if (Transporting()) {
-      return -1;
-    }
-
-    if (TransportIsInitialized()) {
-      return 0;
-    }
-
-    if (QueryPerformanceFrequency(&_perfCounterFreq) == 0) {
-      return -1;
-    }
-    _perfCounterFactor = 10000000.0 / (double)_perfCounterFreq.QuadPart;
-
-    if (GetDevice() == nullptr) {
-      return -1;
-    }
-
-    // Initialize the microphone (devices might have been added or removed)
-    if (InitMixer() == -1) {
-      RTC_LOG(LS_WARNING) << "InitMixer() failed";
-    }
-
-    // Ensure that the updated capturing endpoint device is valid
-    if (GetDevice() == nullptr) {
-      return -1;
-    }
-
-    HRESULT hr = S_OK;
-    WAVEFORMATEX* pWfxIn = nullptr;
-    WAVEFORMATEXTENSIBLE Wfx = WAVEFORMATEXTENSIBLE();
-    WAVEFORMATEX* pWfxClosestMatch = nullptr;
-
-    // Retrieve the stream format that the audio engine uses for its internal
-    // processing (mixing) of shared-mode streams.
-    hr = _audioClient->GetMixFormat(&pWfxIn);
-    if (SUCCEEDED(hr)) {
-      RTC_LOG(LS_VERBOSE) << "Audio Engine's current capturing mix format:";
-      // format type
-      RTC_LOG(LS_VERBOSE) << "wFormatTag     : 0x"
-                          << rtc::ToHex(pWfxIn->wFormatTag) << " ("
-                          << pWfxIn->wFormatTag << ")";
-      // number of channels (i.e. mono, stereo...)
-      RTC_LOG(LS_VERBOSE) << "nChannels      : " << pWfxIn->nChannels;
-      // sample rate
-      RTC_LOG(LS_VERBOSE) << "nSamplesPerSec : " << pWfxIn->nSamplesPerSec;
-      // for buffer estimation
-      RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec: " << pWfxIn->nAvgBytesPerSec;
-      // block size of data
-      RTC_LOG(LS_VERBOSE) << "nBlockAlign    : " << pWfxIn->nBlockAlign;
-      // number of bits per sample of mono data
-      RTC_LOG(LS_VERBOSE) << "wBitsPerSample : " << pWfxIn->wBitsPerSample;
-      RTC_LOG(LS_VERBOSE) << "cbSize         : " << pWfxIn->cbSize;
-    }
-
-    // Set wave format
-    Wfx.Format.wFormatTag = WAVE_FORMAT_EXTENSIBLE;
-    Wfx.Format.wBitsPerSample = 16;
-    Wfx.Format.cbSize = 22;
-    Wfx.dwChannelMask = 0;
-    Wfx.Samples.wValidBitsPerSample = Wfx.Format.wBitsPerSample;
-    Wfx.SubFormat = KSDATAFORMAT_SUBTYPE_PCM;
-
-    const int freqs[6] = {48000, 44100, 16000, 96000, 32000, 8000};
-    hr = S_FALSE;
-
-    // Iterate over frequencies and channels, in order of priority
-    for (unsigned int freq = 0; freq < sizeof(freqs) / sizeof(freqs[0]);
-         freq++) {
-      for (unsigned int chan = 0;
-           chan < sizeof(_channelsPrioList) / sizeof(_channelsPrioList[0]);
-           chan++) {
-        Wfx.Format.nChannels = _channelsPrioList[chan];
-        Wfx.Format.nSamplesPerSec = freqs[freq];
-        Wfx.Format.nBlockAlign =
-            Wfx.Format.nChannels * Wfx.Format.wBitsPerSample / 8;
-        Wfx.Format.nAvgBytesPerSec =
-            Wfx.Format.nSamplesPerSec * Wfx.Format.nBlockAlign;
-        // If the method succeeds and the audio endpoint device supports the
-        // specified stream format, it returns S_OK. If the method succeeds and
-        // provides a closest match to the specified format, it returns S_FALSE.
-        hr = _audioClient->IsFormatSupported(
-            AUDCLNT_SHAREMODE_SHARED, (WAVEFORMATEX*)&Wfx, &pWfxClosestMatch);
-        if (hr == S_OK) {
-          break;
-        } else {
-          if (pWfxClosestMatch) {
-            RTC_LOG(INFO) << "nChannels=" << Wfx.Format.nChannels
-                          << ", nSamplesPerSec=" << Wfx.Format.nSamplesPerSec
-                          << " is not supported. Closest match: "
-                          << "nChannels=" << pWfxClosestMatch->nChannels
-                          << ", nSamplesPerSec="
-                          << pWfxClosestMatch->nSamplesPerSec;
-            CoTaskMemFree(pWfxClosestMatch);
-            pWfxClosestMatch = nullptr;
-          } else {
-            RTC_LOG(INFO) << "nChannels=" << Wfx.Format.nChannels
-                          << ", nSamplesPerSec=" << Wfx.Format.nSamplesPerSec
-                          << " is not supported. No closest match.";
-          }
-        }
-      }
-      if (hr == S_OK)
-        break;
-    }
-
-    if (hr == S_OK) {
-      _audioFrameSize = Wfx.Format.nBlockAlign;
-      _sampleRate = Wfx.Format.nSamplesPerSec;
-      _blockSize = Wfx.Format.nSamplesPerSec / 100;
-      _channels = Wfx.Format.nChannels;
-
-      RTC_LOG(LS_VERBOSE) << "VoE selected this capturing format:";
-      RTC_LOG(LS_VERBOSE) << "wFormatTag        : 0x"
-                          << rtc::ToHex(Wfx.Format.wFormatTag) << " ("
-                          << Wfx.Format.wFormatTag << ")";
-      RTC_LOG(LS_VERBOSE) << "nChannels         : " << Wfx.Format.nChannels;
-      RTC_LOG(LS_VERBOSE) << "nSamplesPerSec    : "
-                          << Wfx.Format.nSamplesPerSec;
-      RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec   : "
-                          << Wfx.Format.nAvgBytesPerSec;
-      RTC_LOG(LS_VERBOSE) << "nBlockAlign       : " << Wfx.Format.nBlockAlign;
-      RTC_LOG(LS_VERBOSE) << "wBitsPerSample    : "
-                          << Wfx.Format.wBitsPerSample;
-      RTC_LOG(LS_VERBOSE) << "cbSize            : " << Wfx.Format.cbSize;
-      RTC_LOG(LS_VERBOSE) << "Additional settings:";
-      RTC_LOG(LS_VERBOSE) << "_recAudioFrameSize: " << _audioFrameSize;
-      RTC_LOG(LS_VERBOSE) << "_recBlockSize     : " << _blockSize;
-      RTC_LOG(LS_VERBOSE) << "_recChannels      : " << _channels;
-    }
-
-    // Create a capturing stream.
-    hr = _audioClient->Initialize(
-        AUDCLNT_SHAREMODE_SHARED,  // share Audio Engine with other applications
-        AUDCLNT_STREAMFLAGS_EVENTCALLBACK |  // processing of the audio buffer
-                                             // by the client will be event
-                                             // driven
-            AUDCLNT_STREAMFLAGS_NOPERSIST,   // volume and mute settings for an
-                                             // audio session will not persist
-                                             // across system restarts
-        0,                    // required for event-driven shared mode
-        0,                    // periodicity
-        (WAVEFORMATEX*)&Wfx,  // selected wave format
-        nullptr);             // session GUID
-
-    if (hr != S_OK) {
-      RTC_LOG(LS_ERROR) << "IAudioClient::Initialize() failed:";
-    }
-    EXIT_ON_ERROR(hr);
-
-    if (_pAudioBuffer) {
-      // Update the audio buffer with the selected parameters
-      _pAudioBuffer->SetRecordingSampleRate(_sampleRate);
-      _pAudioBuffer->SetRecordingChannels((uint8_t)_channels);
-    } else {
-      // We can enter this state during CoreAudioIsSupported() when no
-      // AudioDeviceImplementation has been created, hence the AudioDeviceBuffer
-      // does not exist. It is OK to end up here since we don't initiate any
-      // media in CoreAudioIsSupported().
-      RTC_LOG(LS_VERBOSE)
-          << "AudioDeviceBuffer must be attached before streaming can start";
-    }
-
-    // Get the actual size of the shared (endpoint buffer).
-    // Typical value is 960 audio frames <=> 20ms @ 48kHz sample rate.
-    UINT bufferFrameCount(0);
-    hr = _audioClient->GetBufferSize(&bufferFrameCount);
-    if (SUCCEEDED(hr)) {
-      RTC_LOG(LS_VERBOSE) << "IAudioClient::GetBufferSize() => "
-                          << bufferFrameCount << " (<=> "
-                          << bufferFrameCount * _audioFrameSize << " bytes)";
-    }
-
-    // Set the event handle that the system signals when an audio buffer is
-    // ready to be processed by the client.
-    hr = _audioClient->SetEventHandle(_hSamplesReadyEvent);
-    EXIT_ON_ERROR(hr);
-
-    // Get an IAudioCaptureClient interface.
-    hr = _audioClient->GetService(__uuidof(IAudioCaptureClient),
-                                  (void**)&_audioCaptureClient);
-    EXIT_ON_ERROR(hr);
-
-    // Mark capture side as initialized
-    _transportInitialized = true;
-
-    CoTaskMemFree(pWfxIn);
-    CoTaskMemFree(pWfxClosestMatch);
-
-    RTC_LOG(LS_VERBOSE) << "capture side is now initialized";
-    return 0;
+// template <winrt::Windows::Devices::Enumeration::DeviceClass DEVICE_CLASS>
+// struct DeviceHelper {
+//  protected:
+//   winrt::Windows::Devices::Enumeration::DeviceInformation _deviceInformation =
+//       nullptr;
+
+//   bool _usingDeviceIndex = false;
+//   uint16_t _deviceIndex = -1;
+//   webrtc::AudioDeviceModule::WindowsDeviceType _deviceType =
+//       static_cast<webrtc::AudioDeviceModule::WindowsDeviceType>(0);
+
+//  public:
+//   //
+//   // Device enumeration
+//   //
+
+//   int16_t Devices() {
+//     auto deviceInformationFindAllAsync =
+//         winrt::Windows::Devices::Enumeration::DeviceInformation::FindAllAsync(
+//             DEVICE_CLASS);
+//     blocking_suspend(deviceInformationFindAllAsync);
+//     if (deviceInformationFindAllAsync.Status() ==
+//         winrt::Windows::Foundation::AsyncStatus::Error) {
+//       return -1;
+//     }
+
+//     winrt::Windows::Devices::Enumeration::DeviceInformationCollection
+//         deviceInformationCollection =
+//             deviceInformationFindAllAsync.GetResults();
+//     return deviceInformationCollection.Size();
+//   }
+
+//   int32_t DeviceName(uint16_t index,
+//                      char name[webrtc::kAdmMaxDeviceNameSize],
+//                      char guid[webrtc::kAdmMaxGuidSize]) {
+//     auto deviceInformationFindAllAsync =
+//         winrt::Windows::Devices::Enumeration::DeviceInformation::FindAllAsync(
+//             DEVICE_CLASS);
+//     blocking_suspend(deviceInformationFindAllAsync);
+//     if (deviceInformationFindAllAsync.Status() ==
+//         winrt::Windows::Foundation::AsyncStatus::Error) {
+//       return -1;
+//     }
+
+//     winrt::Windows::Devices::Enumeration::DeviceInformationCollection
+//         deviceInformationCollection =
+//             deviceInformationFindAllAsync.GetResults();
+
+//     // Special fix for the case when the user selects '-1' as index (<=> Default
+//     // Communication Device)
+//     if (index == (uint16_t)(-1)) {
+//       index = 0;
+//       RTC_LOG(LS_VERBOSE)
+//           << "Default Communication endpoint device will be used";
+//     }
+
+//     if (index >= deviceInformationCollection.Size()) {
+//       return -1;
+//     }
+
+//     winrt::Windows::Devices::Enumeration::DeviceInformation deviceInformation =
+//         deviceInformationCollection.GetAt(index);
+
+//     if (name != nullptr) {
+//       std::wstring deviceInformationName = deviceInformation.Name().c_str();
+//       std::string nameUFT8 = rtc::ToUtf8(deviceInformationName);
+//       size_t length =
+//           std::min(nameUFT8.size(),
+//                    static_cast<size_t>(webrtc::kAdmMaxDeviceNameSize - 1));
+//       std::copy_n(nameUFT8.begin(), length, guid);
+//       name[length] = '\0';
+//     }
+
+//     if (guid != nullptr) {
+//       std::wstring deviceInformationId = deviceInformation.Id().c_str();
+//       std::string idUFT8 = rtc::ToUtf8(deviceInformationId);
+//       size_t length = std::min(
+//           idUFT8.size(), static_cast<size_t>(webrtc::kAdmMaxGuidSize - 1));
+//       std::copy_n(idUFT8.begin(), length, guid);
+//       guid[length] = '\0';
+//     }
+
+//     return 0;
+//   }
+
+//   //
+//   // Device selection
+//   //
+
+//   int32_t SetDevice(uint16_t index) {
+//     auto deviceInformationFindAllAsync =
+//         winrt::Windows::Devices::Enumeration::DeviceInformation::FindAllAsync(
+//             DEVICE_CLASS);
+//     blocking_suspend(deviceInformationFindAllAsync);
+//     if (deviceInformationFindAllAsync.Status() ==
+//         winrt::Windows::Foundation::AsyncStatus::Error) {
+//       return -1;
+//     }
+
+//     winrt::Windows::Devices::Enumeration::DeviceInformationCollection
+//         captureDevices = deviceInformationFindAllAsync.GetResults();
+
+//     // Special fix for the case when the user selects '-1' as index (<=> Default
+//     // Communication Device)
+//     if (index == (uint16_t)(-1)) {
+//       index = 0;
+//       RTC_LOG(LS_VERBOSE)
+//           << "Default Communication endpoint device will be used";
+//     }
+
+//     if (index >= captureDevices.Size()) {
+//       return -1;
+//     }
+
+//     _deviceInformation = captureDevices.GetAt(index);
+
+//     _deviceIndex = index;
+//     _usingDeviceIndex = true;
+
+//     return 0;
+//   }
+
+//   int32_t SetDevice(
+//       webrtc::AudioDeviceModule::WindowsDeviceType windowsDeviceType) {
+//     winrt::Windows::Media::Devices::AudioDeviceRole audioDeviceRole;
+//     switch (windowsDeviceType) {
+//       case webrtc::AudioDeviceModule::kDefaultCommunicationDevice:
+//         audioDeviceRole =
+//             winrt::Windows::Media::Devices::AudioDeviceRole::Communications;
+//         break;
+
+//       case webrtc::AudioDeviceModule::kDefaultDevice:
+//         audioDeviceRole =
+//             winrt::Windows::Media::Devices::AudioDeviceRole::Default;
+//         break;
+
+//       default:
+//         return -1;
+//     }
+
+//     winrt::hstring audioDeviceId;
+//     switch (DEVICE_CLASS) {
+//       case winrt::Windows::Devices::Enumeration::DeviceClass::AudioCapture:
+//         audioDeviceId = winrt::Windows::Media::Devices::MediaDevice::
+//             GetDefaultAudioCaptureId(audioDeviceRole);
+//         break;
+
+//       case winrt::Windows::Devices::Enumeration::DeviceClass::AudioRender:
+//         audioDeviceId = winrt::Windows::Media::Devices::MediaDevice::
+//             GetDefaultAudioRenderId(audioDeviceRole);
+//         break;
+
+//       default:
+//         return -1;
+//     }
+//     if (audioDeviceId.empty()) {
+//       return -1;
+//     }
+
+//     auto deviceInformationCreateFromIdAsync = winrt::Windows::Devices::
+//         Enumeration::DeviceInformation::CreateFromIdAsync(audioDeviceId);
+//     blocking_suspend(deviceInformationCreateFromIdAsync);
+//     if (deviceInformationCreateFromIdAsync.Status() ==
+//         winrt::Windows::Foundation::AsyncStatus::Error) {
+//       return -1;
+//     }
+
+//     _deviceInformation = deviceInformationCreateFromIdAsync.GetResults();
+
+//     _deviceType = windowsDeviceType;
+//     _usingDeviceIndex = false;
+
+//     return 0;
+//   }
+
+//   virtual winrt::Windows::Devices::Enumeration::DeviceInformation GetDevice()
+//       final {
+//     return _deviceInformation;
+//   }
+// };
+
+// template <winrt::Windows::Devices::Enumeration::DeviceClass DEVICE_CLASS>
+// struct AudioDeviceHelper : public DeviceHelper<DEVICE_CLASS> {
+//  protected:
+//   webrtc::AudioDeviceBuffer* _pAudioBuffer = nullptr;
+
+//   bool _mixerInitialized = false;
+//   bool _transportInitialized = false;
+//   bool _transporting = false;
+
+//   UINT _audioFrameSize = 0;
+//   uint32_t _sampleRate = 0;
+//   uint32_t _blockSize = 0;
+//   uint32_t _channels = 2;
+//   UINT64 _samples = 0;
+
+//   HANDLE _hSamplesReadyEvent = CreateEvent(nullptr, FALSE, FALSE, nullptr);
+//   HANDLE _hStartedEvent = CreateEvent(nullptr, FALSE, FALSE, nullptr);
+//   HANDLE _hShutdownEvent = CreateEvent(nullptr, FALSE, FALSE, nullptr);
+//   HANDLE _hThread = nullptr;
+
+//   Microsoft::WRL::ComPtr<IAudioClient2> _audioClient;
+//   Microsoft::WRL::ComPtr<ISimpleAudioVolume> _simpleAudioVolume;
+
+//   static DWORD WINAPI WSAPIThread(LPVOID context) {
+//     return reinterpret_cast<AudioDeviceHelper*>(context)->Transport();
+//   }
+
+//  public:
+//   virtual ~AudioDeviceHelper() {
+//     CloseHandle(_hSamplesReadyEvent);
+//     CloseHandle(_hThread);
+//     CloseHandle(_hStartedEvent);
+//     CloseHandle(_hShutdownEvent);
+//   }
+
+//   virtual void AttachAudioBuffer(webrtc::AudioDeviceBuffer* audioBuffer) {
+//     _pAudioBuffer = audioBuffer;
+//   }
+
+//   virtual DWORD Transport() = 0;
+
+//   //
+//   // Audio mixer initialization
+//   //
+
+//   virtual int32_t InitMixer() {
+//     if (MixerIsInitialized()) {
+//       return 0;
+//     }
+
+//     if (Transporting() || GetDevice() == nullptr) {
+//       return -1;
+//     }
+
+//     if (_usingDeviceIndex) {
+//       int16_t nDevices = Devices();
+//       if (_deviceIndex > (nDevices - 1)) {
+//         RTC_LOG(LS_ERROR) << "current device selection is invalid => unable to"
+//                           << " initialize";
+//         return -1;
+//       }
+//     }
+
+//     int32_t ret;
+//     if (_usingDeviceIndex) {
+//       ret = SetDevice(_deviceIndex);
+//     } else {
+//       ret = SetDevice(_deviceType);
+//     }
+//     if (ret != 0) {
+//       RTC_LOG(LS_ERROR) << "failed to initialize the enpoint device";
+//       return -1;
+//     }
+
+//     Microsoft::WRL::ComPtr<CCompletionDelegate> completionDelegate =
+//         Microsoft::WRL::Make<CCompletionDelegate>();
+//     {
+//       Microsoft::WRL::ComPtr<IActivateAudioInterfaceAsyncOperation> asyncOp;
+//       HRESULT hr = ActivateAudioInterfaceAsync(
+//           GetDevice().Id().c_str(), __uuidof(IAudioClient2), nullptr,
+//           completionDelegate.Get(), &asyncOp);
+//       if (FAILED(hr)) {
+//         return -1;
+//       }
+//     }
+
+//     {
+//       HRESULT hr = completionDelegate->Wait(INFINITE);
+//       if (FAILED(hr)) {
+//         return -1;
+//       }
+//     }
+
+//     Microsoft::WRL::ComPtr<IUnknown> punkAudioInterface;
+//     {
+//       HRESULT hr = completionDelegate->GetActivateResult(&punkAudioInterface);
+//       if (FAILED(hr)) {
+//         return -1;
+//       }
+//     }
+
+//     {
+//       HRESULT hr =
+//           punkAudioInterface->QueryInterface(IID_PPV_ARGS(&_audioClient));
+//       if (FAILED(hr)) {
+//         return -1;
+//       }
+//     }
+
+//     {
+//       AudioClientProperties properties = {};
+//       properties.cbSize = sizeof AudioClientProperties;
+//       properties.eCategory = AudioCategory_Communications;
+
+//       HRESULT hr = _audioClient->SetClientProperties(&properties);
+//       if (FAILED(hr)) {
+//         return -1;
+//       }
+//     }
+
+//     _mixerInitialized = true;
+//     return 0;
+//   }
+
+//   virtual bool MixerIsInitialized() const final { return _mixerInitialized; }
+
+//   //
+//   // Audio transport initialization
+//   //
+
+//   virtual int32_t TransportIsAvailable(bool& available) { return true; }
+
+//   virtual int32_t InitTransport() = 0;
+
+//   virtual bool TransportIsInitialized() const final {
+//     return _transportInitialized;
+//   }
+
+//   //
+//   // Audio transport control
+//   //
+
+//   virtual int32_t StartTransport() {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
+
+//     if (_hThread != nullptr) {
+//       return 0;
+//     }
+
+//     if (Transporting()) {
+//       return 0;
+//     }
+
+//     assert(_hThread == nullptr);
+//     _hThread = CreateThread(nullptr, 0, WSAPIThread, this, 0, nullptr);
+//     if (_hThread == nullptr) {
+//       RTC_LOG(LS_ERROR) << "failed to create the thread";
+//       return -1;
+//     }
+
+//     // Set thread priority to highest possible
+//     SetThreadPriority(_hThread, THREAD_PRIORITY_TIME_CRITICAL);
+
+//     DWORD ret = WaitForSingleObject(_hStartedEvent, 1000);
+//     if (ret != WAIT_OBJECT_0) {
+//       RTC_LOG(LS_VERBOSE) << "did not start up properly";
+
+//       // Stop transport thread and clean up
+//       _transporting = true;
+//       StopTransport();
+
+//       return -1;
+//     }
+//     RTC_LOG(LS_VERBOSE) << "audio stream has now started...";
+
+//     _transporting = true;
+
+//     return 0;
+//   }
+
+//   virtual int32_t StopTransport() {
+//     if (!Transporting()) {
+//       return 0;
+//     }
+
+//     if (_hThread == nullptr) {
+//       RTC_LOG(LS_VERBOSE)
+//           << "no rendering stream is active => close down WASAPI only";
+//       _transportInitialized = false;
+//       _transporting = false;
+//       return 0;
+//     }
+
+//     // stop the driving thread...
+//     RTC_LOG(LS_VERBOSE) << "closing down the webrtc_core_audio_thread...";
+//     SetEvent(_hShutdownEvent);
+
+//     DWORD ret = WaitForSingleObject(_hThread, 2000);
+//     if (ret != WAIT_OBJECT_0) {
+//       // the thread did not stop as it should
+//       RTC_LOG(LS_ERROR) << "failed to close down webrtc_core_audio_thread";
+//       CloseHandle(_hThread);
+//       _hThread = nullptr;
+//       _transportInitialized = false;
+//       _transporting = false;
+//       return -1;
+//     }
+
+//     RTC_LOG(LS_VERBOSE) << "webrtc_core_audio_thread is now closed";
 
-  Exit:
-    _TraceCOMError(hr);
-    CoTaskMemFree(pWfxIn);
-    CoTaskMemFree(pWfxClosestMatch);
-    return -1;
-  }
-
-  int32_t SetStereo(bool enable) override {
-    if (!MixerIsInitialized()) {
-      return -1;
-    }
-
-    if (enable) {
-      _channelsPrioList[0] = 2;  // try stereo first
-      _channelsPrioList[1] = 1;
-      _channels = 2;
-    } else {
-      _channelsPrioList[0] = 1;  // try mono first
-      _channelsPrioList[1] = 2;
-      _channels = 1;
-    }
-
-    return 0;
-  }
-};
-
-struct RenderDeviceInternal
-    : public AudioDeviceHelper<
-          winrt::Windows::Devices::Enumeration::DeviceClass::AudioRender> {
- protected:
-  const rtc::CriticalSection* _critSect;
-
-  Microsoft::WRL::ComPtr<IAudioRenderClient> _audioRenderClient;
-
-  uint32_t _deviceSampleRate;
-  uint32_t _deviceBlockSize;
-
-  uint16_t _channelsPrioList[2];
-
- public:
-  uint32_t _sndCardDelay;
-
-  RenderDeviceInternal(rtc::CriticalSection* critSect) : _critSect(critSect) {
-    // list of number of channels to use on recording side
-    _channelsPrioList[0] = 2;  // stereo is prio 1
-    _channelsPrioList[1] = 1;  // mono is prio 2
-  }
-
-  void AttachAudioBuffer(webrtc::AudioDeviceBuffer* audioBuffer) override {
-    AudioDeviceHelper::AttachAudioBuffer(audioBuffer);
-    audioBuffer->SetPlayoutSampleRate(0);
-    audioBuffer->SetPlayoutChannels(0);
-  }
-
-  DWORD Transport() override {
-    bool keepPlaying = true;
-    HANDLE waitArray[2] = {_hShutdownEvent, _hSamplesReadyEvent};
-    HRESULT hr = S_OK;
-
-    // Initialize COM as MTA in this thread.
-    Microsoft::WRL::Wrappers::RoInitializeWrapper roInitializeWrapper(
-        RO_INIT_MULTITHREADED);
-    if (FAILED(roInitializeWrapper)) {
-      RTC_LOG(LS_ERROR) << "failed to initialize COM in render thread";
-      return 1;
-    }
-
-    rtc::SetCurrentThreadName("webrtc_core_audio_render_thread");
-
-    IAudioClock* clock = nullptr;
-
-    // Get size of rendering buffer (length is expressed as the number of audio
-    // frames the buffer can hold). This value is fixed during the rendering
-    // session.
-    //
-    UINT32 bufferLength = 0;
-    hr = _audioClient->GetBufferSize(&bufferLength);
-    EXIT_ON_ERROR(hr);
-    RTC_LOG(LS_VERBOSE) << "[REND] size of buffer       : " << bufferLength;
-
-    // Get maximum latency for the current stream (will not change for the
-    // lifetime  of the IAudioClient object).
-    //
-    REFERENCE_TIME latency;
-    _audioClient->GetStreamLatency(&latency);
-    RTC_LOG(LS_VERBOSE) << "[REND] max stream latency   : " << (DWORD)latency
-                        << " (" << (double)(latency / 10000.0) << " ms)";
-
-    // Get the length of the periodic interval separating successive processing
-    // passes by the audio engine on the data in the endpoint buffer.
-    //
-    // The period between processing passes by the audio engine is fixed for a
-    // particular audio endpoint device and represents the smallest processing
-    // quantum for the audio engine. This period plus the stream latency between
-    // the buffer and endpoint device represents the minimum possible latency
-    // that an audio application can achieve. Typical value: 100000 <=> 0.01 sec
-    // = 10ms.
-    //
-    REFERENCE_TIME devPeriod = 0;
-    REFERENCE_TIME devPeriodMin = 0;
-    _audioClient->GetDevicePeriod(&devPeriod, &devPeriodMin);
-    RTC_LOG(LS_VERBOSE) << "[REND] device period        : " << (DWORD)devPeriod
-                        << " (" << (double)(devPeriod / 10000.0) << " ms)";
-
-    // Derive initial rendering delay.
-    // Example: 10*(960/480) + 15 = 20 + 15 = 35ms
-    //
-    int playout_delay =
-        10 * (bufferLength / _blockSize) + (int)((latency + devPeriod) / 10000);
-    _sndCardDelay = playout_delay;
-    _samples = 0;
-    RTC_LOG(LS_VERBOSE) << "[REND] initial delay        : " << playout_delay;
-
-    double endpointBufferSizeMS =
-        10.0 * ((double)bufferLength / (double)_deviceBlockSize);
-    RTC_LOG(LS_VERBOSE) << "[REND] endpointBufferSizeMS : "
-                        << endpointBufferSizeMS;
-
-    // Before starting the stream, fill the rendering buffer with silence.
-    //
-    BYTE* pData = nullptr;
-    hr = _audioRenderClient->GetBuffer(bufferLength, &pData);
-    EXIT_ON_ERROR(hr);
-
-    hr = _audioRenderClient->ReleaseBuffer(bufferLength,
-                                           AUDCLNT_BUFFERFLAGS_SILENT);
-    EXIT_ON_ERROR(hr);
-
-    _samples += bufferLength;
-
-    hr = _audioClient->GetService(__uuidof(IAudioClock), (void**)&clock);
-    if (FAILED(hr)) {
-      RTC_LOG(LS_WARNING)
-          << "failed to get IAudioClock interface from the IAudioClient";
-    }
+//     // to reset this event manually at each time we finish with it,
+//     // in case that the render thread has exited before StopPlayout(),
+//     // this event might be caught by the new render thread within same VoE
+//     // instance.
+//     ResetEvent(_hShutdownEvent);
 
-    // Start up the rendering audio stream.
-    hr = _audioClient->Start();
-    EXIT_ON_ERROR(hr);
-
-    // Set event which will ensure that the calling thread modifies the playing
-    // state to true.
-    //
-    SetEvent(_hStartedEvent);
-
-    // >> ------------------ THREAD LOOP ------------------
-
-    while (keepPlaying) {
-      // Wait for a render notification event or a shutdown event
-      DWORD waitResult = WaitForMultipleObjects(2, waitArray, FALSE, 500);
-      switch (waitResult) {
-        case WAIT_OBJECT_0 + 0:  // _hShutdownRenderEvent
-          keepPlaying = false;
-          break;
-        case WAIT_OBJECT_0 + 1:  // _hRenderSamplesReadyEvent
-          break;
-        case WAIT_TIMEOUT:  // timeout notification
-          RTC_LOG(LS_WARNING) << "render event timed out after 0.5 seconds";
-          goto Exit;
-        default:  // unexpected error
-          RTC_LOG(LS_WARNING) << "unknown wait termination on render side";
-          goto Exit;
-      }
-
-      while (keepPlaying) {
-        rtc::CritScope lock(_critSect);
-
-        // Sanity check to ensure that essential states are not modified
-        // during the unlocked period.
-        if (_audioRenderClient == nullptr || _audioClient == nullptr) {
-          RTC_LOG(LS_ERROR)
-              << "output state has been modified during unlocked period";
-          goto Exit;
-        }
-
-        // Get the number of frames of padding (queued up to play) in the
-        // endpoint buffer.
-        UINT32 padding = 0;
-        hr = _audioClient->GetCurrentPadding(&padding);
-        EXIT_ON_ERROR(hr);
-
-        // Derive the amount of available space in the output buffer
-        uint32_t framesAvailable = bufferLength - padding;
-
-        // Do we have 10 ms available in the render buffer?
-        if (framesAvailable < _blockSize) {
-          // Not enough space in render buffer to store next render packet.
-          break;
-        }
-
-        // Write n*10ms buffers to the render buffer
-        const uint32_t n10msBuffers = (framesAvailable / _blockSize);
-        for (uint32_t n = 0; n < n10msBuffers; n++) {
-          // Get pointer (i.e., grab the buffer) to next space in the shared
-          // render buffer.
-          hr = _audioRenderClient->GetBuffer(_blockSize, &pData);
-          EXIT_ON_ERROR(hr);
-
-          if (_pAudioBuffer) {
-            // Request data to be played out (#bytes =
-            // _playBlockSize*_audioFrameSize)
-            int32_t nSamples = _pAudioBuffer->RequestPlayoutData(_blockSize);
-
-            if (nSamples == -1) {
-              RTC_LOG(LS_ERROR) << "failed to read data from render client";
-              goto Exit;
-            }
-
-            // Sanity check to ensure that essential states are not modified
-            // during the unlocked period
-            if (_audioRenderClient == nullptr || _audioClient == nullptr) {
-              RTC_LOG(LS_ERROR)
-                  << "output state has been modified during unlocked"
-                  << " period";
-              goto Exit;
-            }
-            if (nSamples != static_cast<int32_t>(_blockSize)) {
-              RTC_LOG(LS_WARNING) << "nSamples(" << nSamples
-                                  << ") != _playBlockSize" << _blockSize << ")";
-            }
-
-            // Get the actual (stored) data
-            nSamples = _pAudioBuffer->GetPlayoutData((int8_t*)pData);
-          }
-
-          DWORD dwFlags(0);
-          hr = _audioRenderClient->ReleaseBuffer(_blockSize, dwFlags);
-          // See http://msdn.microsoft.com/en-us/library/dd316605(VS.85).aspx
-          // for more details regarding AUDCLNT_E_DEVICE_INVALIDATED.
-          EXIT_ON_ERROR(hr);
-
-          _samples += _blockSize;
-        }
-
-        // Check the current delay on the playout side.
-        if (clock) {
-          UINT64 pos = 0;
-          UINT64 freq = 1;
-          clock->GetPosition(&pos, nullptr);
-          clock->GetFrequency(&freq);
-          playout_delay = round(
-              (double(_samples) / _deviceSampleRate - double(pos) / freq) *
-              1000.0);
-          _sndCardDelay = playout_delay;
-        }
-      }
-    }
+//     _transportInitialized = false;
+//     _transporting = false;
 
-    // ------------------ THREAD LOOP ------------------ <<
+//     CloseHandle(_hThread);
+//     _hThread = nullptr;
 
-    webrtc::SleepMs(static_cast<DWORD>(endpointBufferSizeMS + 0.5));
-    hr = _audioClient->Stop();
+//     return 0;
+//   }
+
+//   virtual bool Transporting() const final { return _transporting; }
 
-  Exit:
-    if (clock != nullptr) {
-      clock->Release();
-      clock = nullptr;
-    }
-
-    if (FAILED(hr)) {
-      _audioClient->Stop();
-      _TraceCOMError(hr);
-    }
+//   //
+//   // Speaker volume controls
+//   //
+
+//   virtual int32_t VolumeIsAvailable(bool& available) const {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
+
+//     float volume;
+//     HRESULT hr = _simpleAudioVolume->GetMasterVolume(&volume);
+//     available = SUCCEEDED(hr);
+
+//     return 0;
+//   }
+
+//   virtual int32_t SetVolume(uint32_t volume) {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
+
+//     if (volume < MIN_CORE_SPEAKER_VOLUME || volume > MAX_CORE_SPEAKER_VOLUME) {
+//       return -1;
+//     }
+
+//     const float fLevel = volume / static_cast<float>(MAX_CORE_SPEAKER_VOLUME);
+//     HRESULT hr = _simpleAudioVolume->SetMasterVolume(fLevel, nullptr);
+//     if (FAILED(hr)) {
+//       return -1;
+//     }
 
-    if (keepPlaying) {
-      rtc::CritScope lock(_critSect);
-
-      if (_audioClient != nullptr) {
-        hr = _audioClient->Stop();
-        if (FAILED(hr)) {
-          _TraceCOMError(hr);
-        }
-        hr = _audioClient->Reset();
-        if (FAILED(hr)) {
-          _TraceCOMError(hr);
-        }
-      }
-      RTC_LOG(LS_ERROR)
-          << "Playout error: rendering thread has ended pre-maturely";
-    } else {
-      RTC_LOG(LS_VERBOSE) << "_Rendering thread is now terminated properly";
-    }
+//     return 0;
+//   }
 
-    return (DWORD)hr;
-  }
+//   virtual int32_t Volume(uint32_t& volume) const {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
 
-  int32_t InitTransport() override {
-    if (Transporting()) {
-      return -1;
-    }
+//     float fLevel;
+//     HRESULT hr = _simpleAudioVolume->GetMasterVolume(&fLevel);
+//     if (FAILED(hr)) {
+//       return -1;
+//     }
+
+//     volume = fLevel * MAX_CORE_SPEAKER_VOLUME;
 
-    if (TransportIsInitialized()) {
-      return 0;
-    }
+//     return 0;
+//   }
 
-    if (GetDevice() == nullptr) {
-      return -1;
-    }
+//   virtual int32_t MaxVolume(uint32_t& maxVolume) const {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
 
-    // Initialize the microphone (devices might have been added or removed)
-    if (InitMixer() == -1) {
-      RTC_LOG(LS_WARNING) << "InitMixer() failed";
-    }
+//     maxVolume = MAX_CORE_SPEAKER_VOLUME;
 
-    // Ensure that the updated rendering endpoint device is valid
-    if (GetDevice() == nullptr) {
-      return -1;
-    }
+//     return 0;
+//   }
 
-    HRESULT hr = S_OK;
-    WAVEFORMATEX* pWfxOut = nullptr;
-    WAVEFORMATEX Wfx = WAVEFORMATEX();
-    WAVEFORMATEX* pWfxClosestMatch = nullptr;
-
-    // Retrieve the stream format that the audio engine uses for its internal
-    // processing (mixing) of shared-mode streams.
-    hr = _audioClient->GetMixFormat(&pWfxOut);
-    if (SUCCEEDED(hr)) {
-      RTC_LOG(LS_VERBOSE) << "Audio Engine's current rendering mix format:";
-      // format type
-      RTC_LOG(LS_VERBOSE) << "wFormatTag     : 0x"
-                          << rtc::ToHex(pWfxOut->wFormatTag) << " ("
-                          << pWfxOut->wFormatTag << ")";
-      // number of channels (i.e. mono, stereo...)
-      RTC_LOG(LS_VERBOSE) << "nChannels      : " << pWfxOut->nChannels;
-      // sample rate
-      RTC_LOG(LS_VERBOSE) << "nSamplesPerSec : " << pWfxOut->nSamplesPerSec;
-      // for buffer estimation
-      RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec: " << pWfxOut->nAvgBytesPerSec;
-      // block size of data
-      RTC_LOG(LS_VERBOSE) << "nBlockAlign    : " << pWfxOut->nBlockAlign;
-      // number of bits per sample of mono data
-      RTC_LOG(LS_VERBOSE) << "wBitsPerSample : " << pWfxOut->wBitsPerSample;
-      RTC_LOG(LS_VERBOSE) << "cbSize         : " << pWfxOut->cbSize;
-    }
+//   virtual int32_t MinVolume(uint32_t& minVolume) const {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
 
-    // Set wave format
-    Wfx.wFormatTag = WAVE_FORMAT_PCM;
-    Wfx.wBitsPerSample = 16;
-    Wfx.cbSize = 0;
-
-    const int freqs[] = {48000, 44100, 16000, 96000, 32000, 8000};
-    hr = S_FALSE;
-
-    // Iterate over frequencies and channels, in order of priority
-    for (unsigned int freq = 0; freq < sizeof(freqs) / sizeof(freqs[0]);
-         freq++) {
-      for (unsigned int chan = 0;
-           chan < sizeof(_channelsPrioList) / sizeof(_channelsPrioList[0]);
-           chan++) {
-        Wfx.nChannels = _channelsPrioList[chan];
-        Wfx.nSamplesPerSec = freqs[freq];
-        Wfx.nBlockAlign = Wfx.nChannels * Wfx.wBitsPerSample / 8;
-        Wfx.nAvgBytesPerSec = Wfx.nSamplesPerSec * Wfx.nBlockAlign;
-        // If the method succeeds and the audio endpoint device supports the
-        // specified stream format, it returns S_OK. If the method succeeds and
-        // provides a closest match to the specified format, it returns S_FALSE.
-        hr = _audioClient->IsFormatSupported(AUDCLNT_SHAREMODE_SHARED, &Wfx,
-                                             &pWfxClosestMatch);
-        if (hr == S_OK) {
-          break;
-        } else {
-          if (pWfxClosestMatch) {
-            RTC_LOG(INFO) << "nChannels=" << Wfx.nChannels
-                          << ", nSamplesPerSec=" << Wfx.nSamplesPerSec
-                          << " is not supported. Closest match: "
-                           "nChannels="
-                        << pWfxClosestMatch->nChannels << ", nSamplesPerSec="
-                          << pWfxClosestMatch->nSamplesPerSec;
-            CoTaskMemFree(pWfxClosestMatch);
-            pWfxClosestMatch = nullptr;
-          } else {
-            RTC_LOG(INFO) << "nChannels=" << Wfx.nChannels
-                          << ", nSamplesPerSec=" << Wfx.nSamplesPerSec
-                          << " is not supported. No closest match.";
-          }
-        }
-      }
-      if (hr == S_OK)
-        break;
-    }
+//     minVolume = MIN_CORE_SPEAKER_VOLUME;
 
-    // TODO(andrew): what happens in the event of failure in the above loop?
-    //   Is _ptrClientOut->Initialize expected to fail?
-    //   Same in InitRecording().
-    if (hr == S_OK) {
-      _audioFrameSize = Wfx.nBlockAlign;
-      // Block size is the number of samples each channel in 10ms.
-      _blockSize = Wfx.nSamplesPerSec / 100;
-      _sampleRate = Wfx.nSamplesPerSec;
-      _deviceSampleRate = Wfx.nSamplesPerSec;  // The device itself continues to
-                                               // run at 44.1 kHz.
-      _deviceBlockSize = Wfx.nSamplesPerSec / 100;
-      _channels = Wfx.nChannels;
-
-      RTC_LOG(LS_VERBOSE) << "VoE selected this rendering format:";
-      RTC_LOG(LS_VERBOSE) << "wFormatTag         : 0x"
-                          << rtc::ToHex(Wfx.wFormatTag) << " ("
-                          << Wfx.wFormatTag << ")";
-      RTC_LOG(LS_VERBOSE) << "nChannels          : " << Wfx.nChannels;
-      RTC_LOG(LS_VERBOSE) << "nSamplesPerSec     : " << Wfx.nSamplesPerSec;
-      RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec    : " << Wfx.nAvgBytesPerSec;
-      RTC_LOG(LS_VERBOSE) << "nBlockAlign        : " << Wfx.nBlockAlign;
-      RTC_LOG(LS_VERBOSE) << "wBitsPerSample     : " << Wfx.wBitsPerSample;
-      RTC_LOG(LS_VERBOSE) << "cbSize             : " << Wfx.cbSize;
-      RTC_LOG(LS_VERBOSE) << "Additional settings:";
-      RTC_LOG(LS_VERBOSE) << "_playAudioFrameSize: " << _audioFrameSize;
-      RTC_LOG(LS_VERBOSE) << "_playBlockSize     : " << _blockSize;
-      RTC_LOG(LS_VERBOSE) << "_playChannels      : " << _channels;
-    }
+//     return 0;
+//   }
 
-    // Create a rendering stream.
-    //
-    // ****************************************************************************
-    // For a shared-mode stream that uses event-driven buffering, the caller
-    // must set both hnsPeriodicity and hnsBufferDuration to 0. The Initialize
-    // method determines how large a buffer to allocate based on the scheduling
-    // period of the audio engine. Although the client's buffer processing
-    // thread is event driven, the basic buffer management process, as described
-    // previously, is unaltered. Each time the thread awakens, it should call
-    // IAudioClient::GetCurrentPadding to determine how much data to write to a
-    // rendering buffer or read from a capture buffer. In contrast to the two
-    // buffers that the Initialize method allocates for an exclusive-mode stream
-    // that uses event-driven buffering, a shared-mode stream requires a single
-    // buffer.
-    // ****************************************************************************
-    //
-    REFERENCE_TIME hnsBufferDuration =
-        0;  // ask for minimum buffer size (default)
-    if (_deviceSampleRate == 44100) {
-      // Ask for a larger buffer size (30ms) when using 44.1kHz as render rate.
-      // There seems to be a larger risk of underruns for 44.1 compared
-      // with the default rate (48kHz). When using default, we set the requested
-      // buffer duration to 0, which sets the buffer to the minimum size
-      // required by the engine thread. The actual buffer size can then be
-      // read by GetBufferSize() and it is 20ms on most machines.
-      hnsBufferDuration = 30 * 10000;
-    }
-    hr = _audioClient->Initialize(
-        AUDCLNT_SHAREMODE_SHARED,  // share Audio Engine with other applications
-        AUDCLNT_STREAMFLAGS_EVENTCALLBACK,  // processing of the audio buffer by
-                                            // the client will be event driven
-        hnsBufferDuration,  // requested buffer capacity as a time value (in
-                            // 100-nanosecond units)
-        0,                  // periodicity
-        &Wfx,               // selected wave format
-        nullptr);           // session GUID
-
-    if (FAILED(hr)) {
-      RTC_LOG(LS_ERROR) << "IAudioClient::Initialize() failed:";
-    }
-    EXIT_ON_ERROR(hr);
-
-    if (_pAudioBuffer) {
-      // Update the audio buffer with the selected parameters
-      _pAudioBuffer->SetPlayoutSampleRate(_sampleRate);
-      _pAudioBuffer->SetPlayoutChannels((uint8_t)_channels);
-    } else {
-      // We can enter this state during CoreAudioIsSupported() when no
-      // AudioDeviceImplementation has been created, hence the AudioDeviceBuffer
-      // does not exist. It is OK to end up here since we don't initiate any
-      // media in CoreAudioIsSupported().
-      RTC_LOG(LS_VERBOSE)
-          << "AudioDeviceBuffer must be attached before streaming can start";
-    }
+//   //
+//   // Mute control
+//   //
 
-    // Get the actual size of the shared (endpoint buffer).
-    // Typical value is 960 audio frames <=> 20ms @ 48kHz sample rate.
-    UINT bufferFrameCount(0);
-    hr = _audioClient->GetBufferSize(&bufferFrameCount);
-    if (SUCCEEDED(hr)) {
-      RTC_LOG(LS_VERBOSE) << "IAudioClient::GetBufferSize() => "
-                          << bufferFrameCount << " (<=> "
-                          << bufferFrameCount * _audioFrameSize << " bytes)";
-    }
+//   virtual int32_t MuteIsAvailable(bool& available) const {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
 
-    // Set the event handle that the system signals when an audio buffer is
-    // ready to be processed by the client.
-    hr = _audioClient->SetEventHandle(_hSamplesReadyEvent);
-    EXIT_ON_ERROR(hr);
+//     BOOL mute;
+//     HRESULT hr = _simpleAudioVolume->GetMute(&mute);
+//     available = SUCCEEDED(hr);
 
-    // Get an IAudioRenderClient interface.
-    hr = _audioClient->GetService(__uuidof(IAudioRenderClient),
-                                  (void**)&_audioRenderClient);
-    EXIT_ON_ERROR(hr);
+//     return 0;
+//   }
 
-    // Get an ISimpleAudioVolume interface.
-    hr = _audioClient->GetService(__uuidof(ISimpleAudioVolume),
-                                  (void**)&_simpleAudioVolume);
-    EXIT_ON_ERROR(hr);
+//   virtual int32_t SetMute(bool enable) {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
 
-    // Mark playout side as initialized
-    _transportInitialized = true;
+//     BOOL mute = enable;
+//     HRESULT hr = _simpleAudioVolume->SetMute(mute, nullptr);
+//     if (FAILED(hr)) {
+//       return -1;
+//     }
 
-    CoTaskMemFree(pWfxOut);
-    CoTaskMemFree(pWfxClosestMatch);
+//     return 0;
+//   }
 
-    RTC_LOG(LS_VERBOSE) << "render side is now initialized";
-    return 0;
-
-  Exit:
-    _TraceCOMError(hr);
-    CoTaskMemFree(pWfxOut);
-    CoTaskMemFree(pWfxClosestMatch);
-    return -1;
-  }
-
-  int32_t SetStereo(bool enable) override {
-    if (!MixerIsInitialized()) {
-      return -1;
-    }
-
-    if (enable) {
-      _channelsPrioList[0] = 2;  // try stereo first
-      _channelsPrioList[1] = 1;
-      _channels = 2;
-    } else {
-      _channelsPrioList[0] = 1;  // try mono first
-      _channelsPrioList[1] = 2;
-      _channels = 1;
-    }
-
-    return 0;
-  }
-};
+//   virtual int32_t Mute(bool& enabled) const {
+//     if (!TransportIsInitialized()) {
+//       return -1;
+//     }
+
+//     BOOL mute;
+//     HRESULT hr = _simpleAudioVolume->GetMute(&mute);
+//     if (FAILED(hr)) {
+//       return -1;
+//     }
+
+//     enabled = mute == TRUE;
+
+//     return 0;
+//   }
+
+//   //
+//   // Stereo support
+//   //
+
+//   virtual int32_t StereoIsAvailable(bool& available) const {
+//     if (!MixerIsInitialized()) {
+//       return -1;
+//     }
+
+//     available = true;
+
+//     return 0;
+//   }
+
+//   virtual int32_t SetStereo(bool enable) = 0;
+
+//   virtual int32_t Stereo(bool& enabled) const {
+//     enabled = _channels == 2;
+
+//     return 0;
+//   }
+// };
+
+// struct CaptureDeviceInternal
+//     : public AudioDeviceHelper<
+//           winrt::Windows::Devices::Enumeration::DeviceClass::AudioCapture> {
+//  protected:
+//   const rtc::CriticalSection* _critSect;
+//   const uint32_t* _sndCardDelay;
+
+//   Microsoft::WRL::ComPtr<IAudioCaptureClient> _audioCaptureClient;
+
+//   LARGE_INTEGER _perfCounterFreq;
+//   double _perfCounterFactor;
+
+//   uint16_t _channelsPrioList[3];
+
+//  public:
+//   CaptureDeviceInternal(rtc::CriticalSection* critSect, uint32_t* sndCardDelay)
+//       : _critSect(critSect), _sndCardDelay(sndCardDelay) {
+//     _perfCounterFreq.QuadPart = 1;
+//     _perfCounterFactor = 0.0;
+
+//     // list of number of channels to use on recording side
+//     _channelsPrioList[0] = 2;  // stereo is prio 1
+//     _channelsPrioList[1] = 1;  // mono is prio 2
+//     _channelsPrioList[2] = 4;  // quad is prio 3
+//   }
+
+//   void AttachAudioBuffer(webrtc::AudioDeviceBuffer* audioBuffer) override {
+//     AudioDeviceHelper::AttachAudioBuffer(audioBuffer);
+//     audioBuffer->SetRecordingSampleRate(0);
+//     audioBuffer->SetRecordingChannels(0);
+//   }
+
+//   DWORD Transport() override {
+//     bool keepRecording = true;
+//     HANDLE waitArray[2] = {_hShutdownEvent, _hSamplesReadyEvent};
+//     HRESULT hr = S_OK;
+
+//     LARGE_INTEGER t1;
+
+//     BYTE* syncBuffer = nullptr;
+//     UINT32 syncBufIndex = 0;
+
+//     _samples = 0;
+
+//     // Initialize COM as MTA in this thread.
+//     Microsoft::WRL::Wrappers::RoInitializeWrapper roInitializeWrapper(
+//         RO_INIT_MULTITHREADED);
+//     if (FAILED(roInitializeWrapper)) {
+//       RTC_LOG(LS_ERROR) << "failed to initialize COM in capture thread";
+//       return 1;
+//     }
+
+//     rtc::SetCurrentThreadName("webrtc_core_audio_capture_thread");
+
+//     // Get size of capturing buffer (length is expressed as the number of audio
+//     // frames the buffer can hold). This value is fixed during the capturing
+//     // session.
+//     //
+//     UINT32 bufferLength = 0;
+//     if (_audioClient == nullptr) {
+//       RTC_LOG(LS_ERROR)
+//           << "input state has been modified before capture loop starts.";
+//       return 1;
+//     }
+//     hr = _audioClient->GetBufferSize(&bufferLength);
+//     EXIT_ON_ERROR(hr);
+//     RTC_LOG(LS_VERBOSE) << "[CAPT] size of buffer       : " << bufferLength;
+
+//     // Allocate memory for sync buffer.
+//     // It is used for compensation between native 44.1 and internal 44.0 and
+//     // for cases when the capture buffer is larger than 10ms.
+//     //
+//     const UINT32 syncBufferSize = 2 * (bufferLength * _audioFrameSize);
+//     syncBuffer = new BYTE[syncBufferSize];
+//     if (syncBuffer == nullptr) {
+//       return (DWORD)E_POINTER;
+//     }
+//     RTC_LOG(LS_VERBOSE) << "[CAPT] size of sync buffer  : " << syncBufferSize
+//                         << " [bytes]";
+
+//     // Get maximum latency for the current stream (will not change for the
+//     // lifetime of the IAudioClient object).
+//     //
+//     REFERENCE_TIME latency;
+//     _audioClient->GetStreamLatency(&latency);
+//     RTC_LOG(LS_VERBOSE) << "[CAPT] max stream latency   : " << (DWORD)latency
+//                         << " (" << (double)(latency / 10000.0) << " ms)";
+
+//     // Get the length of the periodic interval separating successive processing
+//     // passes by the audio engine on the data in the endpoint buffer.
+//     //
+//     REFERENCE_TIME devPeriod = 0;
+//     REFERENCE_TIME devPeriodMin = 0;
+//     _audioClient->GetDevicePeriod(&devPeriod, &devPeriodMin);
+//     RTC_LOG(LS_VERBOSE) << "[CAPT] device period        : " << (DWORD)devPeriod
+//                         << " (" << (double)(devPeriod / 10000.0) << " ms)";
+
+//     double extraDelayMS = (double)((latency + devPeriod) / 10000.0);
+//     RTC_LOG(LS_VERBOSE) << "[CAPT] extraDelayMS         : " << extraDelayMS;
+
+//     double endpointBufferSizeMS =
+//         10.0 * ((double)bufferLength / (double)_blockSize);
+//     RTC_LOG(LS_VERBOSE) << "[CAPT] endpointBufferSizeMS : "
+//                         << endpointBufferSizeMS;
+
+//     // Start up the capturing stream.
+//     //
+//     hr = _audioClient->Start();
+//     EXIT_ON_ERROR(hr);
+
+//     // Set event which will ensure that the calling thread modifies the
+//     // recording state to true.
+//     //
+//     SetEvent(_hStartedEvent);
+
+//     // >> ---------------------------- THREAD LOOP ----------------------------
+
+//     while (keepRecording) {
+//       // Wait for a capture notification event or a shutdown event
+//       DWORD waitResult = WaitForMultipleObjects(2, waitArray, FALSE, 500);
+//       switch (waitResult) {
+//         case WAIT_OBJECT_0 + 0:  // _hShutdownCaptureEvent
+//           keepRecording = false;
+//           break;
+//         case WAIT_OBJECT_0 + 1:  // _hCaptureSamplesReadyEvent
+//           break;
+//         case WAIT_TIMEOUT:  // timeout notification
+//           RTC_LOG(LS_WARNING) << "capture event timed out after 0.5 seconds";
+//           goto Exit;
+//         default:  // unexpected error
+//           RTC_LOG(LS_WARNING) << "unknown wait termination on capture side";
+//           goto Exit;
+//       }
+
+//       while (keepRecording) {
+//         rtc::CritScope lock(_critSect);
+
+//         BYTE* pData = 0;
+//         UINT32 framesAvailable = 0;
+//         DWORD flags = 0;
+//         UINT64 recTime = 0;
+//         UINT64 recPos = 0;
+
+//         // Sanity check to ensure that essential states are not modified
+//         // during the unlocked period.
+//         if (_audioCaptureClient == nullptr || _audioClient == nullptr) {
+//           RTC_LOG(LS_ERROR)
+//               << "input state has been modified during unlocked period";
+//           goto Exit;
+//         }
+
+//         //  Find out how much capture data is available
+//         //
+//         hr = _audioCaptureClient->GetBuffer(
+//             &pData,            // packet which is ready to be read by used
+//             &framesAvailable,  // #frames in the captured packet (can be zero)
+//             &flags,            // support flags (check)
+//             &recPos,    // device position of first audio frame in data packet
+//             &recTime);  // value of performance counter at the time of recording
+//                         // the first audio frame
+
+//         if (SUCCEEDED(hr)) {
+//           if (AUDCLNT_S_BUFFER_EMPTY == hr) {
+//             // Buffer was empty => start waiting for a new capture notification
+//             // event
+//             break;
+//           }
+
+//           if (flags & AUDCLNT_BUFFERFLAGS_SILENT) {
+//             // Treat all of the data in the packet as silence and ignore the
+//             // actual data values.
+//             RTC_LOG(LS_WARNING) << "AUDCLNT_BUFFERFLAGS_SILENT";
+//             pData = nullptr;
+//           }
+
+//           assert(framesAvailable != 0);
+
+//           if (pData) {
+//             CopyMemory(&syncBuffer[syncBufIndex * _audioFrameSize], pData,
+//                        framesAvailable * _audioFrameSize);
+//           } else {
+//             ZeroMemory(&syncBuffer[syncBufIndex * _audioFrameSize],
+//                        framesAvailable * _audioFrameSize);
+//           }
+//           assert(syncBufferSize >= (syncBufIndex * _audioFrameSize) +
+//                                        framesAvailable * _audioFrameSize);
+
+//           // Release the capture buffer
+//           //
+//           hr = _audioCaptureClient->ReleaseBuffer(framesAvailable);
+//           EXIT_ON_ERROR(hr);
+
+//           _samples += framesAvailable;
+//           syncBufIndex += framesAvailable;
+
+//           QueryPerformanceCounter(&t1);
+
+//           // Get the current recording and playout delay.
+//           uint32_t sndCardRecDelay = (uint32_t)(
+//               ((((UINT64)t1.QuadPart * _perfCounterFactor) - recTime) / 10000) +
+//               (10 * syncBufIndex) / _blockSize - 10);
+//           uint32_t sndCardPlayDelay = *_sndCardDelay;
+
+//           while (syncBufIndex >= _blockSize) {
+//             if (_pAudioBuffer) {
+//               _pAudioBuffer->SetRecordedBuffer((const int8_t*)syncBuffer,
+//                                                _blockSize);
+//               _pAudioBuffer->SetVQEData(sndCardPlayDelay, sndCardRecDelay);
+
+//               _pAudioBuffer->SetTypingStatus(false);
+
+//               _pAudioBuffer->DeliverRecordedData();
+
+//               // Sanity check to ensure that essential states are not modified
+//               // during the unlocked period
+//               if (_audioCaptureClient == nullptr || _audioClient == nullptr) {
+//                 RTC_LOG(LS_ERROR) << "input state has been modified during"
+//                                   << " unlocked period";
+//                 goto Exit;
+//               }
+//             }
+
+//             // store remaining data which was not able to deliver as 10ms
+//             // segment
+//             MoveMemory(&syncBuffer[0],
+//                        &syncBuffer[_blockSize * _audioFrameSize],
+//                        (syncBufIndex - _blockSize) * _audioFrameSize);
+//             syncBufIndex -= _blockSize;
+//             sndCardRecDelay -= 10;
+//           }
+//         } else {
+//           // If GetBuffer returns AUDCLNT_E_BUFFER_ERROR, the thread consuming
+//           // the audio samples must wait for the next processing pass. The
+//           // client might benefit from keeping a count of the failed GetBuffer
+//           // calls. If GetBuffer returns this error repeatedly, the client can
+//           // start a new processing loop after shutting down the current client
+//           // by calling IAudioClient::Stop, IAudioClient::Reset, and releasing
+//           // the audio client.
+//           RTC_LOG(LS_ERROR)
+//               << "IAudioCaptureClient::GetBuffer returned"
+//               << " AUDCLNT_E_BUFFER_ERROR, hr = 0x" << rtc::ToHex(hr);
+//           goto Exit;
+//         }
+//       }
+//     }
+
+//     // ---------------------------- THREAD LOOP ---------------------------- <<
+
+//     if (_audioClient) {
+//       hr = _audioClient->Stop();
+//     }
+
+//   Exit:
+//     if (FAILED(hr)) {
+//       _audioClient->Stop();
+//       _TraceCOMError(hr);
+//     }
+
+//     if (keepRecording) {
+//       rtc::CritScope lock(_critSect);
+
+//       if (_audioClient != nullptr) {
+//         hr = _audioClient->Stop();
+//         if (FAILED(hr)) {
+//           _TraceCOMError(hr);
+//         }
+//         hr = _audioClient->Reset();
+//         if (FAILED(hr)) {
+//           _TraceCOMError(hr);
+//         }
+//       }
+
+//       RTC_LOG(LS_ERROR)
+//           << "Recording error: capturing thread has ended pre-maturely";
+//     } else {
+//       RTC_LOG(LS_VERBOSE) << "_Capturing thread is now terminated properly";
+//     }
+
+//     if (syncBuffer) {
+//       delete[] syncBuffer;
+//     }
+
+//     return (DWORD)hr;
+//   }
+
+//   int32_t InitTransport() override {
+//     if (Transporting()) {
+//       return -1;
+//     }
+
+//     if (TransportIsInitialized()) {
+//       return 0;
+//     }
+
+//     if (QueryPerformanceFrequency(&_perfCounterFreq) == 0) {
+//       return -1;
+//     }
+//     _perfCounterFactor = 10000000.0 / (double)_perfCounterFreq.QuadPart;
+
+//     if (GetDevice() == nullptr) {
+//       return -1;
+//     }
+
+//     // Initialize the microphone (devices might have been added or removed)
+//     if (InitMixer() == -1) {
+//       RTC_LOG(LS_WARNING) << "InitMixer() failed";
+//     }
+
+//     // Ensure that the updated capturing endpoint device is valid
+//     if (GetDevice() == nullptr) {
+//       return -1;
+//     }
+
+//     HRESULT hr = S_OK;
+//     WAVEFORMATEX* pWfxIn = nullptr;
+//     WAVEFORMATEXTENSIBLE Wfx = WAVEFORMATEXTENSIBLE();
+//     WAVEFORMATEX* pWfxClosestMatch = nullptr;
+
+//     // Retrieve the stream format that the audio engine uses for its internal
+//     // processing (mixing) of shared-mode streams.
+//     hr = _audioClient->GetMixFormat(&pWfxIn);
+//     if (SUCCEEDED(hr)) {
+//       RTC_LOG(LS_VERBOSE) << "Audio Engine's current capturing mix format:";
+//       // format type
+//       RTC_LOG(LS_VERBOSE) << "wFormatTag     : 0x"
+//                           << rtc::ToHex(pWfxIn->wFormatTag) << " ("
+//                           << pWfxIn->wFormatTag << ")";
+//       // number of channels (i.e. mono, stereo...)
+//       RTC_LOG(LS_VERBOSE) << "nChannels      : " << pWfxIn->nChannels;
+//       // sample rate
+//       RTC_LOG(LS_VERBOSE) << "nSamplesPerSec : " << pWfxIn->nSamplesPerSec;
+//       // for buffer estimation
+//       RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec: " << pWfxIn->nAvgBytesPerSec;
+//       // block size of data
+//       RTC_LOG(LS_VERBOSE) << "nBlockAlign    : " << pWfxIn->nBlockAlign;
+//       // number of bits per sample of mono data
+//       RTC_LOG(LS_VERBOSE) << "wBitsPerSample : " << pWfxIn->wBitsPerSample;
+//       RTC_LOG(LS_VERBOSE) << "cbSize         : " << pWfxIn->cbSize;
+//     }
+
+//     // Set wave format
+//     Wfx.Format.wFormatTag = WAVE_FORMAT_EXTENSIBLE;
+//     Wfx.Format.wBitsPerSample = 16;
+//     Wfx.Format.cbSize = 22;
+//     Wfx.dwChannelMask = 0;
+//     Wfx.Samples.wValidBitsPerSample = Wfx.Format.wBitsPerSample;
+//     Wfx.SubFormat = KSDATAFORMAT_SUBTYPE_PCM;
+
+//     const int freqs[6] = {48000, 44100, 16000, 96000, 32000, 8000};
+//     hr = S_FALSE;
+
+//     // Iterate over frequencies and channels, in order of priority
+//     for (unsigned int freq = 0; freq < sizeof(freqs) / sizeof(freqs[0]);
+//          freq++) {
+//       for (unsigned int chan = 0;
+//            chan < sizeof(_channelsPrioList) / sizeof(_channelsPrioList[0]);
+//            chan++) {
+//         Wfx.Format.nChannels = _channelsPrioList[chan];
+//         Wfx.Format.nSamplesPerSec = freqs[freq];
+//         Wfx.Format.nBlockAlign =
+//             Wfx.Format.nChannels * Wfx.Format.wBitsPerSample / 8;
+//         Wfx.Format.nAvgBytesPerSec =
+//             Wfx.Format.nSamplesPerSec * Wfx.Format.nBlockAlign;
+//         // If the method succeeds and the audio endpoint device supports the
+//         // specified stream format, it returns S_OK. If the method succeeds and
+//         // provides a closest match to the specified format, it returns S_FALSE.
+//         hr = _audioClient->IsFormatSupported(
+//             AUDCLNT_SHAREMODE_SHARED, (WAVEFORMATEX*)&Wfx, &pWfxClosestMatch);
+//         if (hr == S_OK) {
+//           break;
+//         } else {
+//           if (pWfxClosestMatch) {
+//             RTC_LOG(INFO) << "nChannels=" << Wfx.Format.nChannels
+//                           << ", nSamplesPerSec=" << Wfx.Format.nSamplesPerSec
+//                           << " is not supported. Closest match: "
+//                           << "nChannels=" << pWfxClosestMatch->nChannels
+//                           << ", nSamplesPerSec="
+//                           << pWfxClosestMatch->nSamplesPerSec;
+//             CoTaskMemFree(pWfxClosestMatch);
+//             pWfxClosestMatch = nullptr;
+//           } else {
+//             RTC_LOG(INFO) << "nChannels=" << Wfx.Format.nChannels
+//                           << ", nSamplesPerSec=" << Wfx.Format.nSamplesPerSec
+//                           << " is not supported. No closest match.";
+//           }
+//         }
+//       }
+//       if (hr == S_OK)
+//         break;
+//     }
+
+//     if (hr == S_OK) {
+//       _audioFrameSize = Wfx.Format.nBlockAlign;
+//       _sampleRate = Wfx.Format.nSamplesPerSec;
+//       _blockSize = Wfx.Format.nSamplesPerSec / 100;
+//       _channels = Wfx.Format.nChannels;
+
+//       RTC_LOG(LS_VERBOSE) << "VoE selected this capturing format:";
+//       RTC_LOG(LS_VERBOSE) << "wFormatTag        : 0x"
+//                           << rtc::ToHex(Wfx.Format.wFormatTag) << " ("
+//                           << Wfx.Format.wFormatTag << ")";
+//       RTC_LOG(LS_VERBOSE) << "nChannels         : " << Wfx.Format.nChannels;
+//       RTC_LOG(LS_VERBOSE) << "nSamplesPerSec    : "
+//                           << Wfx.Format.nSamplesPerSec;
+//       RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec   : "
+//                           << Wfx.Format.nAvgBytesPerSec;
+//       RTC_LOG(LS_VERBOSE) << "nBlockAlign       : " << Wfx.Format.nBlockAlign;
+//       RTC_LOG(LS_VERBOSE) << "wBitsPerSample    : "
+//                           << Wfx.Format.wBitsPerSample;
+//       RTC_LOG(LS_VERBOSE) << "cbSize            : " << Wfx.Format.cbSize;
+//       RTC_LOG(LS_VERBOSE) << "Additional settings:";
+//       RTC_LOG(LS_VERBOSE) << "_recAudioFrameSize: " << _audioFrameSize;
+//       RTC_LOG(LS_VERBOSE) << "_recBlockSize     : " << _blockSize;
+//       RTC_LOG(LS_VERBOSE) << "_recChannels      : " << _channels;
+//     }
+
+//     // Create a capturing stream.
+//     hr = _audioClient->Initialize(
+//         AUDCLNT_SHAREMODE_SHARED,  // share Audio Engine with other applications
+//         AUDCLNT_STREAMFLAGS_EVENTCALLBACK |  // processing of the audio buffer
+//                                              // by the client will be event
+//                                              // driven
+//             AUDCLNT_STREAMFLAGS_NOPERSIST,   // volume and mute settings for an
+//                                              // audio session will not persist
+//                                              // across system restarts
+//         0,                    // required for event-driven shared mode
+//         0,                    // periodicity
+//         (WAVEFORMATEX*)&Wfx,  // selected wave format
+//         nullptr);             // session GUID
+
+//     if (hr != S_OK) {
+//       RTC_LOG(LS_ERROR) << "IAudioClient::Initialize() failed:";
+//     }
+//     EXIT_ON_ERROR(hr);
+
+//     if (_pAudioBuffer) {
+//       // Update the audio buffer with the selected parameters
+//       _pAudioBuffer->SetRecordingSampleRate(_sampleRate);
+//       _pAudioBuffer->SetRecordingChannels((uint8_t)_channels);
+//     } else {
+//       // We can enter this state during CoreAudioIsSupported() when no
+//       // AudioDeviceImplementation has been created, hence the AudioDeviceBuffer
+//       // does not exist. It is OK to end up here since we don't initiate any
+//       // media in CoreAudioIsSupported().
+//       RTC_LOG(LS_VERBOSE)
+//           << "AudioDeviceBuffer must be attached before streaming can start";
+//     }
+
+//     // Get the actual size of the shared (endpoint buffer).
+//     // Typical value is 960 audio frames <=> 20ms @ 48kHz sample rate.
+//     UINT bufferFrameCount(0);
+//     hr = _audioClient->GetBufferSize(&bufferFrameCount);
+//     if (SUCCEEDED(hr)) {
+//       RTC_LOG(LS_VERBOSE) << "IAudioClient::GetBufferSize() => "
+//                           << bufferFrameCount << " (<=> "
+//                           << bufferFrameCount * _audioFrameSize << " bytes)";
+//     }
+
+//     // Set the event handle that the system signals when an audio buffer is
+//     // ready to be processed by the client.
+//     hr = _audioClient->SetEventHandle(_hSamplesReadyEvent);
+//     EXIT_ON_ERROR(hr);
+
+//     // Get an IAudioCaptureClient interface.
+//     hr = _audioClient->GetService(__uuidof(IAudioCaptureClient),
+//                                   (void**)&_audioCaptureClient);
+//     EXIT_ON_ERROR(hr);
+
+//     // Mark capture side as initialized
+//     _transportInitialized = true;
+
+//     CoTaskMemFree(pWfxIn);
+//     CoTaskMemFree(pWfxClosestMatch);
+
+//     RTC_LOG(LS_VERBOSE) << "capture side is now initialized";
+//     return 0;
+
+//   Exit:
+//     _TraceCOMError(hr);
+//     CoTaskMemFree(pWfxIn);
+//     CoTaskMemFree(pWfxClosestMatch);
+//     return -1;
+//   }
+
+//   int32_t SetStereo(bool enable) override {
+//     if (!MixerIsInitialized()) {
+//       return -1;
+//     }
+
+//     if (enable) {
+//       _channelsPrioList[0] = 2;  // try stereo first
+//       _channelsPrioList[1] = 1;
+//       _channels = 2;
+//     } else {
+//       _channelsPrioList[0] = 1;  // try mono first
+//       _channelsPrioList[1] = 2;
+//       _channels = 1;
+//     }
+
+//     return 0;
+//   }
+// };
+
+// struct RenderDeviceInternal
+//     : public AudioDeviceHelper<
+//           winrt::Windows::Devices::Enumeration::DeviceClass::AudioRender> {
+//  protected:
+//   const rtc::CriticalSection* _critSect;
+
+//   Microsoft::WRL::ComPtr<IAudioRenderClient> _audioRenderClient;
+
+//   uint32_t _deviceSampleRate;
+//   uint32_t _deviceBlockSize;
+
+//   uint16_t _channelsPrioList[2];
+
+//  public:
+//   uint32_t _sndCardDelay;
+
+//   RenderDeviceInternal(rtc::CriticalSection* critSect) : _critSect(critSect) {
+//     // list of number of channels to use on recording side
+//     _channelsPrioList[0] = 2;  // stereo is prio 1
+//     _channelsPrioList[1] = 1;  // mono is prio 2
+//   }
+
+//   void AttachAudioBuffer(webrtc::AudioDeviceBuffer* audioBuffer) override {
+//     AudioDeviceHelper::AttachAudioBuffer(audioBuffer);
+//     audioBuffer->SetPlayoutSampleRate(0);
+//     audioBuffer->SetPlayoutChannels(0);
+//   }
+
+//   DWORD Transport() override {
+//     bool keepPlaying = true;
+//     HANDLE waitArray[2] = {_hShutdownEvent, _hSamplesReadyEvent};
+//     HRESULT hr = S_OK;
+
+//     // Initialize COM as MTA in this thread.
+//     Microsoft::WRL::Wrappers::RoInitializeWrapper roInitializeWrapper(
+//         RO_INIT_MULTITHREADED);
+//     if (FAILED(roInitializeWrapper)) {
+//       RTC_LOG(LS_ERROR) << "failed to initialize COM in render thread";
+//       return 1;
+//     }
+
+//     rtc::SetCurrentThreadName("webrtc_core_audio_render_thread");
+
+//     IAudioClock* clock = nullptr;
+
+//     // Get size of rendering buffer (length is expressed as the number of audio
+//     // frames the buffer can hold). This value is fixed during the rendering
+//     // session.
+//     //
+//     UINT32 bufferLength = 0;
+//     hr = _audioClient->GetBufferSize(&bufferLength);
+//     EXIT_ON_ERROR(hr);
+//     RTC_LOG(LS_VERBOSE) << "[REND] size of buffer       : " << bufferLength;
+
+//     // Get maximum latency for the current stream (will not change for the
+//     // lifetime  of the IAudioClient object).
+//     //
+//     REFERENCE_TIME latency;
+//     _audioClient->GetStreamLatency(&latency);
+//     RTC_LOG(LS_VERBOSE) << "[REND] max stream latency   : " << (DWORD)latency
+//                         << " (" << (double)(latency / 10000.0) << " ms)";
+
+//     // Get the length of the periodic interval separating successive processing
+//     // passes by the audio engine on the data in the endpoint buffer.
+//     //
+//     // The period between processing passes by the audio engine is fixed for a
+//     // particular audio endpoint device and represents the smallest processing
+//     // quantum for the audio engine. This period plus the stream latency between
+//     // the buffer and endpoint device represents the minimum possible latency
+//     // that an audio application can achieve. Typical value: 100000 <=> 0.01 sec
+//     // = 10ms.
+//     //
+//     REFERENCE_TIME devPeriod = 0;
+//     REFERENCE_TIME devPeriodMin = 0;
+//     _audioClient->GetDevicePeriod(&devPeriod, &devPeriodMin);
+//     RTC_LOG(LS_VERBOSE) << "[REND] device period        : " << (DWORD)devPeriod
+//                         << " (" << (double)(devPeriod / 10000.0) << " ms)";
+
+//     // Derive initial rendering delay.
+//     // Example: 10*(960/480) + 15 = 20 + 15 = 35ms
+//     //
+//     int playout_delay =
+//         10 * (bufferLength / _blockSize) + (int)((latency + devPeriod) / 10000);
+//     _sndCardDelay = playout_delay;
+//     _samples = 0;
+//     RTC_LOG(LS_VERBOSE) << "[REND] initial delay        : " << playout_delay;
+
+//     double endpointBufferSizeMS =
+//         10.0 * ((double)bufferLength / (double)_deviceBlockSize);
+//     RTC_LOG(LS_VERBOSE) << "[REND] endpointBufferSizeMS : "
+//                         << endpointBufferSizeMS;
+
+//     // Before starting the stream, fill the rendering buffer with silence.
+//     //
+//     BYTE* pData = nullptr;
+//     hr = _audioRenderClient->GetBuffer(bufferLength, &pData);
+//     EXIT_ON_ERROR(hr);
+
+//     hr = _audioRenderClient->ReleaseBuffer(bufferLength,
+//                                            AUDCLNT_BUFFERFLAGS_SILENT);
+//     EXIT_ON_ERROR(hr);
+
+//     _samples += bufferLength;
+
+//     hr = _audioClient->GetService(__uuidof(IAudioClock), (void**)&clock);
+//     if (FAILED(hr)) {
+//       RTC_LOG(LS_WARNING)
+//           << "failed to get IAudioClock interface from the IAudioClient";
+//     }
+
+//     // Start up the rendering audio stream.
+//     hr = _audioClient->Start();
+//     EXIT_ON_ERROR(hr);
+
+//     // Set event which will ensure that the calling thread modifies the playing
+//     // state to true.
+//     //
+//     SetEvent(_hStartedEvent);
+
+//     // >> ------------------ THREAD LOOP ------------------
+
+//     while (keepPlaying) {
+//       // Wait for a render notification event or a shutdown event
+//       DWORD waitResult = WaitForMultipleObjects(2, waitArray, FALSE, 500);
+//       switch (waitResult) {
+//         case WAIT_OBJECT_0 + 0:  // _hShutdownRenderEvent
+//           keepPlaying = false;
+//           break;
+//         case WAIT_OBJECT_0 + 1:  // _hRenderSamplesReadyEvent
+//           break;
+//         case WAIT_TIMEOUT:  // timeout notification
+//           RTC_LOG(LS_WARNING) << "render event timed out after 0.5 seconds";
+//           goto Exit;
+//         default:  // unexpected error
+//           RTC_LOG(LS_WARNING) << "unknown wait termination on render side";
+//           goto Exit;
+//       }
+
+//       while (keepPlaying) {
+//         rtc::CritScope lock(_critSect);
+
+//         // Sanity check to ensure that essential states are not modified
+//         // during the unlocked period.
+//         if (_audioRenderClient == nullptr || _audioClient == nullptr) {
+//           RTC_LOG(LS_ERROR)
+//               << "output state has been modified during unlocked period";
+//           goto Exit;
+//         }
+
+//         // Get the number of frames of padding (queued up to play) in the
+//         // endpoint buffer.
+//         UINT32 padding = 0;
+//         hr = _audioClient->GetCurrentPadding(&padding);
+//         EXIT_ON_ERROR(hr);
+
+//         // Derive the amount of available space in the output buffer
+//         uint32_t framesAvailable = bufferLength - padding;
+
+//         // Do we have 10 ms available in the render buffer?
+//         if (framesAvailable < _blockSize) {
+//           // Not enough space in render buffer to store next render packet.
+//           break;
+//         }
+
+//         // Write n*10ms buffers to the render buffer
+//         const uint32_t n10msBuffers = (framesAvailable / _blockSize);
+//         for (uint32_t n = 0; n < n10msBuffers; n++) {
+//           // Get pointer (i.e., grab the buffer) to next space in the shared
+//           // render buffer.
+//           hr = _audioRenderClient->GetBuffer(_blockSize, &pData);
+//           EXIT_ON_ERROR(hr);
+
+//           if (_pAudioBuffer) {
+//             // Request data to be played out (#bytes =
+//             // _playBlockSize*_audioFrameSize)
+//             int32_t nSamples = _pAudioBuffer->RequestPlayoutData(_blockSize);
+
+//             if (nSamples == -1) {
+//               RTC_LOG(LS_ERROR) << "failed to read data from render client";
+//               goto Exit;
+//             }
+
+//             // Sanity check to ensure that essential states are not modified
+//             // during the unlocked period
+//             if (_audioRenderClient == nullptr || _audioClient == nullptr) {
+//               RTC_LOG(LS_ERROR)
+//                   << "output state has been modified during unlocked"
+//                   << " period";
+//               goto Exit;
+//             }
+//             if (nSamples != static_cast<int32_t>(_blockSize)) {
+//               RTC_LOG(LS_WARNING) << "nSamples(" << nSamples
+//                                   << ") != _playBlockSize" << _blockSize << ")";
+//             }
+
+//             // Get the actual (stored) data
+//             nSamples = _pAudioBuffer->GetPlayoutData((int8_t*)pData);
+//           }
+
+//           DWORD dwFlags(0);
+//           hr = _audioRenderClient->ReleaseBuffer(_blockSize, dwFlags);
+//           // See http://msdn.microsoft.com/en-us/library/dd316605(VS.85).aspx
+//           // for more details regarding AUDCLNT_E_DEVICE_INVALIDATED.
+//           EXIT_ON_ERROR(hr);
+
+//           _samples += _blockSize;
+//         }
+
+//         // Check the current delay on the playout side.
+//         if (clock) {
+//           UINT64 pos = 0;
+//           UINT64 freq = 1;
+//           clock->GetPosition(&pos, nullptr);
+//           clock->GetFrequency(&freq);
+//           playout_delay = round(
+//               (double(_samples) / _deviceSampleRate - double(pos) / freq) *
+//               1000.0);
+//           _sndCardDelay = playout_delay;
+//         }
+//       }
+//     }
+
+//     // ------------------ THREAD LOOP ------------------ <<
+
+//     webrtc::SleepMs(static_cast<DWORD>(endpointBufferSizeMS + 0.5));
+//     hr = _audioClient->Stop();
+
+//   Exit:
+//     if (clock != nullptr) {
+//       clock->Release();
+//       clock = nullptr;
+//     }
+
+//     if (FAILED(hr)) {
+//       _audioClient->Stop();
+//       _TraceCOMError(hr);
+//     }
+
+//     if (keepPlaying) {
+//       rtc::CritScope lock(_critSect);
+
+//       if (_audioClient != nullptr) {
+//         hr = _audioClient->Stop();
+//         if (FAILED(hr)) {
+//           _TraceCOMError(hr);
+//         }
+//         hr = _audioClient->Reset();
+//         if (FAILED(hr)) {
+//           _TraceCOMError(hr);
+//         }
+//       }
+//       RTC_LOG(LS_ERROR)
+//           << "Playout error: rendering thread has ended pre-maturely";
+//     } else {
+//       RTC_LOG(LS_VERBOSE) << "_Rendering thread is now terminated properly";
+//     }
+
+//     return (DWORD)hr;
+//   }
+
+//   int32_t InitTransport() override {
+//     if (Transporting()) {
+//       return -1;
+//     }
+
+//     if (TransportIsInitialized()) {
+//       return 0;
+//     }
+
+//     if (GetDevice() == nullptr) {
+//       return -1;
+//     }
+
+//     // Initialize the microphone (devices might have been added or removed)
+//     if (InitMixer() == -1) {
+//       RTC_LOG(LS_WARNING) << "InitMixer() failed";
+//     }
+
+//     // Ensure that the updated rendering endpoint device is valid
+//     if (GetDevice() == nullptr) {
+//       return -1;
+//     }
+
+//     HRESULT hr = S_OK;
+//     WAVEFORMATEX* pWfxOut = nullptr;
+//     WAVEFORMATEX Wfx = WAVEFORMATEX();
+//     WAVEFORMATEX* pWfxClosestMatch = nullptr;
+
+//     // Retrieve the stream format that the audio engine uses for its internal
+//     // processing (mixing) of shared-mode streams.
+//     hr = _audioClient->GetMixFormat(&pWfxOut);
+//     if (SUCCEEDED(hr)) {
+//       RTC_LOG(LS_VERBOSE) << "Audio Engine's current rendering mix format:";
+//       // format type
+//       RTC_LOG(LS_VERBOSE) << "wFormatTag     : 0x"
+//                           << rtc::ToHex(pWfxOut->wFormatTag) << " ("
+//                           << pWfxOut->wFormatTag << ")";
+//       // number of channels (i.e. mono, stereo...)
+//       RTC_LOG(LS_VERBOSE) << "nChannels      : " << pWfxOut->nChannels;
+//       // sample rate
+//       RTC_LOG(LS_VERBOSE) << "nSamplesPerSec : " << pWfxOut->nSamplesPerSec;
+//       // for buffer estimation
+//       RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec: " << pWfxOut->nAvgBytesPerSec;
+//       // block size of data
+//       RTC_LOG(LS_VERBOSE) << "nBlockAlign    : " << pWfxOut->nBlockAlign;
+//       // number of bits per sample of mono data
+//       RTC_LOG(LS_VERBOSE) << "wBitsPerSample : " << pWfxOut->wBitsPerSample;
+//       RTC_LOG(LS_VERBOSE) << "cbSize         : " << pWfxOut->cbSize;
+//     }
+
+//     // Set wave format
+//     Wfx.wFormatTag = WAVE_FORMAT_PCM;
+//     Wfx.wBitsPerSample = 16;
+//     Wfx.cbSize = 0;
+
+//     const int freqs[] = {48000, 44100, 16000, 96000, 32000, 8000};
+//     hr = S_FALSE;
+
+//     // Iterate over frequencies and channels, in order of priority
+//     for (unsigned int freq = 0; freq < sizeof(freqs) / sizeof(freqs[0]);
+//          freq++) {
+//       for (unsigned int chan = 0;
+//            chan < sizeof(_channelsPrioList) / sizeof(_channelsPrioList[0]);
+//            chan++) {
+//         Wfx.nChannels = _channelsPrioList[chan];
+//         Wfx.nSamplesPerSec = freqs[freq];
+//         Wfx.nBlockAlign = Wfx.nChannels * Wfx.wBitsPerSample / 8;
+//         Wfx.nAvgBytesPerSec = Wfx.nSamplesPerSec * Wfx.nBlockAlign;
+//         // If the method succeeds and the audio endpoint device supports the
+//         // specified stream format, it returns S_OK. If the method succeeds and
+//         // provides a closest match to the specified format, it returns S_FALSE.
+//         hr = _audioClient->IsFormatSupported(AUDCLNT_SHAREMODE_SHARED, &Wfx,
+//                                              &pWfxClosestMatch);
+//         if (hr == S_OK) {
+//           break;
+//         } else {
+//           if (pWfxClosestMatch) {
+//             RTC_LOG(INFO) << "nChannels=" << Wfx.nChannels
+//                           << ", nSamplesPerSec=" << Wfx.nSamplesPerSec
+//                           << " is not supported. Closest match: "
+//                            "nChannels="
+//                         << pWfxClosestMatch->nChannels << ", nSamplesPerSec="
+//                           << pWfxClosestMatch->nSamplesPerSec;
+//             CoTaskMemFree(pWfxClosestMatch);
+//             pWfxClosestMatch = nullptr;
+//           } else {
+//             RTC_LOG(INFO) << "nChannels=" << Wfx.nChannels
+//                           << ", nSamplesPerSec=" << Wfx.nSamplesPerSec
+//                           << " is not supported. No closest match.";
+//           }
+//         }
+//       }
+//       if (hr == S_OK)
+//         break;
+//     }
+
+//     // TODO(andrew): what happens in the event of failure in the above loop?
+//     //   Is _ptrClientOut->Initialize expected to fail?
+//     //   Same in InitRecording().
+//     if (hr == S_OK) {
+//       _audioFrameSize = Wfx.nBlockAlign;
+//       // Block size is the number of samples each channel in 10ms.
+//       _blockSize = Wfx.nSamplesPerSec / 100;
+//       _sampleRate = Wfx.nSamplesPerSec;
+//       _deviceSampleRate = Wfx.nSamplesPerSec;  // The device itself continues to
+//                                                // run at 44.1 kHz.
+//       _deviceBlockSize = Wfx.nSamplesPerSec / 100;
+//       _channels = Wfx.nChannels;
+
+//       RTC_LOG(LS_VERBOSE) << "VoE selected this rendering format:";
+//       RTC_LOG(LS_VERBOSE) << "wFormatTag         : 0x"
+//                           << rtc::ToHex(Wfx.wFormatTag) << " ("
+//                           << Wfx.wFormatTag << ")";
+//       RTC_LOG(LS_VERBOSE) << "nChannels          : " << Wfx.nChannels;
+//       RTC_LOG(LS_VERBOSE) << "nSamplesPerSec     : " << Wfx.nSamplesPerSec;
+//       RTC_LOG(LS_VERBOSE) << "nAvgBytesPerSec    : " << Wfx.nAvgBytesPerSec;
+//       RTC_LOG(LS_VERBOSE) << "nBlockAlign        : " << Wfx.nBlockAlign;
+//       RTC_LOG(LS_VERBOSE) << "wBitsPerSample     : " << Wfx.wBitsPerSample;
+//       RTC_LOG(LS_VERBOSE) << "cbSize             : " << Wfx.cbSize;
+//       RTC_LOG(LS_VERBOSE) << "Additional settings:";
+//       RTC_LOG(LS_VERBOSE) << "_playAudioFrameSize: " << _audioFrameSize;
+//       RTC_LOG(LS_VERBOSE) << "_playBlockSize     : " << _blockSize;
+//       RTC_LOG(LS_VERBOSE) << "_playChannels      : " << _channels;
+//     }
+
+//     // Create a rendering stream.
+//     //
+//     // ****************************************************************************
+//     // For a shared-mode stream that uses event-driven buffering, the caller
+//     // must set both hnsPeriodicity and hnsBufferDuration to 0. The Initialize
+//     // method determines how large a buffer to allocate based on the scheduling
+//     // period of the audio engine. Although the client's buffer processing
+//     // thread is event driven, the basic buffer management process, as described
+//     // previously, is unaltered. Each time the thread awakens, it should call
+//     // IAudioClient::GetCurrentPadding to determine how much data to write to a
+//     // rendering buffer or read from a capture buffer. In contrast to the two
+//     // buffers that the Initialize method allocates for an exclusive-mode stream
+//     // that uses event-driven buffering, a shared-mode stream requires a single
+//     // buffer.
+//     // ****************************************************************************
+//     //
+//     REFERENCE_TIME hnsBufferDuration =
+//         0;  // ask for minimum buffer size (default)
+//     if (_deviceSampleRate == 44100) {
+//       // Ask for a larger buffer size (30ms) when using 44.1kHz as render rate.
+//       // There seems to be a larger risk of underruns for 44.1 compared
+//       // with the default rate (48kHz). When using default, we set the requested
+//       // buffer duration to 0, which sets the buffer to the minimum size
+//       // required by the engine thread. The actual buffer size can then be
+//       // read by GetBufferSize() and it is 20ms on most machines.
+//       hnsBufferDuration = 30 * 10000;
+//     }
+//     hr = _audioClient->Initialize(
+//         AUDCLNT_SHAREMODE_SHARED,  // share Audio Engine with other applications
+//         AUDCLNT_STREAMFLAGS_EVENTCALLBACK,  // processing of the audio buffer by
+//                                             // the client will be event driven
+//         hnsBufferDuration,  // requested buffer capacity as a time value (in
+//                             // 100-nanosecond units)
+//         0,                  // periodicity
+//         &Wfx,               // selected wave format
+//         nullptr);           // session GUID
+
+//     if (FAILED(hr)) {
+//       RTC_LOG(LS_ERROR) << "IAudioClient::Initialize() failed:";
+//     }
+//     EXIT_ON_ERROR(hr);
+
+//     if (_pAudioBuffer) {
+//       // Update the audio buffer with the selected parameters
+//       _pAudioBuffer->SetPlayoutSampleRate(_sampleRate);
+//       _pAudioBuffer->SetPlayoutChannels((uint8_t)_channels);
+//     } else {
+//       // We can enter this state during CoreAudioIsSupported() when no
+//       // AudioDeviceImplementation has been created, hence the AudioDeviceBuffer
+//       // does not exist. It is OK to end up here since we don't initiate any
+//       // media in CoreAudioIsSupported().
+//       RTC_LOG(LS_VERBOSE)
+//           << "AudioDeviceBuffer must be attached before streaming can start";
+//     }
+
+//     // Get the actual size of the shared (endpoint buffer).
+//     // Typical value is 960 audio frames <=> 20ms @ 48kHz sample rate.
+//     UINT bufferFrameCount(0);
+//     hr = _audioClient->GetBufferSize(&bufferFrameCount);
+//     if (SUCCEEDED(hr)) {
+//       RTC_LOG(LS_VERBOSE) << "IAudioClient::GetBufferSize() => "
+//                           << bufferFrameCount << " (<=> "
+//                           << bufferFrameCount * _audioFrameSize << " bytes)";
+//     }
+
+//     // Set the event handle that the system signals when an audio buffer is
+//     // ready to be processed by the client.
+//     hr = _audioClient->SetEventHandle(_hSamplesReadyEvent);
+//     EXIT_ON_ERROR(hr);
+
+//     // Get an IAudioRenderClient interface.
+//     hr = _audioClient->GetService(__uuidof(IAudioRenderClient),
+//                                   (void**)&_audioRenderClient);
+//     EXIT_ON_ERROR(hr);
+
+//     // Get an ISimpleAudioVolume interface.
+//     hr = _audioClient->GetService(__uuidof(ISimpleAudioVolume),
+//                                   (void**)&_simpleAudioVolume);
+//     EXIT_ON_ERROR(hr);
+
+//     // Mark playout side as initialized
+//     _transportInitialized = true;
+
+//     CoTaskMemFree(pWfxOut);
+//     CoTaskMemFree(pWfxClosestMatch);
+
+//     RTC_LOG(LS_VERBOSE) << "render side is now initialized";
+//     return 0;
+
+//   Exit:
+//     _TraceCOMError(hr);
+//     CoTaskMemFree(pWfxOut);
+//     CoTaskMemFree(pWfxClosestMatch);
+//     return -1;
+//   }
+
+//   int32_t SetStereo(bool enable) override {
+//     if (!MixerIsInitialized()) {
+//       return -1;
+//     }
+
+//     if (enable) {
+//       _channelsPrioList[0] = 2;  // try stereo first
+//       _channelsPrioList[1] = 1;
+//       _channels = 2;
+//     } else {
+//       _channelsPrioList[0] = 1;  // try mono first
+//       _channelsPrioList[1] = 2;
+//       _channels = 1;
+//     }
+
+//     return 0;
+//   }
+// };
 
 namespace webrtc {
 
@@ -1681,8 +1681,8 @@ struct AudioDeviceWindowsCoreInternal {
   AudioDeviceBuffer* _pAudioBuffer = nullptr;
   bool _initialized = false;
 
-  CaptureDeviceInternal* _pCaptureDeviceHelper = nullptr;
-  RenderDeviceInternal* _pRenderDeviceHelper = nullptr;
+  // CaptureDeviceInternal* _pCaptureDeviceHelper = nullptr;
+  // RenderDeviceInternal* _pRenderDeviceHelper = nullptr;
 
   Microsoft::WRL::Wrappers::RoInitializeWrapper _roInitializeWrapper{
       RO_INIT_MULTITHREADED};
@@ -1735,17 +1735,17 @@ AudioDeviceWindowsCore::~AudioDeviceWindowsCore() {
 // ----------------------------------------------------------------------------
 
 void AudioDeviceWindowsCore::AttachAudioBuffer(AudioDeviceBuffer* audioBuffer) {
-  _internal->_pAudioBuffer = audioBuffer;
+  // _internal->_pAudioBuffer = audioBuffer;
 
-  if (_internal->_pRenderDeviceHelper != nullptr) {
-    _internal->_pRenderDeviceHelper->AttachAudioBuffer(
-        _internal->_pAudioBuffer);
-  }
+  // if (_internal->_pRenderDeviceHelper != nullptr) {
+  //   _internal->_pRenderDeviceHelper->AttachAudioBuffer(
+  //       _internal->_pAudioBuffer);
+  // }
 
-  if (_internal->_pCaptureDeviceHelper != nullptr) {
-    _internal->_pCaptureDeviceHelper->AttachAudioBuffer(
-        _internal->_pAudioBuffer);
-  }
+  // if (_internal->_pCaptureDeviceHelper != nullptr) {
+  //   _internal->_pCaptureDeviceHelper->AttachAudioBuffer(
+  //       _internal->_pAudioBuffer);
+  // }
 }
 
 // ----------------------------------------------------------------------------
@@ -1763,29 +1763,29 @@ int32_t AudioDeviceWindowsCore::ActiveAudioLayer(
 // ----------------------------------------------------------------------------
 
 AudioDeviceGeneric::InitStatus AudioDeviceWindowsCore::Init() {
-  rtc::CritScope lock(&_internal->_critSect);
+  // rtc::CritScope lock(&_internal->_critSect);
 
-  if (_internal->_initialized) {
-    return InitStatus::OK;
-  }
+  // if (_internal->_initialized) {
+  //   return InitStatus::OK;
+  // }
 
-  if (FAILED(_internal->_roInitializeWrapper)) {
-    return InitStatus::OTHER_ERROR;
-  }
+  // if (FAILED(_internal->_roInitializeWrapper)) {
+  //   return InitStatus::OTHER_ERROR;
+  // }
 
-  _internal->_pRenderDeviceHelper =
-      new (std::nothrow) RenderDeviceInternal(&_internal->_critSect);
-  _internal->_pCaptureDeviceHelper = new (std::nothrow) CaptureDeviceInternal(
-      &_internal->_critSect, &_internal->_pRenderDeviceHelper->_sndCardDelay);
+  // _internal->_pRenderDeviceHelper =
+  //     new (std::nothrow) RenderDeviceInternal(&_internal->_critSect);
+  // _internal->_pCaptureDeviceHelper = new (std::nothrow) CaptureDeviceInternal(
+  //     &_internal->_critSect, &_internal->_pRenderDeviceHelper->_sndCardDelay);
 
-  if (_internal->_pAudioBuffer != nullptr) {
-    _internal->_pRenderDeviceHelper->AttachAudioBuffer(
-        _internal->_pAudioBuffer);
-    _internal->_pCaptureDeviceHelper->AttachAudioBuffer(
-        _internal->_pAudioBuffer);
-  }
+  // if (_internal->_pAudioBuffer != nullptr) {
+  //   _internal->_pRenderDeviceHelper->AttachAudioBuffer(
+  //       _internal->_pAudioBuffer);
+  //   _internal->_pCaptureDeviceHelper->AttachAudioBuffer(
+  //       _internal->_pAudioBuffer);
+  // }
 
-  _internal->_initialized = true;
+  // _internal->_initialized = true;
 
   return InitStatus::OK;
 }
@@ -1795,16 +1795,16 @@ AudioDeviceGeneric::InitStatus AudioDeviceWindowsCore::Init() {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::Terminate() {
-  rtc::CritScope lock(&_internal->_critSect);
+  // rtc::CritScope lock(&_internal->_critSect);
 
-  if (!_internal->_initialized) {
-    return 0;
-  }
+  // if (!_internal->_initialized) {
+  //   return 0;
+  // }
 
-  delete _internal->_pCaptureDeviceHelper;
-  delete _internal->_pRenderDeviceHelper;
+  // delete _internal->_pCaptureDeviceHelper;
+  // delete _internal->_pRenderDeviceHelper;
 
-  _internal->_initialized = false;
+  // _internal->_initialized = false;
 
   return 0;
 }
@@ -1823,7 +1823,8 @@ bool AudioDeviceWindowsCore::Initialized() const {
 
 int32_t AudioDeviceWindowsCore::InitSpeaker() {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->InitMixer();
+  // /*return _internal->RenderDeviceHelper->InitMixer();*/return 0;
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1832,7 +1833,8 @@ int32_t AudioDeviceWindowsCore::InitSpeaker() {
 
 int32_t AudioDeviceWindowsCore::InitMicrophone() {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->InitMixer();
+  // return _internal->_pCaptureDeviceHelper->InitMixer();
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1840,7 +1842,8 @@ int32_t AudioDeviceWindowsCore::InitMicrophone() {
 // ----------------------------------------------------------------------------
 
 bool AudioDeviceWindowsCore::SpeakerIsInitialized() const {
-  return _internal->_pRenderDeviceHelper->MixerIsInitialized();
+  // return _internal->_pRenderDeviceHelper->MixerIsInitialized();
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1848,7 +1851,8 @@ bool AudioDeviceWindowsCore::SpeakerIsInitialized() const {
 // ----------------------------------------------------------------------------
 
 bool AudioDeviceWindowsCore::MicrophoneIsInitialized() const {
-  return _internal->_pCaptureDeviceHelper->MixerIsInitialized();
+  // return _internal->_pCaptureDeviceHelper->MixerIsInitialized();
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1857,7 +1861,8 @@ bool AudioDeviceWindowsCore::MicrophoneIsInitialized() const {
 
 int32_t AudioDeviceWindowsCore::SpeakerVolumeIsAvailable(bool& available) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->VolumeIsAvailable(available);
+  // return _internal->_pRenderDeviceHelper->VolumeIsAvailable(available);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1866,7 +1871,8 @@ int32_t AudioDeviceWindowsCore::SpeakerVolumeIsAvailable(bool& available) {
 
 int32_t AudioDeviceWindowsCore::SetSpeakerVolume(uint32_t volume) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->SetVolume(volume);
+  // return _internal->_pRenderDeviceHelper->SetVolume(volume);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1875,7 +1881,8 @@ int32_t AudioDeviceWindowsCore::SetSpeakerVolume(uint32_t volume) {
 
 int32_t AudioDeviceWindowsCore::SpeakerVolume(uint32_t& volume) const {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->Volume(volume);
+  // return _internal->_pRenderDeviceHelper->Volume(volume);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1888,7 +1895,8 @@ int32_t AudioDeviceWindowsCore::SpeakerVolume(uint32_t& volume) const {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::MaxSpeakerVolume(uint32_t& maxVolume) const {
-  return _internal->_pRenderDeviceHelper->MaxVolume(maxVolume);
+  // return _internal->_pRenderDeviceHelper->MaxVolume(maxVolume);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1896,7 +1904,8 @@ int32_t AudioDeviceWindowsCore::MaxSpeakerVolume(uint32_t& maxVolume) const {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::MinSpeakerVolume(uint32_t& minVolume) const {
-  return _internal->_pRenderDeviceHelper->MinVolume(minVolume);
+  // return _internal->_pRenderDeviceHelper->MinVolume(minVolume);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1905,7 +1914,8 @@ int32_t AudioDeviceWindowsCore::MinSpeakerVolume(uint32_t& minVolume) const {
 
 int32_t AudioDeviceWindowsCore::SpeakerMuteIsAvailable(bool& available) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->MuteIsAvailable(available);
+  // return _internal->_pRenderDeviceHelper->MuteIsAvailable(available);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1914,7 +1924,8 @@ int32_t AudioDeviceWindowsCore::SpeakerMuteIsAvailable(bool& available) {
 
 int32_t AudioDeviceWindowsCore::SetSpeakerMute(bool enable) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->SetMute(enable);
+  // return _internal->_pRenderDeviceHelper->SetMute(enable);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1923,7 +1934,8 @@ int32_t AudioDeviceWindowsCore::SetSpeakerMute(bool enable) {
 
 int32_t AudioDeviceWindowsCore::SpeakerMute(bool& enabled) const {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->Mute(enabled);
+  // return _internal->_pRenderDeviceHelper->Mute(enabled);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1932,7 +1944,8 @@ int32_t AudioDeviceWindowsCore::SpeakerMute(bool& enabled) const {
 
 int32_t AudioDeviceWindowsCore::MicrophoneMuteIsAvailable(bool& available) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->MuteIsAvailable(available);
+  // return _internal->_pCaptureDeviceHelper->MuteIsAvailable(available);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1941,7 +1954,8 @@ int32_t AudioDeviceWindowsCore::MicrophoneMuteIsAvailable(bool& available) {
 
 int32_t AudioDeviceWindowsCore::SetMicrophoneMute(bool enable) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->SetMute(enable);
+  // return _internal->_pCaptureDeviceHelper->SetMute(enable);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1950,7 +1964,8 @@ int32_t AudioDeviceWindowsCore::SetMicrophoneMute(bool enable) {
 
 int32_t AudioDeviceWindowsCore::MicrophoneMute(bool& enabled) const {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->Mute(enabled);
+  // return _internal->_pCaptureDeviceHelper->Mute(enabled);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1958,7 +1973,8 @@ int32_t AudioDeviceWindowsCore::MicrophoneMute(bool& enabled) const {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::StereoRecordingIsAvailable(bool& available) {
-  return _internal->_pCaptureDeviceHelper->StereoIsAvailable(available);
+  // return _internal->_pCaptureDeviceHelper->StereoIsAvailable(available);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1967,7 +1983,8 @@ int32_t AudioDeviceWindowsCore::StereoRecordingIsAvailable(bool& available) {
 
 int32_t AudioDeviceWindowsCore::SetStereoRecording(bool enable) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->SetStereo(enable);
+  // return _internal->_pCaptureDeviceHelper->SetStereo(enable);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1975,7 +1992,8 @@ int32_t AudioDeviceWindowsCore::SetStereoRecording(bool enable) {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::StereoRecording(bool& enabled) const {
-  return _internal->_pCaptureDeviceHelper->Stereo(enabled);
+  // return _internal->_pCaptureDeviceHelper->Stereo(enabled);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1983,7 +2001,8 @@ int32_t AudioDeviceWindowsCore::StereoRecording(bool& enabled) const {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::StereoPlayoutIsAvailable(bool& available) {
-  return _internal->_pRenderDeviceHelper->StereoIsAvailable(available);
+  // return _internal->_pRenderDeviceHelper->StereoIsAvailable(available);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -1992,7 +2011,8 @@ int32_t AudioDeviceWindowsCore::StereoPlayoutIsAvailable(bool& available) {
 
 int32_t AudioDeviceWindowsCore::SetStereoPlayout(bool enable) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->SetStereo(enable);
+  // return _internal->_pRenderDeviceHelper->SetStereo(enable);
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2000,7 +2020,8 @@ int32_t AudioDeviceWindowsCore::SetStereoPlayout(bool enable) {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::StereoPlayout(bool& enabled) const {
-  return _internal->_pRenderDeviceHelper->Stereo(enabled);
+  // /*return _internal->RenderDeviceHelper->Stereo(enabled);*/return 0;
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2009,7 +2030,8 @@ int32_t AudioDeviceWindowsCore::StereoPlayout(bool& enabled) const {
 
 int32_t AudioDeviceWindowsCore::MicrophoneVolumeIsAvailable(bool& available) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->VolumeIsAvailable(available);
+  // /*return _internal->CaptureDeviceHelper->VolumeIsAvailable(available);*/return 0;
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2018,7 +2040,8 @@ int32_t AudioDeviceWindowsCore::MicrophoneVolumeIsAvailable(bool& available) {
 
 int32_t AudioDeviceWindowsCore::SetMicrophoneVolume(uint32_t volume) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->SetVolume(volume);
+  // /*return _internal->CaptureDeviceHelper->SetVolume(volume);*/return 0;
+  return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2027,7 +2050,7 @@ int32_t AudioDeviceWindowsCore::SetMicrophoneVolume(uint32_t volume) {
 
 int32_t AudioDeviceWindowsCore::MicrophoneVolume(uint32_t& volume) const {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->Volume(volume);
+  /*return _internal->CaptureDeviceHelper->Volume(volume);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2040,7 +2063,7 @@ int32_t AudioDeviceWindowsCore::MicrophoneVolume(uint32_t& volume) const {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::MaxMicrophoneVolume(uint32_t& maxVolume) const {
-  return _internal->_pCaptureDeviceHelper->MaxVolume(maxVolume);
+  /*return _internal->CaptureDeviceHelper->MaxVolume(maxVolume);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2048,7 +2071,7 @@ int32_t AudioDeviceWindowsCore::MaxMicrophoneVolume(uint32_t& maxVolume) const {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::MinMicrophoneVolume(uint32_t& minVolume) const {
-  return _internal->_pCaptureDeviceHelper->MinVolume(minVolume);
+  /*return _internal->CaptureDeviceHelper->MinVolume(minVolume);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2057,7 +2080,7 @@ int32_t AudioDeviceWindowsCore::MinMicrophoneVolume(uint32_t& minVolume) const {
 
 int16_t AudioDeviceWindowsCore::PlayoutDevices() {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->Devices();
+  /*return _internal->RenderDeviceHelper->Devices();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2066,7 +2089,7 @@ int16_t AudioDeviceWindowsCore::PlayoutDevices() {
 
 int32_t AudioDeviceWindowsCore::SetPlayoutDevice(uint16_t index) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->SetDevice(index);
+  /*return _internal->RenderDeviceHelper->SetDevice(index);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2076,7 +2099,7 @@ int32_t AudioDeviceWindowsCore::SetPlayoutDevice(uint16_t index) {
 int32_t AudioDeviceWindowsCore::SetPlayoutDevice(
     AudioDeviceModule::WindowsDeviceType device) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->SetDevice(device);
+  /*return _internal->RenderDeviceHelper->SetDevice(device);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2088,7 +2111,7 @@ int32_t AudioDeviceWindowsCore::PlayoutDeviceName(
     char name[kAdmMaxDeviceNameSize],
     char guid[kAdmMaxGuidSize]) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->DeviceName(index, name, guid);
+  /*return _internal->RenderDeviceHelper->DeviceName(index, name, guid);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2100,7 +2123,7 @@ int32_t AudioDeviceWindowsCore::RecordingDeviceName(
     char name[kAdmMaxDeviceNameSize],
     char guid[kAdmMaxGuidSize]) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->DeviceName(index, name, guid);
+  /*return _internal->CaptureDeviceHelper->DeviceName(index, name, guid);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2109,7 +2132,7 @@ int32_t AudioDeviceWindowsCore::RecordingDeviceName(
 
 int16_t AudioDeviceWindowsCore::RecordingDevices() {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->Devices();
+  /*return _internal->CaptureDeviceHelper->Devices();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2118,7 +2141,7 @@ int16_t AudioDeviceWindowsCore::RecordingDevices() {
 
 int32_t AudioDeviceWindowsCore::SetRecordingDevice(uint16_t index) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->SetDevice(index);
+  /*return _internal->CaptureDeviceHelper->SetDevice(index);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2128,7 +2151,7 @@ int32_t AudioDeviceWindowsCore::SetRecordingDevice(uint16_t index) {
 int32_t AudioDeviceWindowsCore::SetRecordingDevice(
     AudioDeviceModule::WindowsDeviceType device) {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->SetDevice(device);
+  /*return _internal->CaptureDeviceHelper->SetDevice(device);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2136,7 +2159,7 @@ int32_t AudioDeviceWindowsCore::SetRecordingDevice(
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::PlayoutIsAvailable(bool& available) {
-  return _internal->_pRenderDeviceHelper->TransportIsAvailable(available);
+  /*return _internal->RenderDeviceHelper->TransportIsAvailable(available);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2144,7 +2167,7 @@ int32_t AudioDeviceWindowsCore::PlayoutIsAvailable(bool& available) {
 // ----------------------------------------------------------------------------
 
 int32_t AudioDeviceWindowsCore::RecordingIsAvailable(bool& available) {
-  return _internal->_pCaptureDeviceHelper->TransportIsAvailable(available);
+  /*return _internal->CaptureDeviceHelper->TransportIsAvailable(available);*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2153,7 +2176,7 @@ int32_t AudioDeviceWindowsCore::RecordingIsAvailable(bool& available) {
 
 int32_t AudioDeviceWindowsCore::InitPlayout() {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->InitTransport();
+  /*return _internal->RenderDeviceHelper->InitTransport();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2162,7 +2185,7 @@ int32_t AudioDeviceWindowsCore::InitPlayout() {
 
 int32_t AudioDeviceWindowsCore::InitRecording() {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->InitTransport();
+  /*return _internal->CaptureDeviceHelper->InitTransport();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2171,7 +2194,7 @@ int32_t AudioDeviceWindowsCore::InitRecording() {
 
 int32_t AudioDeviceWindowsCore::StartRecording() {
   rtc::CritScope critScoped(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->StartTransport();
+  /*return _internal->CaptureDeviceHelper->StartTransport();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2180,7 +2203,7 @@ int32_t AudioDeviceWindowsCore::StartRecording() {
 
 int32_t AudioDeviceWindowsCore::StopRecording() {
   rtc::CritScope lock(&_internal->_critSect);
-  return _internal->_pCaptureDeviceHelper->StopTransport();
+  /*return _internal->CaptureDeviceHelper->StopTransport();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2188,7 +2211,7 @@ int32_t AudioDeviceWindowsCore::StopRecording() {
 // ----------------------------------------------------------------------------
 
 bool AudioDeviceWindowsCore::RecordingIsInitialized() const {
-  return _internal->_pCaptureDeviceHelper->TransportIsInitialized();
+  /*return _internal->CaptureDeviceHelper->TransportIsInitialized();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2196,7 +2219,7 @@ bool AudioDeviceWindowsCore::RecordingIsInitialized() const {
 // ----------------------------------------------------------------------------
 
 bool AudioDeviceWindowsCore::Recording() const {
-  return _internal->_pCaptureDeviceHelper->Transporting();
+  /*return _internal->CaptureDeviceHelper->Transporting();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2204,7 +2227,7 @@ bool AudioDeviceWindowsCore::Recording() const {
 // ----------------------------------------------------------------------------
 
 bool AudioDeviceWindowsCore::PlayoutIsInitialized() const {
-  return _internal->_pRenderDeviceHelper->TransportIsInitialized();
+  /*return _internal->RenderDeviceHelper->TransportIsInitialized();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2213,7 +2236,7 @@ bool AudioDeviceWindowsCore::PlayoutIsInitialized() const {
 
 int32_t AudioDeviceWindowsCore::StartPlayout() {
   rtc::CritScope critScoped(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->StartTransport();
+  /*return _internal->RenderDeviceHelper->StartTransport();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2222,7 +2245,7 @@ int32_t AudioDeviceWindowsCore::StartPlayout() {
 
 int32_t AudioDeviceWindowsCore::StopPlayout() {
   rtc::CritScope critScoped(&_internal->_critSect);
-  return _internal->_pRenderDeviceHelper->StopTransport();
+  /*return _internal->RenderDeviceHelper->StopTransport();*/return 0;
 }
 
 // ----------------------------------------------------------------------------
@@ -2231,8 +2254,8 @@ int32_t AudioDeviceWindowsCore::StopPlayout() {
 
 int32_t AudioDeviceWindowsCore::PlayoutDelay(uint16_t& delayMS) const {
   rtc::CritScope critScoped(&_internal->_critSect);
-  delayMS =
-      static_cast<uint16_t>(_internal->_pRenderDeviceHelper->_sndCardDelay);
+  // delayMS =
+  //     static_cast<uint16_t>(_internal->_pRenderDeviceHelper->_sndCardDelay);
   return 0;
 }
 
@@ -2241,7 +2264,7 @@ int32_t AudioDeviceWindowsCore::PlayoutDelay(uint16_t& delayMS) const {
 // ----------------------------------------------------------------------------
 
 bool AudioDeviceWindowsCore::Playing() const {
-  return _internal->_pRenderDeviceHelper->Transporting();
+  /*return _internal->RenderDeviceHelper->Transporting();*/return 0;
 }
 
 bool AudioDeviceWindowsCore::BuiltInAECIsAvailable() const {
diff --git a/modules/audio_device/win/core_audio_base_win.cc b/modules/audio_device/win/core_audio_base_win.cc
index bf3bf1ab80..5dd88a5924 100644
--- a/modules/audio_device/win/core_audio_base_win.cc
+++ b/modules/audio_device/win/core_audio_base_win.cc
@@ -13,6 +13,7 @@
 
 #include <memory>
 #include <string>
+#include <comdef.h>
 
 #include "rtc_base/arraysize.h"
 #include "rtc_base/checks.h"
@@ -56,18 +57,18 @@ const char* DirectionToString(CoreAudioBase::Direction direction) {
   }
 }
 
-const char* RoleToString(const ERole role) {
-  switch (role) {
-    case eConsole:
-      return "Console";
-    case eMultimedia:
-      return "Multimedia";
-    case eCommunications:
-      return "Communications";
-    default:
-      return "Unsupported";
-  }
-}
+// const char* RoleToString(const ERole role) {
+//   switch (role) {
+//     case eConsole:
+//       return "Console";
+//     case eMultimedia:
+//       return "Multimedia";
+//     case eCommunications:
+//       return "Communications";
+//     default:
+//       return "Unsupported";
+//   }
+// }
 
 std::string IndexToString(int index) {
   std::string ss = std::to_string(index);
@@ -188,9 +189,9 @@ CoreAudioBase::~CoreAudioBase() {
   RTC_DCHECK_EQ(ref_count_, 1);
 }
 
-EDataFlow CoreAudioBase::GetDataFlow() const {
-  return direction_ == CoreAudioBase::Direction::kOutput ? eRender : eCapture;
-}
+// EDataFlow CoreAudioBase::GetDataFlow() const {
+//   return direction_ == CoreAudioBase::Direction::kOutput ? eRender : eCapture;
+// }
 
 bool CoreAudioBase::IsRestarting() const {
   return is_restarting_;
@@ -201,7 +202,7 @@ int64_t CoreAudioBase::TimeSinceStart() const {
 }
 
 int CoreAudioBase::NumberOfActiveDevices() const {
-  return core_audio_utility::NumberOfActiveDevices(GetDataFlow());
+  return 0;//core_audio_utility::NumberOfActiveDevices(GetDataFlow());
 }
 
 int CoreAudioBase::NumberOfEnumeratedDevices() const {
@@ -348,36 +349,36 @@ bool CoreAudioBase::Init() {
   // parameters which are required to create an audio client. It is up to the
   // parent class to set |device_index_| and |device_id_|.
   std::string device_id = AudioDeviceName::kDefaultDeviceId;
-  ERole role = ERole();
-  if (IsDefaultDevice(device_index_)) {
-    role = eConsole;
-  } else if (IsDefaultCommunicationsDevice(device_index_)) {
-    role = eCommunications;
-  } else {
-    device_id = device_id_;
-  }
-  RTC_LOG(LS_INFO) << "Unique device identifier: device_id=" << device_id
-                   << ", role=" << RoleToString(role);
-
-  // Create an IAudioClient interface which enables us to create and initialize
-  // an audio stream between an audio application and the audio engine.
+  // ERole role = ERole();
+  // if (IsDefaultDevice(device_index_)) {
+  //   role = eConsole;
+  // } else if (IsDefaultCommunicationsDevice(device_index_)) {
+  //   role = eCommunications;
+  // } else {
+  //   device_id = device_id_;
+  // }
+  // RTC_LOG(LS_INFO) << "Unique device identifier: device_id=" << device_id
+  //                  << ", role=" << RoleToString(role);
+
+  // // Create an IAudioClient interface which enables us to create and initialize
+  // // an audio stream between an audio application and the audio engine.
   ComPtr<IAudioClient> audio_client;
-  if (core_audio_utility::GetAudioClientVersion() == 3) {
-    RTC_DLOG(INFO) << "Using IAudioClient3";
-    audio_client =
-        core_audio_utility::CreateClient3(device_id, GetDataFlow(), role);
-  } else if (core_audio_utility::GetAudioClientVersion() == 2) {
-    RTC_DLOG(INFO) << "Using IAudioClient2";
-    audio_client =
-        core_audio_utility::CreateClient2(device_id, GetDataFlow(), role);
-  } else {
-    RTC_DLOG(INFO) << "Using IAudioClient";
-    audio_client =
-        core_audio_utility::CreateClient(device_id, GetDataFlow(), role);
-  }
-  if (!audio_client) {
-    return false;
-  }
+  // if (core_audio_utility::GetAudioClientVersion() == 3) {
+  //   RTC_DLOG(INFO) << "Using IAudioClient3";
+  //   audio_client =
+  //       core_audio_utility::CreateClient3(device_id, GetDataFlow(), role);
+  // } else if (core_audio_utility::GetAudioClientVersion() == 2) {
+  //   RTC_DLOG(INFO) << "Using IAudioClient2";
+  //   audio_client =
+  //       core_audio_utility::CreateClient2(device_id, GetDataFlow(), role);
+  // } else {
+  //   RTC_DLOG(INFO) << "Using IAudioClient";
+  //   audio_client =
+  //       core_audio_utility::CreateClient(device_id, GetDataFlow(), role);
+  // }
+  // if (!audio_client) {
+  //   return false;
+  // }
 
   // Set extra client properties before initialization if the audio client
   // supports it.
@@ -395,10 +396,10 @@ bool CoreAudioBase::Init() {
   // rate has been defined by the user. Rate conversion will be performed by
   // the audio engine to match the client if needed.
   AudioParameters params;
-  HRESULT res = sample_rate_ ? core_audio_utility::GetPreferredAudioParameters(
-                                   audio_client.Get(), &params, *sample_rate_)
-                             : core_audio_utility::GetPreferredAudioParameters(
-                                   audio_client.Get(), &params);
+  HRESULT res = 0;//sample_rate_ ? core_audio_utility::GetPreferredAudioParameters(
+  //                                  audio_client.Get(), &params, *sample_rate_)
+  //                            : core_audio_utility::GetPreferredAudioParameters(
+  //                                  audio_client.Get(), &params);
   if (FAILED(res)) {
     return false;
   }
@@ -429,9 +430,9 @@ bool CoreAudioBase::Init() {
   // Add the parts which are unique for the WAVE_FORMAT_EXTENSIBLE structure.
   format_.Samples.wValidBitsPerSample =
       rtc::dchecked_cast<WORD>(params.bits_per_sample());
-  format_.dwChannelMask =
-      format->nChannels == 1 ? KSAUDIO_SPEAKER_MONO : KSAUDIO_SPEAKER_STEREO;
-  format_.SubFormat = KSDATAFORMAT_SUBTYPE_PCM;
+  format_.dwChannelMask = 0;
+      //format->nChannels == 1 ? KSAUDIO_SPEAKER_MONO : KSAUDIO_SPEAKER_STEREO;
+  //format_.SubFormat = KSDATAFORMAT_SUBTYPE_PCM;
   RTC_DLOG(INFO) << core_audio_utility::WaveFormatToString(&format_);
 
   // Verify that the format is supported but exclude the test if the default
@@ -572,13 +573,13 @@ bool CoreAudioBase::Start() {
   }
 
   // Start streaming data between the endpoint buffer and the audio engine.
-  _com_error error = audio_client_->Start();
-  if (FAILED(error.Error())) {
-    StopThread();
-    RTC_LOG(LS_ERROR) << "IAudioClient::Start failed: "
-                      << core_audio_utility::ErrorToString(error);
-    return false;
-  }
+  // _com_error error = audio_client_->Start();
+  // if (FAILED(error.Error())) {
+  //   StopThread();
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::Start failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  //   return false;
+  // }
 
   start_time_ = rtc::TimeMillis();
   num_data_callbacks_ = 0;
@@ -592,44 +593,44 @@ bool CoreAudioBase::Stop() {
   RTC_DLOG(INFO) << "total activity time: " << TimeSinceStart();
 
   // Stop audio streaming.
-  _com_error error = audio_client_->Stop();
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::Stop failed: "
-                      << core_audio_utility::ErrorToString(error);
-  }
-  // Stop and destroy the audio thread but only when a restart attempt is not
-  // ongoing.
-  if (!IsRestarting()) {
-    StopThread();
-  }
-
-  // Flush all pending data and reset the audio clock stream position to 0.
-  error = audio_client_->Reset();
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::Reset failed: "
-                      << core_audio_utility::ErrorToString(error);
-  }
-
-  if (IsOutput()) {
-    // Extra safety check to ensure that the buffers are cleared.
-    // If the buffers are not cleared correctly, the next call to Start()
-    // would fail with AUDCLNT_E_BUFFER_ERROR at
-    // IAudioRenderClient::GetBuffer().
-    UINT32 num_queued_frames = 0;
-    audio_client_->GetCurrentPadding(&num_queued_frames);
-    RTC_DCHECK_EQ(0u, num_queued_frames);
-  }
-
-  // Delete the previous registration by the client to receive notifications
-  // about audio session events.
-  RTC_DLOG(INFO) << "audio session state: "
-                 << SessionStateToString(GetAudioSessionState());
-  error = audio_session_control_->UnregisterAudioSessionNotification(this);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR)
-        << "IAudioSessionControl::UnregisterAudioSessionNotification failed: "
-        << core_audio_utility::ErrorToString(error);
-  }
+  // _com_error error = audio_client_->Stop();
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::Stop failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  // }
+  // // Stop and destroy the audio thread but only when a restart attempt is not
+  // // ongoing.
+  // if (!IsRestarting()) {
+  //   StopThread();
+  // }
+
+  // // Flush all pending data and reset the audio clock stream position to 0.
+  // error = audio_client_->Reset();
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::Reset failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  // }
+
+  // if (IsOutput()) {
+  //   // Extra safety check to ensure that the buffers are cleared.
+  //   // If the buffers are not cleared correctly, the next call to Start()
+  //   // would fail with AUDCLNT_E_BUFFER_ERROR at
+  //   // IAudioRenderClient::GetBuffer().
+  //   UINT32 num_queued_frames = 0;
+  //   audio_client_->GetCurrentPadding(&num_queued_frames);
+  //   RTC_DCHECK_EQ(0u, num_queued_frames);
+  // }
+
+  // // Delete the previous registration by the client to receive notifications
+  // // about audio session events.
+  // RTC_DLOG(INFO) << "audio session state: "
+  //                << SessionStateToString(GetAudioSessionState());
+  // error = audio_session_control_->UnregisterAudioSessionNotification(this);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR)
+  //       << "IAudioSessionControl::UnregisterAudioSessionNotification failed: "
+  //       << core_audio_utility::ErrorToString(error);
+  // }
 
   // To ensure that the restart process is as simple as possible, the audio
   // thread is not destroyed during restart attempts triggered by internal
@@ -665,12 +666,12 @@ bool CoreAudioBase::IsVolumeControlAvailable(bool* available) const {
 
   // Try to use the valid volume control.
   float volume = 0.0;
-  _com_error error = audio_volume->GetMasterVolume(&volume);
-  if (error.Error() != S_OK) {
-    RTC_LOG(LS_ERROR) << "ISimpleAudioVolume::GetMasterVolume failed: "
-                      << core_audio_utility::ErrorToString(error);
-    *available = false;
-  }
+  // _com_error error = audio_volume->GetMasterVolume(&volume);
+  // if (error.Error() != S_OK) {
+  //   RTC_LOG(LS_ERROR) << "ISimpleAudioVolume::GetMasterVolume failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  //   *available = false;
+  // }
   RTC_DLOG(INFO) << "master volume for output audio session: " << volume;
 
   *available = true;
@@ -737,11 +738,11 @@ bool CoreAudioBase::SwitchDeviceIfNeeded() {
 
   // Ensure that at least one device exists and can be utilized. The most
   // probable cause for ending up here is that a device has been removed.
-  if (core_audio_utility::NumberOfActiveDevices(IsInput() ? eCapture
-                                                          : eRender) < 1) {
-    RTC_DLOG(LS_ERROR) << "All devices are disabled or removed";
-    return false;
-  }
+  // if (core_audio_utility::NumberOfActiveDevices(IsInput() ? eCapture
+  //                                                         : eRender) < 1) {
+  //   RTC_DLOG(LS_ERROR) << "All devices are disabled or removed";
+  //   return false;
+  // }
 
   // Get the unique device ID for the index which is currently used. It seems
   // safe to assume that if the ID is the same as the existing device ID, then
@@ -766,11 +767,11 @@ bool CoreAudioBase::SwitchDeviceIfNeeded() {
 AudioSessionState CoreAudioBase::GetAudioSessionState() const {
   AudioSessionState state = AudioSessionStateInactive;
   RTC_DCHECK(audio_session_control_.Get());
-  _com_error error = audio_session_control_->GetState(&state);
-  if (FAILED(error.Error())) {
-    RTC_DLOG(LS_ERROR) << "IAudioSessionControl::GetState failed: "
-                       << core_audio_utility::ErrorToString(error);
-  }
+  // _com_error error = audio_session_control_->GetState(&state);
+  // if (FAILED(error.Error())) {
+  //   RTC_DLOG(LS_ERROR) << "IAudioSessionControl::GetState failed: "
+  //                      << core_audio_utility::ErrorToString(error);
+  // }
   return state;
 }
 
@@ -898,15 +899,15 @@ void CoreAudioBase::ThreadRun() {
   // The device frequency is the frequency generated by the hardware clock in
   // the audio device. The GetFrequency() method reports a constant frequency.
   UINT64 device_frequency = 0;
-  _com_error result(S_FALSE);
-  if (audio_clock_) {
-    RTC_DCHECK(IsOutput());
-    result = audio_clock_->GetFrequency(&device_frequency);
-    if (FAILED(result.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioClock::GetFrequency failed: "
-                        << core_audio_utility::ErrorToString(result);
-    }
-  }
+  // _com_error result(S_FALSE);
+  // if (audio_clock_) {
+  //   RTC_DCHECK(IsOutput());
+  //   result = audio_clock_->GetFrequency(&device_frequency);
+  //   if (FAILED(result.Error())) {
+  //     RTC_LOG(LS_ERROR) << "IAudioClock::GetFrequency failed: "
+  //                       << core_audio_utility::ErrorToString(result);
+  //   }
+  // }
 
   // Keep streaming audio until the stop event or the stream-switch event
   // is signaled. An error event can also break the main thread loop.
@@ -933,21 +934,21 @@ void CoreAudioBase::ThreadRun() {
     }
   }
 
-  if (streaming && error) {
-    RTC_LOG(LS_ERROR) << "[" << DirectionToString(direction())
-                      << "] WASAPI streaming failed.";
-    // Stop audio streaming since something has gone wrong in our main thread
-    // loop. Note that, we are still in a "started" state, hence a Stop() call
-    // is required to join the thread properly.
-    result = audio_client_->Stop();
-    if (FAILED(result.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioClient::Stop failed: "
-                        << core_audio_utility::ErrorToString(result);
-    }
+  // if (streaming && error) {
+  //   RTC_LOG(LS_ERROR) << "[" << DirectionToString(direction())
+  //                     << "] WASAPI streaming failed.";
+  //   // Stop audio streaming since something has gone wrong in our main thread
+  //   // loop. Note that, we are still in a "started" state, hence a Stop() call
+  //   // is required to join the thread properly.
+  //   result = audio_client_->Stop();
+  //   if (FAILED(result.Error())) {
+  //     RTC_LOG(LS_ERROR) << "IAudioClient::Stop failed: "
+  //                       << core_audio_utility::ErrorToString(result);
+  //   }
 
     // TODO(henrika): notify clients that something has gone wrong and that
     // this stream should be destroyed instead of reused in the future.
-  }
+  // }
 
   RTC_DLOG(INFO) << "[" << DirectionToString(direction())
                  << "] ...ThreadRun stops";
diff --git a/modules/audio_device/win/core_audio_base_win.h b/modules/audio_device/win/core_audio_base_win.h
index 87f306f541..b02303139f 100644
--- a/modules/audio_device/win/core_audio_base_win.h
+++ b/modules/audio_device/win/core_audio_base_win.h
@@ -119,7 +119,7 @@ class CoreAudioBase : public IAudioSessionEvents {
   bool IsDefaultCommunicationsDevice(int index) const;
   bool IsDefaultDeviceId(const std::string& device_id) const;
   bool IsDefaultCommunicationsDeviceId(const std::string& device_id) const;
-  EDataFlow GetDataFlow() const;
+  // EDataFlow GetDataFlow() const;
   bool IsRestarting() const;
   int64_t TimeSinceStart() const;
 
diff --git a/modules/audio_device/win/core_audio_input_win.cc b/modules/audio_device/win/core_audio_input_win.cc
index 8ea74267df..86dfff5646 100644
--- a/modules/audio_device/win/core_audio_input_win.cc
+++ b/modules/audio_device/win/core_audio_input_win.cc
@@ -11,6 +11,7 @@
 #include "modules/audio_device/win/core_audio_input_win.h"
 
 #include <memory>
+#include <comdef.h>
 
 #include "modules/audio_device/audio_device_buffer.h"
 #include "modules/audio_device/fine_audio_buffer.h"
@@ -58,7 +59,7 @@ int CoreAudioInput::Terminate() {
 
 int CoreAudioInput::NumDevices() const {
   RTC_DCHECK_RUN_ON(&thread_checker_);
-  return core_audio_utility::NumberOfActiveDevices(eCapture);
+  return 0;//core_audio_utility::NumberOfActiveDevices(eCapture);
 }
 
 int CoreAudioInput::SetDevice(int index) {
@@ -276,43 +277,43 @@ bool CoreAudioInput::OnDataCallback(uint64_t device_frequency) {
     RTC_LOG(INFO) << "--- Input audio stream is alive ---";
   }
   UINT32 num_frames_in_next_packet = 0;
-  _com_error error =
-      audio_capture_client_->GetNextPacketSize(&num_frames_in_next_packet);
-  if (error.Error() == AUDCLNT_E_DEVICE_INVALIDATED) {
-    // Avoid breaking the thread loop implicitly by returning false and return
-    // true instead for AUDCLNT_E_DEVICE_INVALIDATED even it is a valid error
-    // message. We will use notifications about device changes instead to stop
-    // data callbacks and attempt to restart streaming .
-    RTC_DLOG(LS_ERROR) << "AUDCLNT_E_DEVICE_INVALIDATED";
-    return true;
-  }
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioCaptureClient::GetNextPacketSize failed: "
-                      << core_audio_utility::ErrorToString(error);
-    return false;
-  }
+  // _com_error error =
+  //     audio_capture_client_->GetNextPacketSize(&num_frames_in_next_packet);
+  // if (error.Error() == AUDCLNT_E_DEVICE_INVALIDATED) {
+  //   // Avoid breaking the thread loop implicitly by returning false and return
+  //   // true instead for AUDCLNT_E_DEVICE_INVALIDATED even it is a valid error
+  //   // message. We will use notifications about device changes instead to stop
+  //   // data callbacks and attempt to restart streaming .
+  //   RTC_DLOG(LS_ERROR) << "AUDCLNT_E_DEVICE_INVALIDATED";
+  //   return true;
+  // }
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioCaptureClient::GetNextPacketSize failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  //   return false;
+  // }
 
   // Drain the WASAPI capture buffer fully if audio has been recorded.
   while (num_frames_in_next_packet > 0) {
-    uint8_t* audio_data;
+    uint8_t* audio_data{};
     UINT32 num_frames_to_read = 0;
     DWORD flags = 0;
     UINT64 device_position_frames = 0;
     UINT64 capture_time_100ns = 0;
-    error = audio_capture_client_->GetBuffer(&audio_data, &num_frames_to_read,
-                                             &flags, &device_position_frames,
-                                             &capture_time_100ns);
-    if (error.Error() == AUDCLNT_S_BUFFER_EMPTY) {
-      // The call succeeded but no capture data is available to be read.
-      // Return and start waiting for new capture event
-      RTC_DCHECK_EQ(num_frames_to_read, 0u);
-      return true;
-    }
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioCaptureClient::GetBuffer failed: "
-                        << core_audio_utility::ErrorToString(error);
-      return false;
-    }
+    // auto error = audio_capture_client_->GetBuffer(&audio_data, &num_frames_to_read,
+    //                                          &flags, &device_position_frames,
+    //                                          &capture_time_100ns);
+    // if (error.Error() == AUDCLNT_S_BUFFER_EMPTY) {
+    //   // The call succeeded but no capture data is available to be read.
+    //   // Return and start waiting for new capture event
+    //   RTC_DCHECK_EQ(num_frames_to_read, 0u);
+    //   return true;
+    // }
+    // if (FAILED(error.Error())) {
+    //   RTC_LOG(LS_ERROR) << "IAudioCaptureClient::GetBuffer failed: "
+    //                     << core_audio_utility::ErrorToString(error);
+    //   return false;
+    // }
 
     // Update input delay estimate but only about once per second to save
     // resources. The estimate is usually stable.
@@ -362,20 +363,20 @@ bool CoreAudioInput::OnDataCallback(uint64_t device_frequency) {
           latency_ms_);
     }
 
-    error = audio_capture_client_->ReleaseBuffer(num_frames_to_read);
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioCaptureClient::ReleaseBuffer failed: "
-                        << core_audio_utility::ErrorToString(error);
-      return false;
-    }
-
-    error =
-        audio_capture_client_->GetNextPacketSize(&num_frames_in_next_packet);
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioCaptureClient::GetNextPacketSize failed: "
-                        << core_audio_utility::ErrorToString(error);
-      return false;
-    }
+    // error = audio_capture_client_->ReleaseBuffer(num_frames_to_read);
+    // if (FAILED(error.Error())) {
+    //   RTC_LOG(LS_ERROR) << "IAudioCaptureClient::ReleaseBuffer failed: "
+    //                     << core_audio_utility::ErrorToString(error);
+    //   return false;
+    // }
+
+    // error =
+    //     audio_capture_client_->GetNextPacketSize(&num_frames_in_next_packet);
+    // if (FAILED(error.Error())) {
+    //   RTC_LOG(LS_ERROR) << "IAudioCaptureClient::GetNextPacketSize failed: "
+    //                     << core_audio_utility::ErrorToString(error);
+    //   return false;
+    // }
   }
   ++num_data_callbacks_;
   return true;
diff --git a/modules/audio_device/win/core_audio_output_win.cc b/modules/audio_device/win/core_audio_output_win.cc
index 299eefe18c..7cc0ea5a16 100644
--- a/modules/audio_device/win/core_audio_output_win.cc
+++ b/modules/audio_device/win/core_audio_output_win.cc
@@ -11,6 +11,7 @@
 #include "modules/audio_device/win/core_audio_output_win.h"
 
 #include <memory>
+#include <comdef.h>
 
 #include "modules/audio_device/audio_device_buffer.h"
 #include "modules/audio_device/fine_audio_buffer.h"
@@ -56,7 +57,7 @@ int CoreAudioOutput::Terminate() {
 
 int CoreAudioOutput::NumDevices() const {
   RTC_DCHECK_RUN_ON(&thread_checker_);
-  return core_audio_utility::NumberOfActiveDevices(eRender);
+  return 0;//core_audio_utility::NumberOfActiveDevices(eRender);
 }
 
 int CoreAudioOutput::SetDevice(int index) {
@@ -287,20 +288,20 @@ bool CoreAudioOutput::OnDataCallback(uint64_t device_frequency) {
   // Get the padding value which indicates the amount of valid unread data that
   // the endpoint buffer currently contains.
   UINT32 num_unread_frames = 0;
-  _com_error error = audio_client_->GetCurrentPadding(&num_unread_frames);
-  if (error.Error() == AUDCLNT_E_DEVICE_INVALIDATED) {
-    // Avoid breaking the thread loop implicitly by returning false and return
-    // true instead for AUDCLNT_E_DEVICE_INVALIDATED even it is a valid error
-    // message. We will use notifications about device changes instead to stop
-    // data callbacks and attempt to restart streaming .
-    RTC_DLOG(LS_ERROR) << "AUDCLNT_E_DEVICE_INVALIDATED";
-    return true;
-  }
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetCurrentPadding failed: "
-                      << core_audio_utility::ErrorToString(error);
-    return false;
-  }
+  // _com_error error = {};//audio_client_->GetCurrentPadding(&num_unread_frames);
+  // if (error.Error() == AUDCLNT_E_DEVICE_INVALIDATED) {
+  //   // Avoid breaking the thread loop implicitly by returning false and return
+  //   // true instead for AUDCLNT_E_DEVICE_INVALIDATED even it is a valid error
+  //   // message. We will use notifications about device changes instead to stop
+  //   // data callbacks and attempt to restart streaming .
+  //   RTC_DLOG(LS_ERROR) << "AUDCLNT_E_DEVICE_INVALIDATED";
+  //   return true;
+  // }
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetCurrentPadding failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  //   return false;
+  // }
 
   // Contains how much new data we can write to the buffer without the risk of
   // overwriting previously written data that the audio engine has not yet read
@@ -316,13 +317,13 @@ bool CoreAudioOutput::OnDataCallback(uint64_t device_frequency) {
 
   // Request all available space in the rendering endpoint buffer into which the
   // client can later write an audio packet.
-  uint8_t* audio_data;
-  error = audio_render_client_->GetBuffer(num_requested_frames, &audio_data);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioRenderClient::GetBuffer failed: "
-                      << core_audio_utility::ErrorToString(error);
-    return false;
-  }
+  uint8_t* audio_data{};
+  // error = audio_render_client_->GetBuffer(num_requested_frames, &audio_data);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioRenderClient::GetBuffer failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  //   return false;
+  // }
 
   // Update output delay estimate but only about once per second to save
   // resources. The estimate is usually stable.
@@ -342,12 +343,12 @@ bool CoreAudioOutput::OnDataCallback(uint64_t device_frequency) {
       latency_ms_);
 
   // Release the buffer space acquired in IAudioRenderClient::GetBuffer.
-  error = audio_render_client_->ReleaseBuffer(num_requested_frames, 0);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioRenderClient::ReleaseBuffer failed: "
-                      << core_audio_utility::ErrorToString(error);
-    return false;
-  }
+  // error = audio_render_client_->ReleaseBuffer(num_requested_frames, 0);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioRenderClient::ReleaseBuffer failed: "
+  //                     << core_audio_utility::ErrorToString(error);
+  //   return false;
+  // }
 
   num_frames_written_ += num_requested_frames;
   ++num_data_callbacks_;
@@ -358,29 +359,29 @@ bool CoreAudioOutput::OnDataCallback(uint64_t device_frequency) {
 // TODO(henrika): IAudioClock2::GetDevicePosition could perhaps be used here
 // instead. Tried it once, but it crashed for capture devices.
 int CoreAudioOutput::EstimateOutputLatencyMillis(uint64_t device_frequency) {
-  UINT64 position = 0;
-  UINT64 qpc_position = 0;
+  // UINT64 position = 0;
+  // UINT64 qpc_position = 0;
   int delay_ms = 0;
   // Get the device position through output parameter |position|. This is the
   // stream position of the sample that is currently playing through the
   // speakers.
-  _com_error error = audio_clock_->GetPosition(&position, &qpc_position);
-  if (error.Error() == S_OK) {
-    // Number of frames already played out through the speaker.
-    const uint64_t num_played_out_frames =
-        format_.Format.nSamplesPerSec * position / device_frequency;
-
-    // Number of frames that have been written to the buffer but not yet
-    // played out corresponding to the estimated latency measured in number
-    // of audio frames.
-    const uint64_t delay_frames = num_frames_written_ - num_played_out_frames;
-
-    // Convert latency in number of frames into milliseconds.
-    webrtc::TimeDelta delay =
-        webrtc::TimeDelta::Micros(delay_frames * rtc::kNumMicrosecsPerSec /
-                                  format_.Format.nSamplesPerSec);
-    delay_ms = delay.ms();
-  }
+  // _com_error error = {};//audio_clock_->GetPosition(&position, &qpc_position);
+  // if (error.Error() == S_OK) {
+  //   // Number of frames already played out through the speaker.
+  //   const uint64_t num_played_out_frames =
+  //       format_.Format.nSamplesPerSec * position / device_frequency;
+
+  //   // Number of frames that have been written to the buffer but not yet
+  //   // played out corresponding to the estimated latency measured in number
+  //   // of audio frames.
+  //   const uint64_t delay_frames = num_frames_written_ - num_played_out_frames;
+
+  //   // Convert latency in number of frames into milliseconds.
+  //   webrtc::TimeDelta delay =
+  //       webrtc::TimeDelta::Micros(delay_frames * rtc::kNumMicrosecsPerSec /
+  //                                 format_.Format.nSamplesPerSec);
+  //   delay_ms = delay.ms();
+  // }
   return delay_ms;
 }
 
diff --git a/modules/audio_device/win/core_audio_utility_win.cc b/modules/audio_device/win/core_audio_utility_win.cc
index f17ee99143..46fac68561 100644
--- a/modules/audio_device/win/core_audio_utility_win.cc
+++ b/modules/audio_device/win/core_audio_utility_win.cc
@@ -174,31 +174,31 @@ const char* WaveFormatTagToString(WORD format_tag) {
   }
 }
 
-const char* RoleToString(const ERole role) {
-  switch (role) {
-    case eConsole:
-      return "Console";
-    case eMultimedia:
-      return "Multimedia";
-    case eCommunications:
-      return "Communications";
-    default:
-      return "Unsupported";
-  }
-}
-
-const char* FlowToString(const EDataFlow flow) {
-  switch (flow) {
-    case eRender:
-      return "Render";
-    case eCapture:
-      return "Capture";
-    case eAll:
-      return "Render or Capture";
-    default:
-      return "Unsupported";
-  }
-}
+// const char* RoleToString(const ERole role) {
+//   switch (role) {
+//     case eConsole:
+//       return "Console";
+//     case eMultimedia:
+//       return "Multimedia";
+//     case eCommunications:
+//       return "Communications";
+//     default:
+//       return "Unsupported";
+//   }
+// }
+
+// const char* FlowToString(const EDataFlow flow) {
+//   switch (flow) {
+//     case eRender:
+//       return "Render";
+//     case eCapture:
+//       return "Capture";
+//     case eAll:
+//       return "Render or Capture";
+//     default:
+//       return "Unsupported";
+//   }
+// }
 
 bool LoadAudiosesDll() {
   static const wchar_t* const kAudiosesDLL =
@@ -206,8 +206,8 @@ bool LoadAudiosesDll() {
   wchar_t path[MAX_PATH] = {0};
   ExpandEnvironmentStringsW(kAudiosesDLL, path, arraysize(path));
   RTC_DLOG(INFO) << rtc::ToUtf8(path);
-  return (LoadLibraryExW(path, nullptr, LOAD_WITH_ALTERED_SEARCH_PATH) !=
-          nullptr);
+  return false;//(LoadLibraryExW(path, nullptr, LOAD_WITH_ALTERED_SEARCH_PATH) !=
+          //nullptr);
 }
 
 bool LoadAvrtDll() {
@@ -215,38 +215,38 @@ bool LoadAvrtDll() {
   wchar_t path[MAX_PATH] = {0};
   ExpandEnvironmentStringsW(kAvrtDLL, path, arraysize(path));
   RTC_DLOG(INFO) << rtc::ToUtf8(path);
-  return (LoadLibraryExW(path, nullptr, LOAD_WITH_ALTERED_SEARCH_PATH) !=
-          nullptr);
-}
-
-ComPtr<IMMDeviceEnumerator> CreateDeviceEnumeratorInternal(
-    bool allow_reinitialize) {
-  ComPtr<IMMDeviceEnumerator> device_enumerator;
-  _com_error error =
-      ::CoCreateInstance(__uuidof(MMDeviceEnumerator), nullptr, CLSCTX_ALL,
-                         IID_PPV_ARGS(&device_enumerator));
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "CoCreateInstance failed: " << ErrorToString(error);
-  }
-
-  if (error.Error() == CO_E_NOTINITIALIZED && allow_reinitialize) {
-    RTC_LOG(LS_ERROR) << "CoCreateInstance failed with CO_E_NOTINITIALIZED";
-    // We have seen crashes which indicates that this method can in fact
-    // fail with CO_E_NOTINITIALIZED in combination with certain 3rd party
-    // modules. Calling CoInitializeEx() is an attempt to resolve the reported
-    // issues. See http://crbug.com/378465 for details.
-    error = CoInitializeEx(nullptr, COINIT_MULTITHREADED);
-    if (FAILED(error.Error())) {
-      error = ::CoCreateInstance(__uuidof(MMDeviceEnumerator), nullptr,
-                                 CLSCTX_ALL, IID_PPV_ARGS(&device_enumerator));
-      if (FAILED(error.Error())) {
-        RTC_LOG(LS_ERROR) << "CoCreateInstance failed: "
-                          << ErrorToString(error);
-      }
-    }
-  }
-  return device_enumerator;
-}
+  return false;//(LoadLibraryExW(path, nullptr, LOAD_WITH_ALTERED_SEARCH_PATH) !=
+          //nullptr);
+}
+
+// ComPtr<IMMDeviceEnumerator> CreateDeviceEnumeratorInternal(
+//     bool allow_reinitialize) {
+//   // ComPtr<IMMDeviceEnumerator> device_enumerator;
+//   // _com_error error =
+//   //     ::CoCreateInstance(__uuidof(MMDeviceEnumerator), nullptr, CLSCTX_ALL,
+//   //                        IID_PPV_ARGS(&device_enumerator));
+//   // if (FAILED(error.Error())) {
+//   //   RTC_LOG(LS_ERROR) << "CoCreateInstance failed: " << ErrorToString(error);
+//   // }
+
+//   // if (error.Error() == CO_E_NOTINITIALIZED && allow_reinitialize) {
+//   //   RTC_LOG(LS_ERROR) << "CoCreateInstance failed with CO_E_NOTINITIALIZED";
+//   //   // We have seen crashes which indicates that this method can in fact
+//   //   // fail with CO_E_NOTINITIALIZED in combination with certain 3rd party
+//   //   // modules. Calling CoInitializeEx() is an attempt to resolve the reported
+//   //   // issues. See http://crbug.com/378465 for details.
+//   //   error = CoInitializeEx(nullptr, COINIT_MULTITHREADED);
+//   //   if (FAILED(error.Error())) {
+//   //     error = ::CoCreateInstance(__uuidof(MMDeviceEnumerator), nullptr,
+//   //                                CLSCTX_ALL, IID_PPV_ARGS(&device_enumerator));
+//   //     if (FAILED(error.Error())) {
+//   //       RTC_LOG(LS_ERROR) << "CoCreateInstance failed: "
+//   //                         << ErrorToString(error);
+//   //     }
+//   //   }
+//   // }
+//   return {};//device_enumerator;
+// }
 
 bool IsSupportedInternal() {
   // The Core Audio APIs are implemented in the user-mode system components
@@ -261,340 +261,340 @@ bool IsSupportedInternal() {
   // all devices to guarantee Core Audio support. To be 100%, we also verify
   // that it is possible to a create the IMMDeviceEnumerator interface. If
   // this works as well we should be home free.
-  ComPtr<IMMDeviceEnumerator> device_enumerator =
-      CreateDeviceEnumeratorInternal(false);
-  if (!device_enumerator) {
-    RTC_LOG(LS_ERROR)
-        << "Failed to create Core Audio device enumerator on thread with ID "
-        << rtc::CurrentThreadId();
-    return false;
-  }
+  // ComPtr<IMMDeviceEnumerator> device_enumerator =
+  //     CreateDeviceEnumeratorInternal(false);
+  // if (!device_enumerator) {
+  //   RTC_LOG(LS_ERROR)
+  //       << "Failed to create Core Audio device enumerator on thread with ID "
+  //       << rtc::CurrentThreadId();
+  //   return false;
+  // }
 
   return true;
 }
 
-bool IsDeviceActive(IMMDevice* device) {
-  DWORD state = DEVICE_STATE_DISABLED;
-  return SUCCEEDED(device->GetState(&state)) && (state & DEVICE_STATE_ACTIVE);
-}
+// bool IsDeviceActive(IMMDevice* device) {
+//   // DWORD state = DEVICE_STATE_DISABLED;
+//   return false;//SUCCEEDED(device->GetState(&state)) && (state & DEVICE_STATE_ACTIVE);
+// }
 
 // Retrieve an audio device specified by |device_id| or a default device
 // specified by data-flow direction and role if |device_id| is default.
-ComPtr<IMMDevice> CreateDeviceInternal(const std::string& device_id,
-                                       EDataFlow data_flow,
-                                       ERole role) {
-  RTC_DLOG(INFO) << "CreateDeviceInternal: "
-                    "id="
-                 << device_id << ", flow=" << FlowToString(data_flow)
-                 << ", role=" << RoleToString(role);
-  ComPtr<IMMDevice> audio_endpoint_device;
-
-  // Create the IMMDeviceEnumerator interface.
-  ComPtr<IMMDeviceEnumerator> device_enum(CreateDeviceEnumeratorInternal(true));
-  if (!device_enum.Get())
-    return audio_endpoint_device;
-
-  _com_error error(S_FALSE);
-  if (device_id == AudioDeviceName::kDefaultDeviceId) {
-    // Get the default audio endpoint for the specified data-flow direction and
-    // role. Note that, if only a single rendering or capture device is
-    // available, the system always assigns all three rendering or capture roles
-    // to that device. If the method fails to find a rendering or capture device
-    // for the specified role, this means that no rendering or capture device is
-    // available at all. If no device is available, the method sets the output
-    // pointer to NULL and returns ERROR_NOT_FOUND.
-    error = device_enum->GetDefaultAudioEndpoint(
-        data_flow, role, audio_endpoint_device.GetAddressOf());
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR)
-          << "IMMDeviceEnumerator::GetDefaultAudioEndpoint failed: "
-          << ErrorToString(error);
-    }
-  } else {
-    // Ask for an audio endpoint device that is identified by an endpoint ID
-    // string.
-    error = device_enum->GetDevice(rtc::ToUtf16(device_id).c_str(),
-                                   audio_endpoint_device.GetAddressOf());
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IMMDeviceEnumerator::GetDevice failed: "
-                        << ErrorToString(error);
-    }
-  }
-
-  // Verify that the audio endpoint device is active, i.e., that the audio
-  // adapter that connects to the endpoint device is present and enabled.
-  if (SUCCEEDED(error.Error()) && !audio_endpoint_device.Get() &&
-      !IsDeviceActive(audio_endpoint_device.Get())) {
-    RTC_LOG(LS_WARNING) << "Selected endpoint device is not active";
-    audio_endpoint_device.Reset();
-  }
-
-  return audio_endpoint_device;
-}
-
-std::string GetDeviceIdInternal(IMMDevice* device) {
-  // Retrieve unique name of endpoint device.
-  // Example: "{0.0.1.00000000}.{8db6020f-18e3-4f25-b6f5-7726c9122574}".
-  LPWSTR device_id;
-  if (SUCCEEDED(device->GetId(&device_id))) {
-    std::string device_id_utf8 = rtc::ToUtf8(device_id, wcslen(device_id));
-    CoTaskMemFree(device_id);
-    return device_id_utf8;
-  } else {
-    return std::string();
-  }
-}
-
-std::string GetDeviceFriendlyNameInternal(IMMDevice* device) {
-  // Retrieve user-friendly name of endpoint device.
-  // Example: "Microphone (Realtek High Definition Audio)".
-  ComPtr<IPropertyStore> properties;
-  HRESULT hr = device->OpenPropertyStore(STGM_READ, properties.GetAddressOf());
-  if (FAILED(hr))
-    return std::string();
-
-  ScopedPropVariant friendly_name_pv;
-  hr = properties->GetValue(PKEY_Device_FriendlyName,
-                            friendly_name_pv.Receive());
-  if (FAILED(hr))
-    return std::string();
-
-  if (friendly_name_pv.get().vt == VT_LPWSTR &&
-      friendly_name_pv.get().pwszVal) {
-    return rtc::ToUtf8(friendly_name_pv.get().pwszVal,
-                       wcslen(friendly_name_pv.get().pwszVal));
-  } else {
-    return std::string();
-  }
-}
-
-ComPtr<IAudioSessionManager2> CreateSessionManager2Internal(
-    IMMDevice* audio_device) {
-  if (!audio_device)
-    return ComPtr<IAudioSessionManager2>();
-
-  ComPtr<IAudioSessionManager2> audio_session_manager;
-  _com_error error =
-      audio_device->Activate(__uuidof(IAudioSessionManager2), CLSCTX_ALL,
-                             nullptr, &audio_session_manager);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioSessionManager2) failed: "
-                      << ErrorToString(error);
-  }
-  return audio_session_manager;
-}
-
-ComPtr<IAudioSessionEnumerator> CreateSessionEnumeratorInternal(
-    IMMDevice* audio_device) {
-  if (!audio_device) {
-    return ComPtr<IAudioSessionEnumerator>();
-  }
-
-  ComPtr<IAudioSessionEnumerator> audio_session_enumerator;
-  ComPtr<IAudioSessionManager2> audio_session_manager =
-      CreateSessionManager2Internal(audio_device);
-  if (!audio_session_manager.Get()) {
-    return audio_session_enumerator;
-  }
-  _com_error error =
-      audio_session_manager->GetSessionEnumerator(&audio_session_enumerator);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR)
-        << "IAudioSessionEnumerator::IAudioSessionEnumerator failed: "
-        << ErrorToString(error);
-    return ComPtr<IAudioSessionEnumerator>();
-  }
-  return audio_session_enumerator;
-}
+// ComPtr<IMMDevice> CreateDeviceInternal(const std::string& device_id,
+//                                        EDataFlow data_flow,
+//                                        ERole role) {
+//   RTC_DLOG(INFO) << "CreateDeviceInternal: "
+//                     "id="
+//                  << device_id << ", flow=" << FlowToString(data_flow)
+//                  << ", role=" << RoleToString(role);
+//   ComPtr<IMMDevice> audio_endpoint_device;
+
+//   // Create the IMMDeviceEnumerator interface.
+//   ComPtr<IMMDeviceEnumerator> device_enum(CreateDeviceEnumeratorInternal(true));
+//   if (!device_enum.Get())
+//     return audio_endpoint_device;
+
+//   _com_error error(S_FALSE);
+//   if (device_id == AudioDeviceName::kDefaultDeviceId) {
+//     // Get the default audio endpoint for the specified data-flow direction and
+//     // role. Note that, if only a single rendering or capture device is
+//     // available, the system always assigns all three rendering or capture roles
+//     // to that device. If the method fails to find a rendering or capture device
+//     // for the specified role, this means that no rendering or capture device is
+//     // available at all. If no device is available, the method sets the output
+//     // pointer to NULL and returns ERROR_NOT_FOUND.
+//     error = device_enum->GetDefaultAudioEndpoint(
+//         data_flow, role, audio_endpoint_device.GetAddressOf());
+//     if (FAILED(error.Error())) {
+//       RTC_LOG(LS_ERROR)
+//           << "IMMDeviceEnumerator::GetDefaultAudioEndpoint failed: "
+//           << ErrorToString(error);
+//     }
+//   } else {
+//     // Ask for an audio endpoint device that is identified by an endpoint ID
+//     // string.
+//     error = device_enum->GetDevice(rtc::ToUtf16(device_id).c_str(),
+//                                    audio_endpoint_device.GetAddressOf());
+//     if (FAILED(error.Error())) {
+//       RTC_LOG(LS_ERROR) << "IMMDeviceEnumerator::GetDevice failed: "
+//                         << ErrorToString(error);
+//     }
+//   }
+
+//   // Verify that the audio endpoint device is active, i.e., that the audio
+//   // adapter that connects to the endpoint device is present and enabled.
+//   if (SUCCEEDED(error.Error()) && !audio_endpoint_device.Get() &&
+//       !IsDeviceActive(audio_endpoint_device.Get())) {
+//     RTC_LOG(LS_WARNING) << "Selected endpoint device is not active";
+//     audio_endpoint_device.Reset();
+//   }
+
+//   return audio_endpoint_device;
+// }
+
+// std::string GetDeviceIdInternal(IMMDevice* device) {
+//   // Retrieve unique name of endpoint device.
+//   // Example: "{0.0.1.00000000}.{8db6020f-18e3-4f25-b6f5-7726c9122574}".
+//   // LPWSTR device_id;
+//   // if (SUCCEEDED(device->GetId(&device_id))) {
+//   //   std::string device_id_utf8 = rtc::ToUtf8(device_id, wcslen(device_id));
+//   //   CoTaskMemFree(device_id);
+//   //   return device_id_utf8;
+//   // } else {
+//     return std::string();
+//   // }
+// }
+
+// std::string GetDeviceFriendlyNameInternal(IMMDevice* device) {
+//   // Retrieve user-friendly name of endpoint device.
+//   // Example: "Microphone (Realtek High Definition Audio)".
+//   ComPtr<IPropertyStore> properties;
+//   // HRESULT hr = device->OpenPropertyStore(STGM_READ, properties.GetAddressOf());
+//   // if (FAILED(hr))
+//   //   return std::string();
+
+//   // ScopedPropVariant friendly_name_pv;
+//   // hr = properties->GetValue(PKEY_Device_FriendlyName,
+//   //                           friendly_name_pv.Receive());
+//   // if (FAILED(hr))
+//   //   return std::string();
+
+//   // if (friendly_name_pv.get().vt == VT_LPWSTR &&
+//   //     friendly_name_pv.get().pwszVal) {
+//   //   return rtc::ToUtf8(friendly_name_pv.get().pwszVal,
+//   //                      wcslen(friendly_name_pv.get().pwszVal));
+//   // } else {
+//     return std::string();
+//   // }
+// }
+
+// ComPtr<IAudioSessionManager2> CreateSessionManager2Internal(
+//     IMMDevice* audio_device) {
+//   // if (!audio_device)
+//   //   return ComPtr<IAudioSessionManager2>();
+
+//   ComPtr<IAudioSessionManager2> audio_session_manager;
+//   // _com_error error =
+//   //     audio_device->Activate(__uuidof(IAudioSessionManager2), CLSCTX_ALL,
+//   //                            nullptr, &audio_session_manager);
+//   // if (FAILED(error.Error())) {
+//   //   RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioSessionManager2) failed: "
+//   //                     << ErrorToString(error);
+//   // }
+//   return audio_session_manager;
+// }
+
+// ComPtr<IAudioSessionEnumerator> CreateSessionEnumeratorInternal(
+//     IMMDevice* audio_device) {
+//   if (!audio_device) {
+//     return ComPtr<IAudioSessionEnumerator>();
+//   }
+
+//   ComPtr<IAudioSessionEnumerator> audio_session_enumerator;
+//   ComPtr<IAudioSessionManager2> audio_session_manager =
+//       CreateSessionManager2Internal(audio_device);
+//   if (!audio_session_manager.Get()) {
+//     return audio_session_enumerator;
+//   }
+//   // _com_error error =
+//   //     audio_session_manager->GetSessionEnumerator(&audio_session_enumerator);
+//   // if (FAILED(error.Error())) {
+//   //   RTC_LOG(LS_ERROR)
+//   //       << "IAudioSessionEnumerator::IAudioSessionEnumerator failed: "
+//   //       << ErrorToString(error);
+//   //   return ComPtr<IAudioSessionEnumerator>();
+//   // }
+//   return audio_session_enumerator;
+// }
 
 // Creates and activates an IAudioClient COM object given the selected
 // endpoint device.
-ComPtr<IAudioClient> CreateClientInternal(IMMDevice* audio_device) {
-  if (!audio_device)
-    return ComPtr<IAudioClient>();
-
-  ComPtr<IAudioClient> audio_client;
-  _com_error error = audio_device->Activate(__uuidof(IAudioClient), CLSCTX_ALL,
-                                            nullptr, &audio_client);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioClient) failed: "
-                      << ErrorToString(error);
-  }
-  return audio_client;
-}
-
-ComPtr<IAudioClient2> CreateClient2Internal(IMMDevice* audio_device) {
-  if (!audio_device)
-    return ComPtr<IAudioClient2>();
-
-  ComPtr<IAudioClient2> audio_client;
-  _com_error error = audio_device->Activate(__uuidof(IAudioClient2), CLSCTX_ALL,
-                                            nullptr, &audio_client);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioClient2) failed: "
-                      << ErrorToString(error);
-  }
-  return audio_client;
-}
-
-ComPtr<IAudioClient3> CreateClient3Internal(IMMDevice* audio_device) {
-  if (!audio_device)
-    return ComPtr<IAudioClient3>();
-
-  ComPtr<IAudioClient3> audio_client;
-  _com_error error = audio_device->Activate(__uuidof(IAudioClient3), CLSCTX_ALL,
-                                            nullptr, &audio_client);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioClient3) failed: "
-                      << ErrorToString(error);
-  }
-  return audio_client;
-}
-
-ComPtr<IMMDeviceCollection> CreateCollectionInternal(EDataFlow data_flow) {
-  ComPtr<IMMDeviceEnumerator> device_enumerator(
-      CreateDeviceEnumeratorInternal(true));
-  if (!device_enumerator) {
-    return ComPtr<IMMDeviceCollection>();
-  }
-
-  // Generate a collection of active (present and not disabled) audio endpoint
-  // devices for the specified data-flow direction.
-  // This method will succeed even if all devices are disabled.
-  ComPtr<IMMDeviceCollection> collection;
-  _com_error error = device_enumerator->EnumAudioEndpoints(
-      data_flow, DEVICE_STATE_ACTIVE, collection.GetAddressOf());
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMDeviceCollection::EnumAudioEndpoints failed: "
-                      << ErrorToString(error);
-  }
-  return collection;
-}
-
-bool GetDeviceNamesInternal(EDataFlow data_flow,
-                            webrtc::AudioDeviceNames* device_names) {
-  RTC_DLOG(LS_INFO) << "GetDeviceNamesInternal: flow="
-                    << FlowToString(data_flow);
-
-  // Generate a collection of active audio endpoint devices for the specified
-  // direction.
-  ComPtr<IMMDeviceCollection> collection = CreateCollectionInternal(data_flow);
-  if (!collection.Get()) {
-    RTC_LOG(LS_ERROR) << "Failed to create a collection of active devices";
-    return false;
-  }
-
-  // Retrieve the number of active (present, not disabled and plugged in) audio
-  // devices for the specified direction.
-  UINT number_of_active_devices = 0;
-  _com_error error = collection->GetCount(&number_of_active_devices);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMDeviceCollection::GetCount failed: "
-                      << ErrorToString(error);
-    return false;
-  }
-
-  if (number_of_active_devices == 0) {
-    RTC_DLOG(LS_WARNING) << "Found no active devices";
-    return false;
-  }
-
-  // Loop over all active devices and add friendly name and unique id to the
-  // |device_names| queue. For now, devices are added at indexes 0, 1, ..., N-1
-  // but they will be moved to 2,3,..., N+1 at the next stage when default and
-  // default communication devices are added at index 0 and 1.
-  ComPtr<IMMDevice> audio_device;
-  for (UINT i = 0; i < number_of_active_devices; ++i) {
-    // Retrieve a pointer to the specified item in the device collection.
-    error = collection->Item(i, audio_device.GetAddressOf());
-    if (FAILED(error.Error())) {
-      // Skip this item and try to get the next item instead; will result in an
-      // incomplete list of devices.
-      RTC_LOG(LS_WARNING) << "IMMDeviceCollection::Item failed: "
-                          << ErrorToString(error);
-      continue;
-    }
-    if (!audio_device.Get()) {
-      RTC_LOG(LS_WARNING) << "Invalid audio device";
-      continue;
-    }
-
-    // Retrieve the complete device name for the given audio device endpoint.
-    AudioDeviceName device_name(
-        GetDeviceFriendlyNameInternal(audio_device.Get()),
-        GetDeviceIdInternal(audio_device.Get()));
-    // Add combination of user-friendly and unique name to the output list.
-    device_names->push_back(device_name);
-  }
-
-  // Log a warning of the list of device is not complete but let's keep on
-  // trying to add default and default communications device at the front.
-  if (device_names->size() != number_of_active_devices) {
-    RTC_DLOG(LS_WARNING)
-        << "List of device names does not contain all active devices";
-  }
-
-  // Avoid adding default and default communication devices if no active device
-  // could be added to the queue. We might as well break here and return false
-  // since no active devices were identified.
-  if (device_names->empty()) {
-    RTC_DLOG(LS_ERROR) << "List of active devices is empty";
-    return false;
-  }
-
-  // Prepend the queue with two more elements: one for the default device and
-  // one for the default communication device (can correspond to the same unique
-  // id if only one active device exists). The first element (index 0) is the
-  // default device and the second element (index 1) is the default
-  // communication device.
-  ERole role[] = {eCommunications, eConsole};
-  ComPtr<IMMDevice> default_device;
-  AudioDeviceName default_device_name;
-  for (size_t i = 0; i < arraysize(role); ++i) {
-    default_device = CreateDeviceInternal(AudioDeviceName::kDefaultDeviceId,
-                                          data_flow, role[i]);
-    if (!default_device.Get()) {
-      // Add empty strings to device name if the device could not be created.
-      RTC_DLOG(LS_WARNING) << "Failed to add device with role: "
-                           << RoleToString(role[i]);
-      default_device_name.device_name = std::string();
-      default_device_name.unique_id = std::string();
-    } else {
-      // Populate the device name with friendly name and unique id.
-      std::string device_name;
-      device_name += (role[i] == eConsole ? "Default - " : "Communication - ");
-      device_name += GetDeviceFriendlyNameInternal(default_device.Get());
-      std::string unique_id = GetDeviceIdInternal(default_device.Get());
-      default_device_name.device_name = std::move(device_name);
-      default_device_name.unique_id = std::move(unique_id);
-    }
-
-    // Add combination of user-friendly and unique name to the output queue.
-    // The last element (<=> eConsole) will be at the front of the queue, hence
-    // at index 0. Empty strings will be added for cases where no default
-    // devices were found.
-    device_names->push_front(default_device_name);
-  }
-
-  // Example of log output when only one device is active. Note that the queue
-  // contains two extra elements at index 0 (Default) and 1 (Communication) to
-  // allow selection of device by role instead of id. All elements corresponds
-  // the same unique id.
-  // [0] friendly name: Default - Headset Microphone (2- Arctis 7 Chat)
-  // [0] unique id    : {0.0.1.00000000}.{ff9eed76-196e-467a-b295-26986e69451c}
-  // [1] friendly name: Communication - Headset Microphone (2- Arctis 7 Chat)
-  // [1] unique id    : {0.0.1.00000000}.{ff9eed76-196e-467a-b295-26986e69451c}
-  // [2] friendly name: Headset Microphone (2- Arctis 7 Chat)
-  // [2] unique id    : {0.0.1.00000000}.{ff9eed76-196e-467a-b295-26986e69451c}
-  for (size_t i = 0; i < device_names->size(); ++i) {
-    RTC_DLOG(INFO) << "[" << i
-                   << "] friendly name: " << (*device_names)[i].device_name;
-    RTC_DLOG(INFO) << "[" << i
-                   << "] unique id    : " << (*device_names)[i].unique_id;
-  }
-
-  return true;
-}
+// ComPtr<IAudioClient> CreateClientInternal(IMMDevice* audio_device) {
+//   if (!audio_device)
+//     return ComPtr<IAudioClient>();
+
+//   ComPtr<IAudioClient> audio_client;
+//   // _com_error error = audio_device->Activate(__uuidof(IAudioClient), CLSCTX_ALL,
+//   //                                           nullptr, &audio_client);
+//   // if (FAILED(error.Error())) {
+//   //   RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioClient) failed: "
+//   //                     << ErrorToString(error);
+//   // }
+//   return audio_client;
+// }
+
+// ComPtr<IAudioClient2> CreateClient2Internal(IMMDevice* audio_device) {
+//   if (!audio_device)
+//     return ComPtr<IAudioClient2>();
+
+//   ComPtr<IAudioClient2> audio_client;
+//   // _com_error error = audio_device->Activate(__uuidof(IAudioClient2), CLSCTX_ALL,
+//   //                                           nullptr, &audio_client);
+//   // if (FAILED(error.Error())) {
+//   //   RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioClient2) failed: "
+//   //                     << ErrorToString(error);
+//   // }
+//   return audio_client;
+// }
+
+// ComPtr<IAudioClient3> CreateClient3Internal(IMMDevice* audio_device) {
+//   if (!audio_device)
+//     return ComPtr<IAudioClient3>();
+
+//   ComPtr<IAudioClient3> audio_client;
+//   // _com_error error = audio_device->Activate(__uuidof(IAudioClient3), CLSCTX_ALL,
+//   //                                           nullptr, &audio_client);
+//   // if (FAILED(error.Error())) {
+//   //   RTC_LOG(LS_ERROR) << "IMMDevice::Activate(IAudioClient3) failed: "
+//   //                     << ErrorToString(error);
+//   // }
+//   return audio_client;
+// }
+
+// ComPtr<IMMDeviceCollection> CreateCollectionInternal(EDataFlow data_flow) {
+//   ComPtr<IMMDeviceEnumerator> device_enumerator(
+//       CreateDeviceEnumeratorInternal(true));
+//   if (!device_enumerator) {
+//     return ComPtr<IMMDeviceCollection>();
+//   }
+
+//   // Generate a collection of active (present and not disabled) audio endpoint
+//   // devices for the specified data-flow direction.
+//   // This method will succeed even if all devices are disabled.
+//   ComPtr<IMMDeviceCollection> collection;
+//   _com_error error = device_enumerator->EnumAudioEndpoints(
+//       data_flow, DEVICE_STATE_ACTIVE, collection.GetAddressOf());
+//   if (FAILED(error.Error())) {
+//     RTC_LOG(LS_ERROR) << "IMMDeviceCollection::EnumAudioEndpoints failed: "
+//                       << ErrorToString(error);
+//   }
+//   return collection;
+// }
+
+// bool GetDeviceNamesInternal(EDataFlow data_flow,
+//                             webrtc::AudioDeviceNames* device_names) {
+//   RTC_DLOG(LS_INFO) << "GetDeviceNamesInternal: flow="
+//                     << FlowToString(data_flow);
+
+//   // Generate a collection of active audio endpoint devices for the specified
+//   // direction.
+//   ComPtr<IMMDeviceCollection> collection = CreateCollectionInternal(data_flow);
+//   if (!collection.Get()) {
+//     RTC_LOG(LS_ERROR) << "Failed to create a collection of active devices";
+//     return false;
+//   }
+
+//   // Retrieve the number of active (present, not disabled and plugged in) audio
+//   // devices for the specified direction.
+//   UINT number_of_active_devices = 0;
+//   _com_error error = collection->GetCount(&number_of_active_devices);
+//   if (FAILED(error.Error())) {
+//     RTC_LOG(LS_ERROR) << "IMMDeviceCollection::GetCount failed: "
+//                       << ErrorToString(error);
+//     return false;
+//   }
+
+//   if (number_of_active_devices == 0) {
+//     RTC_DLOG(LS_WARNING) << "Found no active devices";
+//     return false;
+//   }
+
+//   // Loop over all active devices and add friendly name and unique id to the
+//   // |device_names| queue. For now, devices are added at indexes 0, 1, ..., N-1
+//   // but they will be moved to 2,3,..., N+1 at the next stage when default and
+//   // default communication devices are added at index 0 and 1.
+//   ComPtr<IMMDevice> audio_device;
+//   for (UINT i = 0; i < number_of_active_devices; ++i) {
+//     // Retrieve a pointer to the specified item in the device collection.
+//     error = collection->Item(i, audio_device.GetAddressOf());
+//     if (FAILED(error.Error())) {
+//       // Skip this item and try to get the next item instead; will result in an
+//       // incomplete list of devices.
+//       RTC_LOG(LS_WARNING) << "IMMDeviceCollection::Item failed: "
+//                           << ErrorToString(error);
+//       continue;
+//     }
+//     if (!audio_device.Get()) {
+//       RTC_LOG(LS_WARNING) << "Invalid audio device";
+//       continue;
+//     }
+
+//     // Retrieve the complete device name for the given audio device endpoint.
+//     AudioDeviceName device_name(
+//         GetDeviceFriendlyNameInternal(audio_device.Get()),
+//         GetDeviceIdInternal(audio_device.Get()));
+//     // Add combination of user-friendly and unique name to the output list.
+//     device_names->push_back(device_name);
+//   }
+
+//   // Log a warning of the list of device is not complete but let's keep on
+//   // trying to add default and default communications device at the front.
+//   if (device_names->size() != number_of_active_devices) {
+//     RTC_DLOG(LS_WARNING)
+//         << "List of device names does not contain all active devices";
+//   }
+
+//   // Avoid adding default and default communication devices if no active device
+//   // could be added to the queue. We might as well break here and return false
+//   // since no active devices were identified.
+//   if (device_names->empty()) {
+//     RTC_DLOG(LS_ERROR) << "List of active devices is empty";
+//     return false;
+//   }
+
+//   // Prepend the queue with two more elements: one for the default device and
+//   // one for the default communication device (can correspond to the same unique
+//   // id if only one active device exists). The first element (index 0) is the
+//   // default device and the second element (index 1) is the default
+//   // communication device.
+//   // ERole role[] = {eCommunications, eConsole};
+//   // ComPtr<IMMDevice> default_device;
+//   // AudioDeviceName default_device_name;
+//   // for (size_t i = 0; i < arraysize(role); ++i) {
+//   //   default_device = CreateDeviceInternal(AudioDeviceName::kDefaultDeviceId,
+//   //                                         data_flow, role[i]);
+//   //   if (!default_device.Get()) {
+//   //     // Add empty strings to device name if the device could not be created.
+//   //     RTC_DLOG(LS_WARNING) << "Failed to add device with role: "
+//   //                          << RoleToString(role[i]);
+//   //     default_device_name.device_name = std::string();
+//   //     default_device_name.unique_id = std::string();
+//   //   } else {
+//   //     // Populate the device name with friendly name and unique id.
+//   //     std::string device_name;
+//   //     device_name += (role[i] == eConsole ? "Default - " : "Communication - ");
+//   //     device_name += GetDeviceFriendlyNameInternal(default_device.Get());
+//   //     std::string unique_id = GetDeviceIdInternal(default_device.Get());
+//   //     default_device_name.device_name = std::move(device_name);
+//   //     default_device_name.unique_id = std::move(unique_id);
+//   //   }
+
+//   //   // Add combination of user-friendly and unique name to the output queue.
+//   //   // The last element (<=> eConsole) will be at the front of the queue, hence
+//   //   // at index 0. Empty strings will be added for cases where no default
+//   //   // devices were found.
+//   //   device_names->push_front(default_device_name);
+//   // }
+
+//   // Example of log output when only one device is active. Note that the queue
+//   // contains two extra elements at index 0 (Default) and 1 (Communication) to
+//   // allow selection of device by role instead of id. All elements corresponds
+//   // the same unique id.
+//   // [0] friendly name: Default - Headset Microphone (2- Arctis 7 Chat)
+//   // [0] unique id    : {0.0.1.00000000}.{ff9eed76-196e-467a-b295-26986e69451c}
+//   // [1] friendly name: Communication - Headset Microphone (2- Arctis 7 Chat)
+//   // [1] unique id    : {0.0.1.00000000}.{ff9eed76-196e-467a-b295-26986e69451c}
+//   // [2] friendly name: Headset Microphone (2- Arctis 7 Chat)
+//   // [2] unique id    : {0.0.1.00000000}.{ff9eed76-196e-467a-b295-26986e69451c}
+//   for (size_t i = 0; i < device_names->size(); ++i) {
+//     RTC_DLOG(INFO) << "[" << i
+//                    << "] friendly name: " << (*device_names)[i].device_name;
+//     RTC_DLOG(INFO) << "[" << i
+//                    << "] unique id    : " << (*device_names)[i].unique_id;
+//   }
+
+//   return true;
+// }
 
 HRESULT GetPreferredAudioParametersInternal(IAudioClient* client,
                                             AudioParameters* params,
@@ -679,28 +679,28 @@ bool IsMMCSSSupported() {
   return LoadAvrtDll();
 }
 
-int NumberOfActiveDevices(EDataFlow data_flow) {
-  // Generate a collection of active audio endpoint devices for the specified
-  // data-flow direction.
-  ComPtr<IMMDeviceCollection> collection = CreateCollectionInternal(data_flow);
-  if (!collection.Get()) {
-    return 0;
-  }
-
-  // Retrieve the number of active audio devices for the specified direction.
-  UINT number_of_active_devices = 0;
-  collection->GetCount(&number_of_active_devices);
-  std::string str;
-  if (data_flow == eCapture) {
-    str = "Number of capture devices: ";
-  } else if (data_flow == eRender) {
-    str = "Number of render devices: ";
-  } else if (data_flow == eAll) {
-    str = "Total number of devices: ";
-  }
-  RTC_DLOG(INFO) << str << number_of_active_devices;
-  return static_cast<int>(number_of_active_devices);
-}
+// int NumberOfActiveDevices(EDataFlow data_flow) {
+//   // Generate a collection of active audio endpoint devices for the specified
+//   // data-flow direction.
+//   ComPtr<IMMDeviceCollection> collection = CreateCollectionInternal(data_flow);
+//   if (!collection.Get()) {
+//     return 0;
+//   }
+
+//   // Retrieve the number of active audio devices for the specified direction.
+//   UINT number_of_active_devices = 0;
+//   collection->GetCount(&number_of_active_devices);
+//   std::string str;
+//   if (data_flow == eCapture) {
+//     str = "Number of capture devices: ";
+//   } else if (data_flow == eRender) {
+//     str = "Number of render devices: ";
+//   } else if (data_flow == eAll) {
+//     str = "Total number of devices: ";
+//   }
+//   RTC_DLOG(INFO) << str << number_of_active_devices;
+//   return static_cast<int>(number_of_active_devices);
+// }
 
 uint32_t GetAudioClientVersion() {
   uint32_t version = 1;
@@ -712,196 +712,198 @@ uint32_t GetAudioClientVersion() {
   return version;
 }
 
-ComPtr<IMMDeviceEnumerator> CreateDeviceEnumerator() {
-  RTC_DLOG(INFO) << "CreateDeviceEnumerator";
-  return CreateDeviceEnumeratorInternal(true);
-}
+// ComPtr<IMMDeviceEnumerator> CreateDeviceEnumerator() {
+//   RTC_DLOG(INFO) << "CreateDeviceEnumerator";
+//   return CreateDeviceEnumeratorInternal(true);
+// }
 
 std::string GetDefaultInputDeviceID() {
   RTC_DLOG(INFO) << "GetDefaultInputDeviceID";
-  ComPtr<IMMDevice> device(
-      CreateDevice(AudioDeviceName::kDefaultDeviceId, eCapture, eConsole));
-  return device.Get() ? GetDeviceIdInternal(device.Get()) : std::string();
+  // ComPtr<IMMDevice> device{};
+  //     // CreateDevice(AudioDeviceName::kDefaultDeviceId, eCapture, eConsole));
+  // return device.Get() ? GetDeviceIdInternal(device.Get()) : std::string();
+  return {};
 }
 
 std::string GetDefaultOutputDeviceID() {
   RTC_DLOG(INFO) << "GetDefaultOutputDeviceID";
-  ComPtr<IMMDevice> device(
-      CreateDevice(AudioDeviceName::kDefaultDeviceId, eRender, eConsole));
-  return device.Get() ? GetDeviceIdInternal(device.Get()) : std::string();
+  // ComPtr<IMMDevice> device{};
+      // CreateDevice(AudioDeviceName::kDefaultDeviceId, eRender, eConsole));
+  // return device.Get() ? GetDeviceIdInternal(device.Get()) : std::string();
+  return {};
 }
 
 std::string GetCommunicationsInputDeviceID() {
   RTC_DLOG(INFO) << "GetCommunicationsInputDeviceID";
-  ComPtr<IMMDevice> device(CreateDevice(AudioDeviceName::kDefaultDeviceId,
-                                        eCapture, eCommunications));
-  return device.Get() ? GetDeviceIdInternal(device.Get()) : std::string();
+  // ComPtr<IMMDevice> device(CreateDevice(AudioDeviceName::kDefaultDeviceId,
+  //                                       eCapture, eCommunications));
+  return /*device.Get() ? GetDeviceIdInternal(device.Get()) :*/ std::string();
 }
 
 std::string GetCommunicationsOutputDeviceID() {
   RTC_DLOG(INFO) << "GetCommunicationsOutputDeviceID";
-  ComPtr<IMMDevice> device(CreateDevice(AudioDeviceName::kDefaultDeviceId,
-                                        eRender, eCommunications));
-  return device.Get() ? GetDeviceIdInternal(device.Get()) : std::string();
-}
-
-ComPtr<IMMDevice> CreateDevice(const std::string& device_id,
-                               EDataFlow data_flow,
-                               ERole role) {
-  RTC_DLOG(INFO) << "CreateDevice";
-  return CreateDeviceInternal(device_id, data_flow, role);
-}
-
-AudioDeviceName GetDeviceName(IMMDevice* device) {
-  RTC_DLOG(INFO) << "GetDeviceName";
-  RTC_DCHECK(device);
-  AudioDeviceName device_name(GetDeviceFriendlyNameInternal(device),
-                              GetDeviceIdInternal(device));
-  RTC_DLOG(INFO) << "friendly name: " << device_name.device_name;
-  RTC_DLOG(INFO) << "unique id    : " << device_name.unique_id;
-  return device_name;
-}
-
-std::string GetFriendlyName(const std::string& device_id,
-                            EDataFlow data_flow,
-                            ERole role) {
-  RTC_DLOG(INFO) << "GetFriendlyName";
-  ComPtr<IMMDevice> audio_device = CreateDevice(device_id, data_flow, role);
-  if (!audio_device.Get())
-    return std::string();
-
-  AudioDeviceName device_name = GetDeviceName(audio_device.Get());
-  return device_name.device_name;
-}
-
-EDataFlow GetDataFlow(IMMDevice* device) {
-  RTC_DLOG(INFO) << "GetDataFlow";
-  RTC_DCHECK(device);
-  ComPtr<IMMEndpoint> endpoint;
-  _com_error error = device->QueryInterface(endpoint.GetAddressOf());
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMDevice::QueryInterface failed: "
-                      << ErrorToString(error);
-    return eAll;
-  }
-
-  EDataFlow data_flow;
-  error = endpoint->GetDataFlow(&data_flow);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IMMEndpoint::GetDataFlow failed: "
-                      << ErrorToString(error);
-    return eAll;
-  }
-  return data_flow;
-}
+  // ComPtr<IMMDevice> device(CreateDevice(AudioDeviceName::kDefaultDeviceId,
+  //                                       eRender, eCommunications));
+  return /*device.Get() ? GetDeviceIdInternal(device.Get()) :*/ std::string();
+}
+
+// ComPtr<IMMDevice> CreateDevice(const std::string& device_id,
+//                                EDataFlow data_flow,
+//                                ERole role) {
+//   RTC_DLOG(INFO) << "CreateDevice";
+//   return CreateDeviceInternal(device_id, data_flow, role);
+// }
+
+// AudioDeviceName GetDeviceName(IMMDevice* device) {
+//   RTC_DLOG(INFO) << "GetDeviceName";
+//   RTC_DCHECK(device);
+//   AudioDeviceName device_name(GetDeviceFriendlyNameInternal(device),
+//                               GetDeviceIdInternal(device));
+//   RTC_DLOG(INFO) << "friendly name: " << device_name.device_name;
+//   RTC_DLOG(INFO) << "unique id    : " << device_name.unique_id;
+//   return device_name;
+// }
+
+// std::string GetFriendlyName(const std::string& device_id,
+//                             EDataFlow data_flow,
+//                             ERole role) {
+//   RTC_DLOG(INFO) << "GetFriendlyName";
+//   ComPtr<IMMDevice> audio_device = CreateDevice(device_id, data_flow, role);
+//   if (!audio_device.Get())
+//     return std::string();
+
+//   AudioDeviceName device_name = GetDeviceName(audio_device.Get());
+//   return device_name.device_name;
+// }
+
+// EDataFlow GetDataFlow(IMMDevice* device) {
+//   RTC_DLOG(INFO) << "GetDataFlow";
+//   RTC_DCHECK(device);
+//   ComPtr<IMMEndpoint> endpoint;
+//   _com_error error = device->QueryInterface(endpoint.GetAddressOf());
+//   if (FAILED(error.Error())) {
+//     RTC_LOG(LS_ERROR) << "IMMDevice::QueryInterface failed: "
+//                       << ErrorToString(error);
+//     return eAll;
+//   }
+
+//   EDataFlow data_flow;
+//   error = endpoint->GetDataFlow(&data_flow);
+//   if (FAILED(error.Error())) {
+//     RTC_LOG(LS_ERROR) << "IMMEndpoint::GetDataFlow failed: "
+//                       << ErrorToString(error);
+//     return eAll;
+//   }
+//   return data_flow;
+// }
 
 bool GetInputDeviceNames(webrtc::AudioDeviceNames* device_names) {
   RTC_DLOG(INFO) << "GetInputDeviceNames";
   RTC_DCHECK(device_names);
   RTC_DCHECK(device_names->empty());
-  return GetDeviceNamesInternal(eCapture, device_names);
+  return false;//GetDeviceNamesInternal(eCapture, device_names);
 }
 
 bool GetOutputDeviceNames(webrtc::AudioDeviceNames* device_names) {
   RTC_DLOG(INFO) << "GetOutputDeviceNames";
   RTC_DCHECK(device_names);
   RTC_DCHECK(device_names->empty());
-  return GetDeviceNamesInternal(eRender, device_names);
+  return false;//GetDeviceNamesInternal(eRender, device_names);
 }
 
-ComPtr<IAudioSessionManager2> CreateSessionManager2(IMMDevice* device) {
-  RTC_DLOG(INFO) << "CreateSessionManager2";
-  return CreateSessionManager2Internal(device);
-}
+// ComPtr<IAudioSessionManager2> CreateSessionManager2(IMMDevice* device) {
+//   RTC_DLOG(INFO) << "CreateSessionManager2";
+//   return CreateSessionManager2Internal(device);
+// }
 
-Microsoft::WRL::ComPtr<IAudioSessionEnumerator> CreateSessionEnumerator(
-    IMMDevice* device) {
-  RTC_DLOG(INFO) << "CreateSessionEnumerator";
-  return CreateSessionEnumeratorInternal(device);
-}
+// Microsoft::WRL::ComPtr<IAudioSessionEnumerator> CreateSessionEnumerator(
+//     IMMDevice* device) {
+//   RTC_DLOG(INFO) << "CreateSessionEnumerator";
+//   return CreateSessionEnumeratorInternal(device);
+// }
 
 int NumberOfActiveSessions(IMMDevice* device) {
   RTC_DLOG(INFO) << "NumberOfActiveSessions";
-  ComPtr<IAudioSessionEnumerator> session_enumerator =
-      CreateSessionEnumerator(device);
+  // ComPtr<IAudioSessionEnumerator> session_enumerator =
+  //     CreateSessionEnumerator(device);
 
   // Iterate over all audio sessions for the given device.
-  int session_count = 0;
-  _com_error error = session_enumerator->GetCount(&session_count);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioSessionEnumerator::GetCount failed: "
-                      << ErrorToString(error);
-    return 0;
-  }
-  RTC_DLOG(INFO) << "Total number of audio sessions: " << session_count;
+  // int session_count = 0;
+  // _com_error error = session_enumerator->GetCount(&session_count);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioSessionEnumerator::GetCount failed: "
+  //                     << ErrorToString(error);
+  //   return 0;
+  // }
+  // RTC_DLOG(INFO) << "Total number of audio sessions: " << session_count;
 
   int num_active = 0;
-  for (int session = 0; session < session_count; session++) {
-    // Acquire the session control interface.
-    ComPtr<IAudioSessionControl> session_control;
-    error = session_enumerator->GetSession(session, &session_control);
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioSessionEnumerator::GetSession failed: "
-                        << ErrorToString(error);
-      return 0;
-    }
-
-    // Log the display name of the audio session for debugging purposes.
-    LPWSTR display_name;
-    if (SUCCEEDED(session_control->GetDisplayName(&display_name))) {
-      RTC_DLOG(INFO) << "display name: "
-                     << rtc::ToUtf8(display_name, wcslen(display_name));
-      CoTaskMemFree(display_name);
-    }
-
-    // Get the current state and check if the state is active or not.
-    AudioSessionState state;
-    error = session_control->GetState(&state);
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioSessionControl::GetState failed: "
-                        << ErrorToString(error);
-      return 0;
-    }
-    if (state == AudioSessionStateActive) {
-      ++num_active;
-    }
-  }
+  // for (int session = 0; session < session_count; session++) {
+  //   // Acquire the session control interface.
+  //   ComPtr<IAudioSessionControl> session_control;
+  //   error = session_enumerator->GetSession(session, &session_control);
+  //   if (FAILED(error.Error())) {
+  //     RTC_LOG(LS_ERROR) << "IAudioSessionEnumerator::GetSession failed: "
+  //                       << ErrorToString(error);
+  //     return 0;
+  //   }
+
+  //   // Log the display name of the audio session for debugging purposes.
+  //   LPWSTR display_name;
+  //   if (SUCCEEDED(session_control->GetDisplayName(&display_name))) {
+  //     RTC_DLOG(INFO) << "display name: "
+  //                    << rtc::ToUtf8(display_name, wcslen(display_name));
+  //     CoTaskMemFree(display_name);
+  //   }
+
+  //   // Get the current state and check if the state is active or not.
+  //   AudioSessionState state;
+  //   error = session_control->GetState(&state);
+  //   if (FAILED(error.Error())) {
+  //     RTC_LOG(LS_ERROR) << "IAudioSessionControl::GetState failed: "
+  //                       << ErrorToString(error);
+  //     return 0;
+  //   }
+  //   if (state == AudioSessionStateActive) {
+  //     ++num_active;
+  //   }
+  // }
 
   RTC_DLOG(INFO) << "Number of active audio sessions: " << num_active;
   return num_active;
 }
 
-ComPtr<IAudioClient> CreateClient(const std::string& device_id,
-                                  EDataFlow data_flow,
-                                  ERole role) {
-  RTC_DLOG(INFO) << "CreateClient";
-  ComPtr<IMMDevice> device(CreateDevice(device_id, data_flow, role));
-  return CreateClientInternal(device.Get());
-}
-
-ComPtr<IAudioClient2> CreateClient2(const std::string& device_id,
-                                    EDataFlow data_flow,
-                                    ERole role) {
-  RTC_DLOG(INFO) << "CreateClient2";
-  ComPtr<IMMDevice> device(CreateDevice(device_id, data_flow, role));
-  return CreateClient2Internal(device.Get());
-}
-
-ComPtr<IAudioClient3> CreateClient3(const std::string& device_id,
-                                    EDataFlow data_flow,
-                                    ERole role) {
-  RTC_DLOG(INFO) << "CreateClient3";
-  ComPtr<IMMDevice> device(CreateDevice(device_id, data_flow, role));
-  return CreateClient3Internal(device.Get());
-}
+// ComPtr<IAudioClient> CreateClient(const std::string& device_id,
+//                                   EDataFlow data_flow,
+//                                   ERole role) {
+//   RTC_DLOG(INFO) << "CreateClient";
+//   ComPtr<IMMDevice> device(CreateDevice(device_id, data_flow, role));
+//   return CreateClientInternal(device.Get());
+// }
+
+// ComPtr<IAudioClient2> CreateClient2(const std::string& device_id,
+//                                     EDataFlow data_flow,
+//                                     ERole role) {
+//   RTC_DLOG(INFO) << "CreateClient2";
+//   ComPtr<IMMDevice> device(CreateDevice(device_id, data_flow, role));
+//   return CreateClient2Internal(device.Get());
+// }
+
+// ComPtr<IAudioClient3> CreateClient3(const std::string& device_id,
+//                                     EDataFlow data_flow,
+//                                     ERole role) {
+//   RTC_DLOG(INFO) << "CreateClient3";
+//   ComPtr<IMMDevice> device(CreateDevice(device_id, data_flow, role));
+//   return CreateClient3Internal(device.Get());
+// }
 
 HRESULT SetClientProperties(IAudioClient2* client) {
   RTC_DLOG(INFO) << "SetClientProperties";
   RTC_DCHECK(client);
-  if (GetAudioClientVersion() < 2) {
-    RTC_LOG(LS_WARNING) << "Requires IAudioClient2 or higher";
-    return AUDCLNT_E_UNSUPPORTED_FORMAT;
-  }
+  // if (GetAudioClientVersion() < 2) {
+  //   RTC_LOG(LS_WARNING) << "Requires IAudioClient2 or higher";
+  //   return AUDCLNT_E_UNSUPPORTED_FORMAT;
+  // }
   AudioClientProperties props = {0};
   props.cbSize = sizeof(AudioClientProperties);
   // Real-time VoIP communication.
@@ -913,12 +915,12 @@ HRESULT SetClientProperties(IAudioClient2* client) {
   // TODO(henrika): evaluate hardware-offloading. Might complicate usage of
   // IAudioClient::GetMixFormat().
   BOOL supports_offload = FALSE;
-  _com_error error =
-      client->IsOffloadCapable(props.eCategory, &supports_offload);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient2::IsOffloadCapable failed: "
-                      << ErrorToString(error);
-  }
+  // _com_error error =
+  //     client->IsOffloadCapable(props.eCategory, &supports_offload);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient2::IsOffloadCapable failed: "
+  //                     << ErrorToString(error);
+  // }
   RTC_DLOG(INFO) << "supports_offload: " << supports_offload;
   props.bIsOffload = false;
 #if (NTDDI_VERSION < NTDDI_WINBLUE)
@@ -941,12 +943,13 @@ HRESULT SetClientProperties(IAudioClient2* client) {
   // props.Options |= AUDCLNT_STREAMOPTIONS_MATCH_FORMAT;
   RTC_DLOG(INFO) << "options: 0x" << rtc::ToHex(props.Options);
 #endif
-  error = client->SetClientProperties(&props);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient2::SetClientProperties failed: "
-                      << ErrorToString(error);
-  }
-  return error.Error();
+  // error = client->SetClientProperties(&props);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient2::SetClientProperties failed: "
+  //                     << ErrorToString(error);
+  // }
+  // return error.Error();
+  return 0;
 }
 
 HRESULT GetBufferSizeLimits(IAudioClient2* client,
@@ -955,30 +958,31 @@ HRESULT GetBufferSizeLimits(IAudioClient2* client,
                             REFERENCE_TIME* max_buffer_duration) {
   RTC_DLOG(INFO) << "GetBufferSizeLimits";
   RTC_DCHECK(client);
-  if (GetAudioClientVersion() < 2) {
-    RTC_LOG(LS_WARNING) << "Requires IAudioClient2 or higher";
-    return AUDCLNT_E_UNSUPPORTED_FORMAT;
-  }
-  REFERENCE_TIME min_duration = 0;
-  REFERENCE_TIME max_duration = 0;
-  _com_error error =
-      client->GetBufferSizeLimits(reinterpret_cast<const WAVEFORMATEX*>(format),
-                                  TRUE, &min_duration, &max_duration);
-  if (error.Error() == AUDCLNT_E_OFFLOAD_MODE_ONLY) {
-    // This API seems to be supported in off-load mode only but it is not
-    // documented as a valid error code. Making a special note about it here.
-    RTC_LOG(LS_ERROR) << "IAudioClient2::GetBufferSizeLimits failed: "
-                         "AUDCLNT_E_OFFLOAD_MODE_ONLY";
-  } else if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient2::GetBufferSizeLimits failed: "
-                      << ErrorToString(error);
-  } else {
-    *min_buffer_duration = min_duration;
-    *max_buffer_duration = max_duration;
-    RTC_DLOG(INFO) << "min_buffer_duration: " << min_buffer_duration;
-    RTC_DLOG(INFO) << "max_buffer_duration: " << max_buffer_duration;
-  }
-  return error.Error();
+  // if (GetAudioClientVersion() < 2) {
+  //   RTC_LOG(LS_WARNING) << "Requires IAudioClient2 or higher";
+  //   return AUDCLNT_E_UNSUPPORTED_FORMAT;
+  // }
+  // REFERENCE_TIME min_duration = 0;
+  // REFERENCE_TIME max_duration = 0;
+  // _com_error error =
+  //     client->GetBufferSizeLimits(reinterpret_cast<const WAVEFORMATEX*>(format),
+  //                                 TRUE, &min_duration, &max_duration);
+  // if (error.Error() == AUDCLNT_E_OFFLOAD_MODE_ONLY) {
+  //   // This API seems to be supported in off-load mode only but it is not
+  //   // documented as a valid error code. Making a special note about it here.
+  //   RTC_LOG(LS_ERROR) << "IAudioClient2::GetBufferSizeLimits failed: "
+  //                        "AUDCLNT_E_OFFLOAD_MODE_ONLY";
+  // } else if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient2::GetBufferSizeLimits failed: "
+  //                     << ErrorToString(error);
+  // } else {
+  //   *min_buffer_duration = min_duration;
+  //   *max_buffer_duration = max_duration;
+  //   RTC_DLOG(INFO) << "min_buffer_duration: " << min_buffer_duration;
+  //   RTC_DLOG(INFO) << "max_buffer_duration: " << max_buffer_duration;
+  // }
+  // return error.Error();
+  return 0;
 }
 
 HRESULT GetSharedModeMixFormat(IAudioClient* client,
@@ -998,41 +1002,42 @@ HRESULT GetSharedModeMixFormat(IAudioClient* client,
   // where only the WAVEFORMATEX parts is initialized and we must be able to
   // account for that.
   ScopedCoMem<WAVEFORMATEXTENSIBLE> mix_format;
-  _com_error error =
-      client->GetMixFormat(reinterpret_cast<WAVEFORMATEX**>(&mix_format));
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetMixFormat failed: "
-                      << ErrorToString(error);
-    return error.Error();
-  }
-
-  // Use a wave format wrapper to make things simpler.
-  WaveFormatWrapper wrapped_format(mix_format.Get());
-
-  // Verify that the reported format can be mixed by the audio engine in
-  // shared mode.
-  if (!wrapped_format.IsPcm() && !wrapped_format.IsFloat()) {
-    RTC_DLOG(LS_ERROR)
-        << "Only pure PCM or float audio streams can be mixed in shared mode";
-    return AUDCLNT_E_UNSUPPORTED_FORMAT;
-  }
-
-  // Log a warning for the rare case where |mix_format| only contains a
-  // stand-alone WAVEFORMATEX structure but don't return.
-  if (!wrapped_format.IsExtensible()) {
-    RTC_DLOG(WARNING)
-        << "The returned format contains no extended information. "
-           "The size is "
-        << wrapped_format.size() << " bytes.";
-  }
-
-  // Copy the correct number of bytes into |*format| taking into account if
-  // the returned structure is correctly extended or not.
-  RTC_CHECK_LE(wrapped_format.size(), sizeof(WAVEFORMATEXTENSIBLE));
-  memcpy(format, wrapped_format.get(), wrapped_format.size());
-  RTC_DLOG(INFO) << WaveFormatToString(format);
-
-  return error.Error();
+  // _com_error error =
+  //     client->GetMixFormat(reinterpret_cast<WAVEFORMATEX**>(&mix_format));
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetMixFormat failed: "
+  //                     << ErrorToString(error);
+  //   return error.Error();
+  // }
+
+  // // Use a wave format wrapper to make things simpler.
+  // WaveFormatWrapper wrapped_format(mix_format.Get());
+
+  // // Verify that the reported format can be mixed by the audio engine in
+  // // shared mode.
+  // if (!wrapped_format.IsPcm() && !wrapped_format.IsFloat()) {
+  //   RTC_DLOG(LS_ERROR)
+  //       << "Only pure PCM or float audio streams can be mixed in shared mode";
+  //   return AUDCLNT_E_UNSUPPORTED_FORMAT;
+  // }
+
+  // // Log a warning for the rare case where |mix_format| only contains a
+  // // stand-alone WAVEFORMATEX structure but don't return.
+  // if (!wrapped_format.IsExtensible()) {
+  //   RTC_DLOG(WARNING)
+  //       << "The returned format contains no extended information. "
+  //          "The size is "
+  //       << wrapped_format.size() << " bytes.";
+  // }
+
+  // // Copy the correct number of bytes into |*format| taking into account if
+  // // the returned structure is correctly extended or not.
+  // RTC_CHECK_LE(wrapped_format.size(), sizeof(WAVEFORMATEXTENSIBLE));
+  // memcpy(format, wrapped_format.get(), wrapped_format.size());
+  // RTC_DLOG(INFO) << WaveFormatToString(format);
+
+  // return error.Error();
+  return 0;
 }
 
 bool IsFormatSupported(IAudioClient* client,
@@ -1046,32 +1051,33 @@ bool IsFormatSupported(IAudioClient* client,
   // stream format or not. In shared mode, the audio engine always supports
   // the mix format (see GetSharedModeMixFormat).
   // TODO(henrika): verify support for exclusive mode as well?
-  _com_error error = client->IsFormatSupported(
-      share_mode, reinterpret_cast<const WAVEFORMATEX*>(format),
-      &closest_match);
-  RTC_LOG(INFO) << WaveFormatToString(
-      const_cast<WAVEFORMATEXTENSIBLE*>(format));
-  if ((error.Error() == S_OK) && (closest_match == nullptr)) {
-    RTC_DLOG(INFO)
-        << "The audio endpoint device supports the specified stream format";
-  } else if ((error.Error() == S_FALSE) && (closest_match != nullptr)) {
-    // Call succeeded with a closest match to the specified format. This log can
-    // only be triggered for shared mode.
-    RTC_LOG(LS_WARNING)
-        << "Exact format is not supported, but a closest match exists";
-    RTC_LOG(INFO) << WaveFormatToString(closest_match.Get());
-  } else if ((error.Error() == AUDCLNT_E_UNSUPPORTED_FORMAT) &&
-             (closest_match == nullptr)) {
-    // The audio engine does not support the caller-specified format or any
-    // similar format.
-    RTC_DLOG(INFO) << "The audio endpoint device does not support the "
-                      "specified stream format";
-  } else {
-    RTC_LOG(LS_ERROR) << "IAudioClient::IsFormatSupported failed: "
-                      << ErrorToString(error);
-  }
-
-  return (error.Error() == S_OK);
+  // _com_error error = client->IsFormatSupported(
+  //     share_mode, reinterpret_cast<const WAVEFORMATEX*>(format),
+  //     &closest_match);
+  // RTC_LOG(INFO) << WaveFormatToString(
+  //     const_cast<WAVEFORMATEXTENSIBLE*>(format));
+  // if ((error.Error() == S_OK) && (closest_match == nullptr)) {
+  //   RTC_DLOG(INFO)
+  //       << "The audio endpoint device supports the specified stream format";
+  // } else if ((error.Error() == S_FALSE) && (closest_match != nullptr)) {
+  //   // Call succeeded with a closest match to the specified format. This log can
+  //   // only be triggered for shared mode.
+  //   RTC_LOG(LS_WARNING)
+  //       << "Exact format is not supported, but a closest match exists";
+  //   RTC_LOG(INFO) << WaveFormatToString(closest_match.Get());
+  // } else if ((error.Error() == AUDCLNT_E_UNSUPPORTED_FORMAT) &&
+  //            (closest_match == nullptr)) {
+  //   // The audio engine does not support the caller-specified format or any
+  //   // similar format.
+  //   RTC_DLOG(INFO) << "The audio endpoint device does not support the "
+  //                     "specified stream format";
+  // } else {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::IsFormatSupported failed: "
+  //                     << ErrorToString(error);
+  // }
+
+  // return (error.Error() == S_OK);
+  return false;
 }
 
 HRESULT GetDevicePeriod(IAudioClient* client,
@@ -1083,22 +1089,23 @@ HRESULT GetDevicePeriod(IAudioClient* client,
   // for a shared-mode stream. The |minimum_period| parameter specifies the
   // minimum scheduling period for an exclusive-mode stream.
   // The time is expressed in 100-nanosecond units.
-  REFERENCE_TIME default_period = 0;
-  REFERENCE_TIME minimum_period = 0;
-  _com_error error = client->GetDevicePeriod(&default_period, &minimum_period);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetDevicePeriod failed: "
-                      << ErrorToString(error);
-    return error.Error();
-  }
-
-  *device_period = (share_mode == AUDCLNT_SHAREMODE_SHARED) ? default_period
-                                                            : minimum_period;
-  RTC_LOG(INFO) << "device_period: "
-                << ReferenceTimeToTimeDelta(*device_period).ms() << " [ms]";
-  RTC_LOG(INFO) << "minimum_period: "
-                << ReferenceTimeToTimeDelta(minimum_period).ms() << " [ms]";
-  return error.Error();
+  // REFERENCE_TIME default_period = 0;
+  // REFERENCE_TIME minimum_period = 0;
+  // _com_error error = client->GetDevicePeriod(&default_period, &minimum_period);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetDevicePeriod failed: "
+  //                     << ErrorToString(error);
+  //   return error.Error();
+  // }
+
+  // *device_period = (share_mode == AUDCLNT_SHAREMODE_SHARED) ? default_period
+  //                                                           : minimum_period;
+  // RTC_LOG(INFO) << "device_period: "
+  //               << ReferenceTimeToTimeDelta(*device_period).ms() << " [ms]";
+  // RTC_LOG(INFO) << "minimum_period: "
+  //               << ReferenceTimeToTimeDelta(minimum_period).ms() << " [ms]";
+  // return error.Error();
+  return 0;
 }
 
 HRESULT GetSharedModeEnginePeriod(IAudioClient3* client3,
@@ -1110,35 +1117,36 @@ HRESULT GetSharedModeEnginePeriod(IAudioClient3* client3,
   RTC_DLOG(INFO) << "GetSharedModeEnginePeriod";
   RTC_DCHECK(client3);
 
-  UINT32 default_period = 0;
-  UINT32 fundamental_period = 0;
-  UINT32 min_period = 0;
-  UINT32 max_period = 0;
-  _com_error error = client3->GetSharedModeEnginePeriod(
-      reinterpret_cast<const WAVEFORMATEX*>(format), &default_period,
-      &fundamental_period, &min_period, &max_period);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient3::GetSharedModeEnginePeriod failed: "
-                      << ErrorToString(error);
-    return error.Error();
-  }
-
-  WAVEFORMATEX format_ex = format->Format;
-  const WORD sample_rate = format_ex.nSamplesPerSec;
-  RTC_LOG(INFO) << "default_period_in_frames: " << default_period << " ("
-                << FramesToMilliseconds(default_period, sample_rate) << " ms)";
-  RTC_LOG(INFO) << "fundamental_period_in_frames: " << fundamental_period
-                << " (" << FramesToMilliseconds(fundamental_period, sample_rate)
-                << " ms)";
-  RTC_LOG(INFO) << "min_period_in_frames: " << min_period << " ("
-                << FramesToMilliseconds(min_period, sample_rate) << " ms)";
-  RTC_LOG(INFO) << "max_period_in_frames: " << max_period << " ("
-                << FramesToMilliseconds(max_period, sample_rate) << " ms)";
-  *default_period_in_frames = default_period;
-  *fundamental_period_in_frames = fundamental_period;
-  *min_period_in_frames = min_period;
-  *max_period_in_frames = max_period;
-  return error.Error();
+  // UINT32 default_period = 0;
+  // UINT32 fundamental_period = 0;
+  // UINT32 min_period = 0;
+  // UINT32 max_period = 0;
+  // _com_error error = client3->GetSharedModeEnginePeriod(
+  //     reinterpret_cast<const WAVEFORMATEX*>(format), &default_period,
+  //     &fundamental_period, &min_period, &max_period);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient3::GetSharedModeEnginePeriod failed: "
+  //                     << ErrorToString(error);
+  //   return error.Error();
+  // }
+
+  // WAVEFORMATEX format_ex = format->Format;
+  // const WORD sample_rate = format_ex.nSamplesPerSec;
+  // RTC_LOG(INFO) << "default_period_in_frames: " << default_period << " ("
+  //               << FramesToMilliseconds(default_period, sample_rate) << " ms)";
+  // RTC_LOG(INFO) << "fundamental_period_in_frames: " << fundamental_period
+  //               << " (" << FramesToMilliseconds(fundamental_period, sample_rate)
+  //               << " ms)";
+  // RTC_LOG(INFO) << "min_period_in_frames: " << min_period << " ("
+  //               << FramesToMilliseconds(min_period, sample_rate) << " ms)";
+  // RTC_LOG(INFO) << "max_period_in_frames: " << max_period << " ("
+  //               << FramesToMilliseconds(max_period, sample_rate) << " ms)";
+  // *default_period_in_frames = default_period;
+  // *fundamental_period_in_frames = fundamental_period;
+  // *min_period_in_frames = min_period;
+  // *max_period_in_frames = max_period;
+  // return error.Error();
+  return 0;
 }
 
 HRESULT GetPreferredAudioParameters(IAudioClient* client,
@@ -1206,61 +1214,62 @@ HRESULT SharedModeInitialize(IAudioClient* client,
   // Initialize the shared mode client for minimal delay if |buffer_duration|
   // is 0 or possibly a higher delay (more robust) if |buffer_duration| is
   // larger than 0. The actual size is given by IAudioClient::GetBufferSize().
-  _com_error error = client->Initialize(
-      AUDCLNT_SHAREMODE_SHARED, stream_flags, buffer_duration, 0,
-      reinterpret_cast<const WAVEFORMATEX*>(format), nullptr);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::Initialize failed: "
-                      << ErrorToString(error);
-    return error.Error();
-  }
-
-  // If a stream is initialized to be event driven and in shared mode, the
-  // associated application must also obtain a handle by making a call to
-  // IAudioClient::SetEventHandle.
-  if (use_event) {
-    error = client->SetEventHandle(event_handle);
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioClient::SetEventHandle failed: "
-                        << ErrorToString(error);
-      return error.Error();
-    }
-  }
-
-  UINT32 buffer_size_in_frames = 0;
-  // Retrieves the size (maximum capacity) of the endpoint buffer. The size is
-  // expressed as the number of audio frames the buffer can hold.
-  // For rendering clients, the buffer length determines the maximum amount of
-  // rendering data that the application can write to the endpoint buffer
-  // during a single processing pass. For capture clients, the buffer length
-  // determines the maximum amount of capture data that the audio engine can
-  // read from the endpoint buffer during a single processing pass.
-  error = client->GetBufferSize(&buffer_size_in_frames);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetBufferSize failed: "
-                      << ErrorToString(error);
-    return error.Error();
-  }
-
-  *endpoint_buffer_size = buffer_size_in_frames;
-  RTC_DLOG(INFO) << "endpoint buffer size: " << buffer_size_in_frames
-                 << " [audio frames]";
-  const double size_in_ms = static_cast<double>(buffer_size_in_frames) /
-                            (format->Format.nSamplesPerSec / 1000.0);
-  RTC_DLOG(INFO) << "endpoint buffer size: "
-                 << static_cast<int>(size_in_ms + 0.5) << " [ms]";
-  RTC_DLOG(INFO) << "bytes per audio frame: " << format->Format.nBlockAlign;
-  RTC_DLOG(INFO) << "endpoint buffer size: "
-                 << buffer_size_in_frames * format->Format.nChannels *
-                        (format->Format.wBitsPerSample / 8)
-                 << " [bytes]";
-
-  // TODO(henrika): utilize when delay measurements are added.
-  REFERENCE_TIME latency = 0;
-  error = client->GetStreamLatency(&latency);
-  RTC_DLOG(INFO) << "stream latency: " << ReferenceTimeToTimeDelta(latency).ms()
-                 << " [ms]";
-  return error.Error();
+  // _com_error error = client->Initialize(
+  //     AUDCLNT_SHAREMODE_SHARED, stream_flags, buffer_duration, 0,
+  //     reinterpret_cast<const WAVEFORMATEX*>(format), nullptr);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::Initialize failed: "
+  //                     << ErrorToString(error);
+  //   return error.Error();
+  // }
+
+  // // If a stream is initialized to be event driven and in shared mode, the
+  // // associated application must also obtain a handle by making a call to
+  // // IAudioClient::SetEventHandle.
+  // if (use_event) {
+  //   error = client->SetEventHandle(event_handle);
+  //   if (FAILED(error.Error())) {
+  //     RTC_LOG(LS_ERROR) << "IAudioClient::SetEventHandle failed: "
+  //                       << ErrorToString(error);
+  //     return error.Error();
+  //   }
+  // }
+
+  // UINT32 buffer_size_in_frames = 0;
+  // // Retrieves the size (maximum capacity) of the endpoint buffer. The size is
+  // // expressed as the number of audio frames the buffer can hold.
+  // // For rendering clients, the buffer length determines the maximum amount of
+  // // rendering data that the application can write to the endpoint buffer
+  // // during a single processing pass. For capture clients, the buffer length
+  // // determines the maximum amount of capture data that the audio engine can
+  // // read from the endpoint buffer during a single processing pass.
+  // error = client->GetBufferSize(&buffer_size_in_frames);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetBufferSize failed: "
+  //                     << ErrorToString(error);
+  //   return error.Error();
+  // }
+
+  // *endpoint_buffer_size = buffer_size_in_frames;
+  // RTC_DLOG(INFO) << "endpoint buffer size: " << buffer_size_in_frames
+  //                << " [audio frames]";
+  // const double size_in_ms = static_cast<double>(buffer_size_in_frames) /
+  //                           (format->Format.nSamplesPerSec / 1000.0);
+  // RTC_DLOG(INFO) << "endpoint buffer size: "
+  //                << static_cast<int>(size_in_ms + 0.5) << " [ms]";
+  // RTC_DLOG(INFO) << "bytes per audio frame: " << format->Format.nBlockAlign;
+  // RTC_DLOG(INFO) << "endpoint buffer size: "
+  //                << buffer_size_in_frames * format->Format.nChannels *
+  //                       (format->Format.wBitsPerSample / 8)
+  //                << " [bytes]";
+
+  // // TODO(henrika): utilize when delay measurements are added.
+  // REFERENCE_TIME latency = 0;
+  // error = client->GetStreamLatency(&latency);
+  // RTC_DLOG(INFO) << "stream latency: " << ReferenceTimeToTimeDelta(latency).ms()
+  //                << " [ms]";
+  // return error.Error();
+  return 0;
 }
 
 HRESULT SharedModeInitializeLowLatency(IAudioClient3* client,
@@ -1295,58 +1304,59 @@ HRESULT SharedModeInitializeLowLatency(IAudioClient3* client,
   // Initialize the shared mode client for lowest possible latency.
   // It is assumed that GetSharedModeEnginePeriod() has been used to query the
   // smallest possible engine period and that it is given by |period_in_frames|.
-  _com_error error = client->InitializeSharedAudioStream(
-      stream_flags, period_in_frames,
-      reinterpret_cast<const WAVEFORMATEX*>(format), nullptr);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient3::InitializeSharedAudioStream failed: "
-                      << ErrorToString(error);
-    return error.Error();
-  }
-
-  // Set the event handle.
-  if (use_event) {
-    error = client->SetEventHandle(event_handle);
-    if (FAILED(error.Error())) {
-      RTC_LOG(LS_ERROR) << "IAudioClient::SetEventHandle failed: "
-                        << ErrorToString(error);
-      return error.Error();
-    }
-  }
-
-  UINT32 buffer_size_in_frames = 0;
-  // Retrieve the size (maximum capacity) of the endpoint buffer.
-  error = client->GetBufferSize(&buffer_size_in_frames);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetBufferSize failed: "
-                      << ErrorToString(error);
-    return error.Error();
-  }
-
-  *endpoint_buffer_size = buffer_size_in_frames;
-  RTC_DLOG(INFO) << "endpoint buffer size: " << buffer_size_in_frames
-                 << " [audio frames]";
-  const double size_in_ms = static_cast<double>(buffer_size_in_frames) /
-                            (format->Format.nSamplesPerSec / 1000.0);
-  RTC_DLOG(INFO) << "endpoint buffer size: "
-                 << static_cast<int>(size_in_ms + 0.5) << " [ms]";
-  RTC_DLOG(INFO) << "bytes per audio frame: " << format->Format.nBlockAlign;
-  RTC_DLOG(INFO) << "endpoint buffer size: "
-                 << buffer_size_in_frames * format->Format.nChannels *
-                        (format->Format.wBitsPerSample / 8)
-                 << " [bytes]";
-
-  // TODO(henrika): utilize when delay measurements are added.
-  REFERENCE_TIME latency = 0;
-  error = client->GetStreamLatency(&latency);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_WARNING) << "IAudioClient::GetStreamLatency failed: "
-                        << ErrorToString(error);
-  } else {
-    RTC_DLOG(INFO) << "stream latency: "
-                   << ReferenceTimeToTimeDelta(latency).ms() << " [ms]";
-  }
-  return error.Error();
+  // _com_error error = client->InitializeSharedAudioStream(
+  //     stream_flags, period_in_frames,
+  //     reinterpret_cast<const WAVEFORMATEX*>(format), nullptr);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient3::InitializeSharedAudioStream failed: "
+  //                     << ErrorToString(error);
+  //   return error.Error();
+  // }
+
+  // // Set the event handle.
+  // if (use_event) {
+  //   error = client->SetEventHandle(event_handle);
+  //   if (FAILED(error.Error())) {
+  //     RTC_LOG(LS_ERROR) << "IAudioClient::SetEventHandle failed: "
+  //                       << ErrorToString(error);
+  //     return error.Error();
+  //   }
+  // }
+
+  // UINT32 buffer_size_in_frames = 0;
+  // // Retrieve the size (maximum capacity) of the endpoint buffer.
+  // error = client->GetBufferSize(&buffer_size_in_frames);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetBufferSize failed: "
+  //                     << ErrorToString(error);
+  //   return error.Error();
+  // }
+
+  // *endpoint_buffer_size = buffer_size_in_frames;
+  // RTC_DLOG(INFO) << "endpoint buffer size: " << buffer_size_in_frames
+  //                << " [audio frames]";
+  // const double size_in_ms = static_cast<double>(buffer_size_in_frames) /
+  //                           (format->Format.nSamplesPerSec / 1000.0);
+  // RTC_DLOG(INFO) << "endpoint buffer size: "
+  //                << static_cast<int>(size_in_ms + 0.5) << " [ms]";
+  // RTC_DLOG(INFO) << "bytes per audio frame: " << format->Format.nBlockAlign;
+  // RTC_DLOG(INFO) << "endpoint buffer size: "
+  //                << buffer_size_in_frames * format->Format.nChannels *
+  //                       (format->Format.wBitsPerSample / 8)
+  //                << " [bytes]";
+
+  // // TODO(henrika): utilize when delay measurements are added.
+  // REFERENCE_TIME latency = 0;
+  // error = client->GetStreamLatency(&latency);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_WARNING) << "IAudioClient::GetStreamLatency failed: "
+  //                       << ErrorToString(error);
+  // } else {
+  //   RTC_DLOG(INFO) << "stream latency: "
+  //                  << ReferenceTimeToTimeDelta(latency).ms() << " [ms]";
+  // }
+  // return error.Error();
+  return 0;
 }
 
 ComPtr<IAudioRenderClient> CreateRenderClient(IAudioClient* client) {
@@ -1355,13 +1365,13 @@ ComPtr<IAudioRenderClient> CreateRenderClient(IAudioClient* client) {
   // Get access to the IAudioRenderClient interface. This interface
   // enables us to write output data to a rendering endpoint buffer.
   ComPtr<IAudioRenderClient> audio_render_client;
-  _com_error error = client->GetService(IID_PPV_ARGS(&audio_render_client));
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR)
-        << "IAudioClient::GetService(IID_IAudioRenderClient) failed: "
-        << ErrorToString(error);
-    return ComPtr<IAudioRenderClient>();
-  }
+  // _com_error error = client->GetService(IID_PPV_ARGS(&audio_render_client));
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR)
+  //       << "IAudioClient::GetService(IID_IAudioRenderClient) failed: "
+  //       << ErrorToString(error);
+  //   return ComPtr<IAudioRenderClient>();
+  // }
   return audio_render_client;
 }
 
@@ -1371,13 +1381,13 @@ ComPtr<IAudioCaptureClient> CreateCaptureClient(IAudioClient* client) {
   // Get access to the IAudioCaptureClient interface. This interface
   // enables us to read input data from a capturing endpoint buffer.
   ComPtr<IAudioCaptureClient> audio_capture_client;
-  _com_error error = client->GetService(IID_PPV_ARGS(&audio_capture_client));
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR)
-        << "IAudioClient::GetService(IID_IAudioCaptureClient) failed: "
-        << ErrorToString(error);
-    return ComPtr<IAudioCaptureClient>();
-  }
+  // _com_error error = client->GetService(IID_PPV_ARGS(&audio_capture_client));
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR)
+  //       << "IAudioClient::GetService(IID_IAudioCaptureClient) failed: "
+  //       << ErrorToString(error);
+  //   return ComPtr<IAudioCaptureClient>();
+  // }
   return audio_capture_client;
 }
 
@@ -1387,12 +1397,12 @@ ComPtr<IAudioClock> CreateAudioClock(IAudioClient* client) {
   // Get access to the IAudioClock interface. This interface enables us to
   // monitor a stream's data rate and the current position in the stream.
   ComPtr<IAudioClock> audio_clock;
-  _com_error error = client->GetService(IID_PPV_ARGS(&audio_clock));
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetService(IID_IAudioClock) failed: "
-                      << ErrorToString(error);
-    return ComPtr<IAudioClock>();
-  }
+  // _com_error error = client->GetService(IID_PPV_ARGS(&audio_clock));
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetService(IID_IAudioClock) failed: "
+  //                     << ErrorToString(error);
+  //   return ComPtr<IAudioClock>();
+  // }
   return audio_clock;
 }
 
@@ -1400,12 +1410,12 @@ ComPtr<IAudioSessionControl> CreateAudioSessionControl(IAudioClient* client) {
   RTC_DLOG(INFO) << "CreateAudioSessionControl";
   RTC_DCHECK(client);
   ComPtr<IAudioSessionControl> audio_session_control;
-  _com_error error = client->GetService(IID_PPV_ARGS(&audio_session_control));
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetService(IID_IAudioControl) failed: "
-                      << ErrorToString(error);
-    return ComPtr<IAudioSessionControl>();
-  }
+  // _com_error error = client->GetService(IID_PPV_ARGS(&audio_session_control));
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetService(IID_IAudioControl) failed: "
+  //                     << ErrorToString(error);
+  //   return ComPtr<IAudioSessionControl>();
+  // }
   return audio_session_control;
 }
 
@@ -1415,13 +1425,13 @@ ComPtr<ISimpleAudioVolume> CreateSimpleAudioVolume(IAudioClient* client) {
   // Get access to the ISimpleAudioVolume interface. This interface enables a
   // client to control the master volume level of an audio session.
   ComPtr<ISimpleAudioVolume> simple_audio_volume;
-  _com_error error = client->GetService(IID_PPV_ARGS(&simple_audio_volume));
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR)
-        << "IAudioClient::GetService(IID_ISimpleAudioVolume) failed: "
-        << ErrorToString(error);
-    return ComPtr<ISimpleAudioVolume>();
-  }
+  // _com_error error = client->GetService(IID_PPV_ARGS(&simple_audio_volume));
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR)
+  //       << "IAudioClient::GetService(IID_ISimpleAudioVolume) failed: "
+  //       << ErrorToString(error);
+  //   return ComPtr<ISimpleAudioVolume>();
+  // }
   return simple_audio_volume;
 }
 
@@ -1430,49 +1440,49 @@ bool FillRenderEndpointBufferWithSilence(IAudioClient* client,
   RTC_DLOG(INFO) << "FillRenderEndpointBufferWithSilence";
   RTC_DCHECK(client);
   RTC_DCHECK(render_client);
-  UINT32 endpoint_buffer_size = 0;
-  _com_error error = client->GetBufferSize(&endpoint_buffer_size);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetBufferSize failed: "
-                      << ErrorToString(error);
-    return false;
-  }
-
-  UINT32 num_queued_frames = 0;
-  // Get number of audio frames that are queued up to play in the endpoint
-  // buffer.
-  error = client->GetCurrentPadding(&num_queued_frames);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioClient::GetCurrentPadding failed: "
-                      << ErrorToString(error);
-    return false;
-  }
-  RTC_DLOG(INFO) << "num_queued_frames: " << num_queued_frames;
-
-  BYTE* data = nullptr;
-  int num_frames_to_fill = endpoint_buffer_size - num_queued_frames;
-  RTC_DLOG(INFO) << "num_frames_to_fill: " << num_frames_to_fill;
-  error = render_client->GetBuffer(num_frames_to_fill, &data);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioRenderClient::GetBuffer failed: "
-                      << ErrorToString(error);
-    return false;
-  }
-
-  // Using the AUDCLNT_BUFFERFLAGS_SILENT flag eliminates the need to
-  // explicitly write silence data to the rendering buffer.
-  error = render_client->ReleaseBuffer(num_frames_to_fill,
-                                       AUDCLNT_BUFFERFLAGS_SILENT);
-  if (FAILED(error.Error())) {
-    RTC_LOG(LS_ERROR) << "IAudioRenderClient::ReleaseBuffer failed: "
-                      << ErrorToString(error);
-    return false;
-  }
+  // UINT32 endpoint_buffer_size = 0;
+  // _com_error error = client->GetBufferSize(&endpoint_buffer_size);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetBufferSize failed: "
+  //                     << ErrorToString(error);
+  //   return false;
+  // }
+
+  // UINT32 num_queued_frames = 0;
+  // // Get number of audio frames that are queued up to play in the endpoint
+  // // buffer.
+  // error = client->GetCurrentPadding(&num_queued_frames);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioClient::GetCurrentPadding failed: "
+  //                     << ErrorToString(error);
+  //   return false;
+  // }
+  // RTC_DLOG(INFO) << "num_queued_frames: " << num_queued_frames;
+
+  // BYTE* data = nullptr;
+  // int num_frames_to_fill = endpoint_buffer_size - num_queued_frames;
+  // RTC_DLOG(INFO) << "num_frames_to_fill: " << num_frames_to_fill;
+  // error = render_client->GetBuffer(num_frames_to_fill, &data);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioRenderClient::GetBuffer failed: "
+  //                     << ErrorToString(error);
+  //   return false;
+  // }
+
+  // // Using the AUDCLNT_BUFFERFLAGS_SILENT flag eliminates the need to
+  // // explicitly write silence data to the rendering buffer.
+  // error = render_client->ReleaseBuffer(num_frames_to_fill,
+  //                                      AUDCLNT_BUFFERFLAGS_SILENT);
+  // if (FAILED(error.Error())) {
+  //   RTC_LOG(LS_ERROR) << "IAudioRenderClient::ReleaseBuffer failed: "
+  //                     << ErrorToString(error);
+  //   return false;
+  // }
 
   return true;
 }
 
-std::string WaveFormatToString(const WaveFormatWrapper format) {
+std::string WaveFormatToString(const core_audio_utility::WaveFormatWrapper format) {
   char ss_buf[1024];
   rtc::SimpleStringBuilder ss(ss_buf);
   // Start with the WAVEFORMATEX part (which always exists).
@@ -1516,7 +1526,7 @@ double FramesToMilliseconds(uint32_t num_frames, uint16_t sample_rate) {
 std::string ErrorToString(const _com_error& error) {
   char ss_buf[1024];
   rtc::SimpleStringBuilder ss(ss_buf);
-  ss.AppendFormat("(HRESULT: 0x%08X)", error.Error());
+  // ss.AppendFormat("(HRESULT: 0x%08X)", error.Error());
   return ss.str();
 }
 
diff --git a/modules/audio_device/win/core_audio_utility_win.h b/modules/audio_device/win/core_audio_utility_win.h
index 265b8996d7..19b4e05e38 100644
--- a/modules/audio_device/win/core_audio_utility_win.h
+++ b/modules/audio_device/win/core_audio_utility_win.h
@@ -83,30 +83,30 @@ class ScopedMMCSSRegistration {
   }
 
   explicit ScopedMMCSSRegistration(const wchar_t* task_name) {
-    RTC_DLOG(INFO) << "ScopedMMCSSRegistration: " << rtc::ToUtf8(task_name);
-    // Register the calling thread with MMCSS for the supplied |task_name|.
-    DWORD mmcss_task_index = 0;
-    mmcss_handle_ = AvSetMmThreadCharacteristicsW(task_name, &mmcss_task_index);
-    if (mmcss_handle_ == nullptr) {
-      RTC_LOG(LS_ERROR) << "Failed to enable MMCSS on this thread: "
-                        << GetLastError();
-    } else {
-      const DWORD priority_class = GetPriorityClass(GetCurrentProcess());
-      const int priority = GetThreadPriority(GetCurrentThread());
-      RTC_DLOG(INFO) << "priority class: "
-                     << PriorityClassToString(priority_class) << "("
-                     << priority_class << ")";
-      RTC_DLOG(INFO) << "priority: " << PriorityToString(priority) << "("
-                     << priority << ")";
-    }
+    // RTC_DLOG(INFO) << "ScopedMMCSSRegistration: " << rtc::ToUtf8(task_name);
+    // // Register the calling thread with MMCSS for the supplied |task_name|.
+    // DWORD mmcss_task_index = 0;
+    // mmcss_handle_ = AvSetMmThreadCharacteristicsW(task_name, &mmcss_task_index);
+    // if (mmcss_handle_ == nullptr) {
+    //   RTC_LOG(LS_ERROR) << "Failed to enable MMCSS on this thread: "
+    //                     << GetLastError();
+    // } else {
+    //   const DWORD priority_class = GetPriorityClass(GetCurrentProcess());
+    //   const int priority = GetThreadPriority(GetCurrentThread());
+    //   RTC_DLOG(INFO) << "priority class: "
+    //                  << PriorityClassToString(priority_class) << "("
+    //                  << priority_class << ")";
+    //   RTC_DLOG(INFO) << "priority: " << PriorityToString(priority) << "("
+    //                  << priority << ")";
+    // }
   }
 
   ~ScopedMMCSSRegistration() {
-    if (Succeeded()) {
-      // Deregister with MMCSS.
-      RTC_DLOG(INFO) << "~ScopedMMCSSRegistration";
-      AvRevertMmThreadCharacteristics(mmcss_handle_);
-    }
+    // if (Succeeded()) {
+    //   // Deregister with MMCSS.
+    //   RTC_DLOG(INFO) << "~ScopedMMCSSRegistration";
+    //   AvRevertMmThreadCharacteristics(mmcss_handle_);
+    // }
   }
 
   ScopedMMCSSRegistration(const ScopedMMCSSRegistration&) = delete;
@@ -371,7 +371,7 @@ bool IsMMCSSSupported();
 // Number of active audio devices in the specified data flow direction.
 // Set |data_flow| to eAll to retrieve the total number of active audio
 // devices.
-int NumberOfActiveDevices(EDataFlow data_flow);
+// int NumberOfActiveDevices(EDataFlow data_flow);
 
 // Returns 1, 2, or 3 depending on what version of IAudioClient the platform
 // supports.
@@ -391,27 +391,27 @@ std::string GetDefaultOutputDeviceID();
 std::string GetCommunicationsInputDeviceID();
 std::string GetCommunicationsOutputDeviceID();
 
-// Creates an IMMDevice interface corresponding to the unique device id in
-// |device_id|, or by data-flow direction and role if |device_id| is set to
-// AudioDeviceName::kDefaultDeviceId.
-Microsoft::WRL::ComPtr<IMMDevice> CreateDevice(const std::string& device_id,
-                                               EDataFlow data_flow,
-                                               ERole role);
+// // Creates an IMMDevice interface corresponding to the unique device id in
+// // |device_id|, or by data-flow direction and role if |device_id| is set to
+// // AudioDeviceName::kDefaultDeviceId.
+// Microsoft::WRL::ComPtr<IMMDevice> CreateDevice(const std::string& device_id,
+//                                                EDataFlow data_flow,
+//                                                ERole role);
 
 // Returns the unique ID and user-friendly name of a given endpoint device.
 // Example: "{0.0.1.00000000}.{8db6020f-18e3-4f25-b6f5-7726c9122574}", and
 //          "Microphone (Realtek High Definition Audio)".
 webrtc::AudioDeviceName GetDeviceName(IMMDevice* device);
 
-// Gets the user-friendly name of the endpoint device which is represented
-// by a unique id in |device_id|, or by data-flow direction and role if
-// |device_id| is set to AudioDeviceName::kDefaultDeviceId.
-std::string GetFriendlyName(const std::string& device_id,
-                            EDataFlow data_flow,
-                            ERole role);
+// // Gets the user-friendly name of the endpoint device which is represented
+// // by a unique id in |device_id|, or by data-flow direction and role if
+// // |device_id| is set to AudioDeviceName::kDefaultDeviceId.
+// std::string GetFriendlyName(const std::string& device_id,
+//                             EDataFlow data_flow,
+//                             ERole role);
 
 // Query if the audio device is a rendering device or a capture device.
-EDataFlow GetDataFlow(IMMDevice* device);
+// EDataFlow GetDataFlow(IMMDevice* device);
 
 // Enumerates all input devices and adds the names (friendly name and unique
 // device id) to the list in |device_names|.
@@ -443,13 +443,13 @@ int NumberOfActiveSessions(IMMDevice* device);
 
 // Creates an IAudioClient instance for a specific device or the default
 // device specified by data-flow direction and role.
-Microsoft::WRL::ComPtr<IAudioClient> CreateClient(const std::string& device_id,
-                                                  EDataFlow data_flow,
-                                                  ERole role);
-Microsoft::WRL::ComPtr<IAudioClient2>
-CreateClient2(const std::string& device_id, EDataFlow data_flow, ERole role);
-Microsoft::WRL::ComPtr<IAudioClient3>
-CreateClient3(const std::string& device_id, EDataFlow data_flow, ERole role);
+// Microsoft::WRL::ComPtr<IAudioClient> CreateClient(const std::string& device_id,
+//                                                   EDataFlow data_flow,
+//                                                   ERole role);
+// Microsoft::WRL::ComPtr<IAudioClient2>
+// CreateClient2(const std::string& device_id, EDataFlow data_flow, ERole role);
+// Microsoft::WRL::ComPtr<IAudioClient3>
+// CreateClient3(const std::string& device_id, EDataFlow data_flow, ERole role);
 
 // Sets the AudioCategory_Communications category. Should be called before
 // GetSharedModeMixFormat() and IsFormatSupported(). The |client| argument must
diff --git a/modules/audio_device/win/core_audio_utility_win_unittest.cc b/modules/audio_device/win/core_audio_utility_win_unittest.cc
index 9e3a02ff69..712f7c66ec 100644
--- a/modules/audio_device/win/core_audio_utility_win_unittest.cc
+++ b/modules/audio_device/win/core_audio_utility_win_unittest.cc
@@ -7,7 +7,7 @@
  *  in the file PATENTS.  All contributing project authors may
  *  be found in the AUTHORS file in the root of the source tree.
  */
-
+#if 0
 #include "modules/audio_device/win/core_audio_utility_win.h"
 #include "rtc_base/arraysize.h"
 #include "rtc_base/logging.h"
@@ -876,3 +876,4 @@ TEST_F(CoreAudioUtilityWinTest, FillRenderEndpointBufferWithSilence) {
 
 }  // namespace webrtc_win
 }  // namespace webrtc
+#endif
\ No newline at end of file
-- 
2.25.0.windows.1

